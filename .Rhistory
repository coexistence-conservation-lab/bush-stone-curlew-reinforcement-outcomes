mtr <- rbind(
## zone 1
c(-37.897319, 144.429048), # S end of NW diagonal
c(-37.894066, 144.432334), # N end of NW diagonal, i.e. NW corner
c(-37.894749, 144.438305), # bend at main gate
c(-37.894693, 144.438324), # main gate
c(-37.894803, 144.439214), # bend before N Z1/2 gate
c(-37.894718, 144.439337), # N Z1/2 gate, i.e. NE corner
## zone 2
c(-37.892433, 144.440236), # N boundary internal aviary/Z2 i.e. NW corner
c(-37.892803, 144.443374), # Z2 northern boundary bend 1
c(-37.893634, 144.444076), # Z2 northern boundary bend 2
c(-37.894585, 144.447739), # N end of Z2/Z3 boundary, i.e. NE corner
c(-37.896515, 144.446789), # Z2/Z3 boundary bend 1
c(-37.896726, 144.446099), # Z2/Z3 boundary bend 2
c(-37.897964, 144.445706), # Z2/Z3 boundary bend 3
c(-37.899960, 144.444517), # S end of Z2/Z3 boundary, i.e. SE corner
# hashed lines are to remove the gap of the rock wallaby pen
#c(-37.899908, 144.444288), # Z2/btrw NE corner
#c(-37.898280, 144.440662), # Z1/btrw pen NW corner
## zone 1
#c(-37.900692, 144.440368), # Z1/btrw SW corner
#c(-37.902610, 144.443002), # Z1/btrw SE corner
c(-37.909538, 144.439648), # Z1 SE corner
c(-37.908999, 144.434965), # Z1 southern boundary bend 1
c(-37.907537, 144.433359), # Z1 southern boundary bend 2
c(-37.905958, 144.430140), # Z1 southern boundary bend 3
c(-37.905486, 144.429479), # Z1 southern boundary bend 4
c(-37.904649, 144.427566), # Z1 SW corner
c(-37.897319, 144.429048)  # S end of NW diagonal
) %>%  vect(type = "polygons", crs = "EPSG:4326") %>%
# transpose
t()
# Find points outside polygons
outside <- points[!relate(points, mtr, "intersects")] %>%
as.data.frame(geom = "XY")
# Plot points outside polygon
ggmap(map_z15)+
geom_point(data=outside, aes(x, y, colour = id), alpha = 0.7, size = 3)+
geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
scale_colour_viridis_d()+
theme_void()
View(points)
# convert geometry to regular columns to save to disk
distance_roosts2 <- distance_roosts_latlon %>%
st_drop_geometry() %>%
mutate(longitude = st_coordinates(distance_roosts_latlon$geometry)[,1],
latitude = st_coordinates(distance_roosts_latlon$geometry)[,2])
View(distance_roosts2)
# write to file
write.csv(distance_roosts2, "results/daily_distance_between_roosts.csv", row.names = FALSE)
View(roosts)
# release coords as spatial
release  <- st_sfc(st_point(c(274423.45, 5801912.85) ), crs = 32755)
# calculate distance between roosts and release site
dist <- roosts %>%
mutate(dist_release = as.numeric(st_distance(release, roosts))) %>%
# keep max distance per day
group_by(date, id) %>%
filter(dist_release == max(dist_release)) %>%
ungroup() %>%
# format date as a date
mutate(date = as_date(date)) %>%
# arrange by date
arrange(date) %>%
# transform to lat lon
vect() %>%
project("EPSG:4326")
# plot roosts with colour as distance from release
ggmap(map_z15)+
geom_sf(data = dist, aes(colour = dist_release), inherit.aes = FALSE)+
scale_colour_viridis_c()+
theme_void()
# format as data frame
dist <- st_as_sf(dist) %>%
st_drop_geometry()
View(dist)
# save to file
write.csv(dist, "results/daily_roost_distance_from_release.csv", row.names = FALSE)
# Read in cleaned data
data <- read.csv("data/data_cleaned.csv") %>%
# Time in posix format
mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS",
tz = "Australia/Melbourne")) %>%
# Add date
mutate(date = as_date(time_local, tz = "Australia/Melbourne"))
# set up data in spatial points dataframe
locs <- SpatialPointsDataFrame(coordinates(
cbind(data$easting, data$northing)), data = data)
# home range polygon per bird per day 🐢 40 minutes
birds <- as.character(unique(data$id))
days <- unique(locs[["date"]])
# Create empty dataframes for both 50% and 90% KUDs
hr50_daily <- data.frame()
hr90_daily <- data.frame()
for (i in 1:length(birds)){
for (j in 1:length(days)){
points <- subset(locs, id == birds[i] & date == days[j],
select = id)
if (length(points) < 5){
next
}
# Calculate KUD once
kud <- kernelUD(points[,1], h="href", grid = 300, extent = 5)
# Get both 50% and 90% contours from the same KUD object
kud90 <- getverticeshr(kud, percent = 90)
kud50 <- getverticeshr(kud, percent = 50)
# Set projection for both
proj4string(kud90) <- CRS("EPSG:32755")
proj4string(kud50) <- CRS("EPSG:32755")
# Convert to sf and add date
kud90_df_utm <- st_as_sf(kud90) %>%
mutate(date = days[j],
id = birds[i],
hr_level = "90")
kud50_df_utm <- st_as_sf(kud50) %>%
mutate(date = days[j],
id = birds[i],
hr_level = "50")
# Append to respective dataframes
hr90_daily <- rbind.data.frame(hr90_daily, kud90_df_utm)
hr50_daily <- rbind.data.frame(hr50_daily, kud50_df_utm)
# Print progress
print(paste("Completed:", birds[i], "on", days[j]))
}
}
# Packages
pacman::p_load(adehabitatHR, amt, atlastools, beepr, cowplot, effects, emmeans, flextable, ggeffects, ggfortify, ggmap, ggnewscale, ggforce, ggpubr, ggraph, ggridges, ggspatial, glmmTMB, gtools, igraph, janitor, jtools, lme4, lmerTest, move2, momentuHMM, MuMIn, ozmaps, patchwork, performance, plotrix, readxl, scales, scattermore, sf, showtext, sjPlot, sp, suncalc, survival, survminer, terra, tidygraph, tidyterra, tidyverse, tmap, viridis, wildlifeDI)
# Read in cleaned data
data <- read.csv("data/data_cleaned.csv") %>%
# Time in posix format
mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS",
tz = "Australia/Melbourne")) %>%
# Add date
mutate(date = as_date(time_local, tz = "Australia/Melbourne"))
# set up data in spatial points dataframe
locs <- SpatialPointsDataFrame(coordinates(
cbind(data$easting, data$northing)), data = data)
# set up data in spatial points dataframe
locs <- SpatialPointsDataFrame(coordinates(
cbind(data$x, data$y)), data = data)
# home range polygon per bird per day 🐢 40 minutes
birds <- as.character(unique(data$id))
days <- unique(locs[["date"]])
# Create empty dataframes for both 50% and 90% KUDs
hr50_daily <- data.frame()
hr90_daily <- data.frame()
for (i in 1:length(birds)){
for (j in 1:length(days)){
points <- subset(locs, id == birds[i] & date == days[j],
select = id)
if (length(points) < 5){
next
}
# Calculate KUD once
kud <- kernelUD(points[,1], h="href", grid = 300, extent = 5)
# Get both 50% and 90% contours from the same KUD object
kud90 <- getverticeshr(kud, percent = 90)
kud50 <- getverticeshr(kud, percent = 50)
# Set projection for both
proj4string(kud90) <- CRS("EPSG:32755")
proj4string(kud50) <- CRS("EPSG:32755")
# Convert to sf and add date
kud90_df_utm <- st_as_sf(kud90) %>%
mutate(date = days[j],
id = birds[i],
hr_level = "90")
kud50_df_utm <- st_as_sf(kud50) %>%
mutate(date = days[j],
id = birds[i],
hr_level = "50")
# Append to respective dataframes
hr90_daily <- rbind.data.frame(hr90_daily, kud90_df_utm)
hr50_daily <- rbind.data.frame(hr50_daily, kud50_df_utm)
# Print progress
print(paste("Completed:", birds[i], "on", days[j]))
}
}
# convert to lat lon for plotting
hr90_daily_ll <- st_transform(hr90_daily, "EPSG:4326")
hr50_daily_ll <- st_transform(hr50_daily, "EPSG:4326")
# plot home range map
ggmap(map_z15)+
geom_sf(data = hr90_daily_ll, aes(fill = id), alpha = 0.2, inherit.aes = FALSE)+
scale_colour_viridis_d()+
theme_void()
# Google and STadia API key for ggmaps
ggmap::register_google(key = readChar("apikey_google.txt", nchars = file.info("apikey_google.txt")$size))
map_z15 <- get_map(c(144.4380, -37.9000), zoom=15, maptype = "satellite")
# plot home range map
ggmap(map_z15)+
geom_sf(data = hr90_daily_ll, aes(fill = id), alpha = 0.2, inherit.aes = FALSE)+
scale_colour_viridis_d()+
theme_void()
# plot core range map
ggmap(map_z15)+
geom_sf(data = hr50_daily_ll, aes(fill = id), alpha = 0.2, inherit.aes = FALSE)+
scale_colour_viridis_d()+
theme_void()+
facet_wrap(~id)
# extract area per day i.e. drop geometry
hr_area <- st_drop_geometry(hr90_daily) %>%
rbind(st_drop_geometry(hr50_daily)) %>%
pivot_wider(names_from = hr_level, values_from = area) %>%
rename(kud90 = "90",
kud50 = "50")
View(hr_area)
# save to file
write.csv(hr_area, "results/daily_hr.csv", row.names = FALSE)
# Read in cleaned data
data <- read.csv("data/data_cleaned.csv") %>%
# Time in posix format
mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS",
tz = "Australia/Melbourne")) %>%
# Add date
mutate(date = as_date(time_local, tz = "Australia/Melbourne")) %>%
# needed to omit NAs for wildlifeDI to work
na.omit()
# format track data as move2 object
move <- mt_as_move2(data, coords = c("x", "y"), time_column = "time_local", track_id_column = "id") %>%
# add crs
sf::st_set_crs("EPSG:32755")
# define resident only date period
res_dates <- seq.Date(from = as_date("2023-01-16"), to = as_date("2023-06-06"), by = "day")
# subset to dates
data_resident <- move %>%
filter(date %in% res_dates)
# Test for a single dyad
dyad <- filter(data_resident, id %in% c("Aurora", "Briar"))
# list of residents
residents <- unique(data_resident$id)
# All bird combinations
list <-combinations(n = 13, r = 2, v = residents, repeats.allowed = FALSE)
list1 <- list[,1]
list2 <- list[,2]
# Calculate interactions between all birds 🐢
interact <- data.frame()
for(i in 1:length(list1)) {
dyad <- filter(data_resident, id %in% c(list1[i], list2[i]))
temp <- tryCatch({
data.frame(Prox(dyad, tc=5.5*60, dc=30)) %>%
clean_names()
}, error = function(e) data.frame(ca = NA, bird1 = NA, bird2 = NA))
print(paste("Finished", list1[i], "&", list2[i], i, "of 78", sep = " "))
interact <- rbind(interact, temp)
}
# tidy up the output
interact2 <- interact %>%
# remove unneeded columns
select(id1, id2, prox) %>%
# format prox numeric to 4 decimal places
mutate(prox = as.numeric(format(round(prox, 4), nsmall = 4)))
# save to disk
write.csv(interact2, "results/proximity_residents.csv", row.names = FALSE)
# summary statistics prox values
hist(interact2$prox)
summary(interact2$prox)
# read in dyad proximity scores and convert to association matrix
prox1 <- read.csv("results/proximity_residents.csv") %>%
# add rows for last and first bird self comparison
rbind(data.frame(id1 = c("Valentine", "Aurora"),
id2 = c("Valentine", "Aurora"),
prox = c(NA, NA))) %>%
# long to wide format
pivot_wider(names_from = id2, values_from = prox) %>%
# first column to rownames
column_to_rownames("id1") %>%
# relocate first bird to first column
relocate(Aurora) %>%
# format as matrix
as.matrix()
# make symmetrical
prox1[lower.tri(prox1)] <- t(prox1)[lower.tri(prox1)]
# convert to graph object
g1 <- graph_from_adjacency_matrix(prox1, mode = "undirected", diag = FALSE, weighted = TRUE)
g1
# network density - real edges divided by possible edges
edge_density(g1)
# set seed to keep layout static
set.seed(333)
layout1 <- create_layout(g1, layout = "fr")
# plot with tidygraph (wrapper for igraph in tidy API)
ggraph(layout1)+
# vary edge alpha by weight
geom_edge_fan(aes(alpha = weight), show.legend = FALSE) +
# node basic
geom_node_point(size = 7, shape = 16)+
# add labels
geom_node_text(aes(label = name), nudge_y = 0.15)+
# theme
theme_void()
# set seed to keep layout static
set.seed(111)
layout1 <- create_layout(g1, layout = "fr")
# plot with tidygraph (wrapper for igraph in tidy API)
ggraph(layout1)+
# vary edge alpha by weight
geom_edge_fan(aes(alpha = weight), show.legend = FALSE) +
# node basic
geom_node_point(size = 7, shape = 16)+
# add labels
geom_node_text(aes(label = name), nudge_y = 0.15)+
# theme
theme_void()
# set seed to keep layout static
set.seed(1111)
layout1 <- create_layout(g1, layout = "fr")
# plot with tidygraph (wrapper for igraph in tidy API)
ggraph(layout1)+
# vary edge alpha by weight
geom_edge_fan(aes(alpha = weight), show.legend = FALSE) +
# node basic
geom_node_point(size = 7, shape = 16)+
# add labels
geom_node_text(aes(label = name), nudge_y = 0.15)+
# theme
theme_void()
# community with spinglass - weights NULL uses the default weights of the dataset
com1 <- cluster_spinglass(g1, weights = NULL)
length(com1)
modularity(com1)
membership(com1)
# add community to network layout
layout1 <- layout1 %>%
mutate(community = as.factor(membership(com1)))
# plot with communities
ggraph(layout1)+
# community polygon
geom_mark_hull(aes(x = x, y = y, fill = community),
colour = "white", alpha = 0.2, expand = unit(0.5, "cm"),
show.legend = FALSE)+
# vary edge alpha by weight
geom_edge_fan(aes(alpha = weight), show.legend = FALSE) +
# node basic
geom_node_point(size = 7, shape = 16)+
# add labels
geom_node_text(aes(label = name), nudge_y = 0.15)+
# theme
theme_void()
# plot
ggraph(layout2)+
# community polygon
geom_mark_hull(aes(x = x, y = y, fill = community),
colour = "white", alpha = 0.2, expand = unit(0.5, "cm"),
show.legend = FALSE)+
# vary edge alpha by weight
geom_edge_fan(aes(alpha = weight), show.legend = FALSE) +
# node shape by cohort
geom_node_point(aes(shape = cohort), size = 7)+
# add labels
geom_node_text(aes(label = id), nudge_y = 0.15)+
# theme
theme_void()
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-05"), by = "day")
# read in data and filter to reinforcement period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
# add metadata
left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
# format dates as dates
mutate(date = as_date(date_bird)) %>%
# limit to reinforcement period
filter(date %in% rein_dates) %>%
# add a time elapsed post-release variable
mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
# add column for membership to social group
mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
# convert group to factor and set resident as the intercept
mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))
# Metadata - translocation information
metadata  <- read.csv("data/metadata.csv") %>%
clean_names() %>%
rename(id = identity)
# Metadata - translocation information
metadata  <- read.csv("data/metadata.csv") %>%
clean_names() %>%
rename(id = identity)
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-05"), by = "day")
# read in data and filter to reinforcement period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
# add metadata
left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
# format dates as dates
mutate(date = as_date(date_bird)) %>%
# limit to reinforcement period
filter(date %in% rein_dates) %>%
# add a time elapsed post-release variable
mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
# add column for membership to social group
mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
# convert group to factor and set resident as the intercept
mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))
# create social group means
sum1 <- datam1 %>%
group_by(date, social) %>%
summarise(dist = mean(daily_dist),
upper = dist + 1.96 * std.error(daily_dist),
lower = dist - 1.96 * std.error(daily_dist)) %>%
arrange(date)
# plot daily distance over time as social group means
ggplot(sum1, aes(date, dist, ymin = lower, ymax = upper)) +
geom_path(aes(colour = social)) +
geom_ribbon(aes(fill = social), alpha = 0.2) +
xlab("Days post-reinforcement") +
ylab("Daily distance moved (m)") +
theme_minimal() +
scale_fill_viridis_d()+
scale_colour_viridis_d()
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-04"), by = "day")
# read in data and filter to reinforcement period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
# add metadata
left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
# format dates as dates
mutate(date = as_date(date_bird)) %>%
# limit to reinforcement period
filter(date %in% rein_dates) %>%
# add a time elapsed post-release variable
mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
# add column for membership to social group
mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
# convert group to factor and set resident as the intercept
mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))
# create social group means
sum1 <- datam1 %>%
group_by(date, social) %>%
summarise(dist = mean(daily_dist),
upper = dist + 1.96 * std.error(daily_dist),
lower = dist - 1.96 * std.error(daily_dist)) %>%
arrange(date)
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-01"), by = "day")
# read in data and filter to reinforcement period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
# add metadata
left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
# format dates as dates
mutate(date = as_date(date_bird)) %>%
# limit to reinforcement period
filter(date %in% rein_dates) %>%
# add a time elapsed post-release variable
mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
# add column for membership to social group
mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
# convert group to factor and set resident as the intercept
mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))
# create social group means
sum1 <- datam1 %>%
group_by(date, social) %>%
summarise(dist = mean(daily_dist),
upper = dist + 1.96 * std.error(daily_dist),
lower = dist - 1.96 * std.error(daily_dist)) %>%
arrange(date)
# plot daily distance over time as social group means
ggplot(sum1, aes(date, dist, ymin = lower, ymax = upper)) +
geom_path(aes(colour = social)) +
geom_ribbon(aes(fill = social), alpha = 0.2) +
xlab("Days post-reinforcement") +
ylab("Daily distance moved (m)") +
theme_minimal() +
scale_fill_viridis_d()+
scale_colour_viridis_d()
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-04"), by = "day")
# read in data and filter to reinforcement period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
# add metadata
left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
# format dates as dates
mutate(date = as_date(date_bird)) %>%
# limit to reinforcement period
filter(date %in% rein_dates) %>%
# add a time elapsed post-release variable
mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
# add column for membership to social group
mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
# convert group to factor and set resident as the intercept
mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))
# create social group means
sum1 <- datam1 %>%
group_by(date, social) %>%
summarise(dist = mean(daily_dist),
upper = dist + 1.96 * std.error(daily_dist),
lower = dist - 1.96 * std.error(daily_dist)) %>%
arrange(date)
# distribution of movement data
hist(datam1$daily_dist)
ggqqplot(datam1$daily_dist)
# test difference between the groups with interaction of time as a quadratic
m1 <- glmmTMB(daily_dist ~ social * (scale(elapsed) + I(scale(elapsed)^2)) + (1|id),
data = datam1,
na.action = "na.fail")
# model selection
dm1 <- dredge(m1)
# model selection
dm1 <- dredge(m1, fixed = "cond(social)")
View(dm1)
# parsimonious model where delta <2 and fewest predictors
# in this case first
best1 <- get.models(dm1, delta <2)[[1]]
# check model
check_model(best1)
# summary
summary(best1)
# post-hoc comparison of slopes
emtrends(best1, pairwise ~ social, var = "elapsed")
