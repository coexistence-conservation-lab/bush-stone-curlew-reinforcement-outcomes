---
title: "bsc_reinforcement_analyses"
author: "Shoshana Rapley"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)

# Packages
pacman::p_load(adehabitatHR, amt, asnipe, atlastools, beepr, emmeans, ggfortify, ggmap, ggnewscale, ggpubr, ggridges, glmmTMB, gtools, igraph, janitor, lme4, lmerTest, move2, momentuHMM, scattermore, sf, sp, STRAND, suncalc, survival, survminer, terra, tidyterra, tidyverse, wildlifeDI)

# Google API key for ggmaps
ggmap::register_google(key = readChar("apikey_google.txt", nchars = file.info("apikey_google.txt")$size))

# Background map MR zones 1 and 2
map_z14 <- get_map(c(144.4380, -37.9000), zoom=14, maptype = "satellite")
map_z15 <- get_map(c(144.4380, -37.9000), zoom=15, maptype = "satellite")

# Metadata - translocation information
metadata  <- read.csv("data/metadata.csv") %>%
  clean_names() %>%
  rename(id = identity,
         mortality = mortality_or_capture) %>%
  mutate(start_date = as_date(dmy(start_date)),
         end_date = as_date(dmy(end_date)),
         mortality = as_date(dmy(mortality)))
```

# Introduction

Reinforcement is a form of conservation translocation used to stabilise or enhance populations. Reinforcement is also a stage within other forms of translocation, which usually involve multiple release cohorts. Even a reintroduction project will have conspecifics present from the second release. Benefits of reinforcing release are assumed (e.g., increase population size, add diversity) but rarely empirically tested – and if they are its usually from perspective of reinforcing individuals, not the population as a whole. Outcomes of reinforcement are mediated by social interactions, which are also assumed but not often empirically tested. 

Here we test the outcomes of reinforcement for a population of bush stone-curlew where all individuals in the population (previously released and reinforcing) are accounted for and tracked with GPS. We ask: do the cohorts integrate? And do social interactions benefit the reinforcing cohort? 

# Data cleaning

We translocated 36 adult captive-bred bush stone-curlews from Mt Rothwell captive colony to Mt Rothwell Zone 1 (fenced sanctuary) in two stages. The first (pilot) cohort of 16 birds was released between October 2022 and June 2023. The second (reinforcing) cohort of 20 birds was released in June 2023. 

All translocated birds were fitted with a GPS tracker (Ornitrak20 from Ornitela) with a duty cycle of a fix every 60 seconds (or reduced when battery low). Telemetry data were stored on Movebank. We collected data from the release date of each individual until the 12th of January 2024 (when GPS devices were removed from all remaning birds except one, ahead of the 3G shutdown).

High throughput animal tracking data require filtering to remove erroneous points, while maintaining real movement data. We follow the workflow by [Gupte et al. (2021)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.13610), that is:

1) temporal filtering
2) filtering by quality covariates
3) filtering biologically unrealistic movement
4) median smoothing

## Test pipeline

We first tested the pipeline with a subset of the data (birds "Marmalade" & "Fauna"). Marmalade left the fenced area during the study while Fauna did not. 

### 1) Temporal filtering

We removed points after the end of the study period (4/8/23 at the start of next experiment - translocation to Orana).

```{r}
# import data from movebank
data_raw <- readr::read_csv("movebank/Fauna01.csv", show_col_types = FALSE) %>%
  rbind(readr::read_csv("movebank/Marmalade01.csv", show_col_types = FALSE)) %>%
  clean_names() %>%
  # Time in posix format
  mutate(datetime = as.POSIXct(study_local_timestamp, "%Y-%m-%d %H:%M:%S"),
         date = as.Date(datetime)) %>%
  # Remove days after end of tracking period
  filter(date < "2023-08-04") %>%
  rename(id = individual_local_identifier)

# plot raw data
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow", alpha = .6)+
  theme_void()+
  facet_wrap(~id)
```

### 2) Filtering by quality covariates

In the past I've found filtering by satellite count and hdop has a high rate of false positives (removing real movement) and low rate of true positives (removing unrealistic movement) so we don't want to be overly aggressive with the application of these filters.

```{r}
# Histogram of satellite vales
hist(data_raw$gps_satellite_count)

# Plot track, colour by satellite values
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_raw, aes(location_long, location_lat, colour = gps_satellite_count))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

Most points have a satellite count >=4. Not many of the obvious spikes have low satellite count. We'll filter to include only satellite count >=4. 

Now look at the horizontal dilution of precision (HDOP).

```{r}
# Histogram of hdop vales
hist(data_raw$gps_hdop)

# Plot track, colour by hdop values
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_raw, aes(location_long, location_lat, colour = gps_hdop))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

There are a handful of massive hdop values (5-15) but the vast majority are =<2. Again the obvious spikes don't have high hdop values. We'll filter to only include hdop <=2. 

Next we'll apply filtering on the basis of altitude. 

Incorrect GPS fixes often have incorrect altitude. High altitude was not expected as no birds were undertaking long-distance flight, which is the only time high altitude is possible. All birds were wing-clipped on release and some later moulted and undertook short-distance flight, but not at high altitude. 

First we need to find flight height altitude by correcting for ground elevation. We are using the [FABDEM (Forest And Buildings removed Copernicus 30m DEM)](https://gee-community-catalog.org/projects/fabdem/).

```{r}
# read in FABDEM
fabdem <- rast("S38E144_FABDEM_V1-0.tif") 

# convert data to spatial points
coords <- data_raw %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Extract dem and add to dataframe
data_alt <- data_raw %>%
  mutate(terra::extract(fabdem, coords, ID = FALSE)) %>%
  rename(elevation = "S38E144_FABDEM_V1-0") %>%
  # calculate flight height
  mutate(altitude = height_above_msl - elevation)

# Histogram altitude
hist(data_alt$altitude)

# Summary statistics altitude
summary(data_alt$altitude)
quantile(data_alt$altitude, probs = 0.95)

# Plot track, colour by altitude values
ggmap(map_z13)+
  geom_path(data=data_alt, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_alt, aes(location_long, location_lat, colour = altitude))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

The median altitude (above the ground surface) was 9m. The min (-2060m) and max (8313m) altitude were considered unrealistic. Many of the obvious spikes have very high or negative altitude. 

We cut off the maximum altitude at 60 (just above the 0.95 quartile) and the minimum to -10m (ground level allowing for some error).

```{r}
# Apply quality covariate filters
data_qfilt <- data_alt %>%
  filter(gps_satellite_count >= 4) %>%
  filter(gps_hdop <=2) %>%
  filter(altitude < 60 & altitude >-10)

# Plot effect of filtering
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "purple", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow")+
  geom_point(data=data_qfilt, aes(location_long, location_lat), 
             colour = "purple")+
  theme_void()+
  facet_wrap(~id)
```

This successfully filtered out most of the obvious spikes.

### 3) Filtering biologically unrealistic movement

To remove spikes in the data we can filter out positions with extreme incoming and outgoing speeds. First we need to define biologically realistic incoming and outgoing speeds.

```{r}
# Append turning angle, incoming/outgoing speeds to data frame per bird
birds <- unique(data_raw$id)

data_speed <- data.frame()

for(i in 1:length(birds)){
 subset <- filter(data_qfilt, id == birds[i])

 temp <- subset %>%
   mutate(speed_in  = atl_get_speed( 
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("in")),
    speed_out = atl_get_speed(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("out")),
    angle = atl_turning_angle(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime"),
    speed_delta = abs(speed_in - speed_out)
    )
 
 data_speed <- rbind(data_speed, temp)
}

# Histogram incoming speeds
hist(data_speed$speed_in)

# Summary statistics incoming speeds
summary(data_speed$speed_in)
quantile(data_speed$speed_in, probs = 0.99, na.rm = TRUE)

# Histogram outgoing speeds
hist(data_speed$speed_out)

# Summary statistics outgoing speeds
summary(data_speed$speed_out)
quantile(data_speed$speed_out, probs = 0.95, na.rm = TRUE)

# Histogram turning angle
hist(data_speed$angle)

# Summary statistics turning angle
summary(data_speed$angle)

# Histogram difference between incoming and outgoing speed
hist(data_speed$speed_delta)

# Summary statistics difference between incoming and outgoing speed
summary(data_speed$speed_delta)
quantile(data_speed$speed_delta, probs = 0.95, na.rm = TRUE)

# Plot track, colour by speed
ggmap(map_z14)+
  geom_path(data=data_speed, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_speed, aes(location_long, location_lat, colour = speed_delta))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

Speeds were usually <2m/s and outgoing speeds while turning are likely <1m/s. A sharp turning angle was defined as <90 degrees. Sharp increase/decrease in speed also isn't expected, with the vast majority of difference between incoming and outgoing speed 0.1m/s.

We defined biologically realistic movement as speeds <2m/s (a note of caution: this shouldn't be used when the birds are undertaking long distance movements as faster speeds may be possible e.g. while gliding on wind), turning speeds of 0.5m/s, and delta speed as 0.4m/s. 

```{r}
# Apply turning angle filtering
data_sfilt <- data_speed %>%
  filter(speed_in < 2) %>%
  filter(speed_delta < 0.4) %>%
  filter(!(speed_out >0.5 & angle <90))

# Plot effect of filtering
ggmap(map_z14)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "purple", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow")+
  geom_point(data=data_qfilt, aes(location_long, location_lat), 
             colour = "orange")+
  geom_point(data=data_sfilt, aes(location_long, location_lat), 
             colour = "purple")+
  theme_void()+
  facet_wrap(~id)
```

### 4) Median smoothing

Even after speed/angle filtering, we retain some smaller-scale 'jitter'- these are challenging to remove as they lie within the bounds of realistic movement. Median resampling is a method of smoothing the track to reduce jitter. We want to apply it sparingly to not reduce track verismilitude.

```{r}
# Apply median smooth by bird
data_smooth <- data.frame()

for(i in 1:length(birds)){
  
  subset <- filter(data_sfilt, id == birds[i])
  
  temp <- atl_median_smooth(data = subset, x = "location_lat", y = "location_long",
                                  time = "datetime", moving_window = 3)
  
  data_smooth <- rbind(data_smooth, temp)
}

# Plot effect of smoothing
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)

# And zoom in to the fenced area
ggmap(map_z15)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)

# And visualise without filtered out data
ggmap(map_z15)+
    geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)
```

*_Visual check using fence polygon._*
We know Fauna didn't leave the study site during the tracking period so this is a good way to check if filtering was successful. 

First define the fenced area.

```{r}
# Define fence polygons (zones 1 and 2)
mtr <- rbind(
  ## zone 1
  c(-37.897319, 144.429048), # S end of NW diagonal
  c(-37.894066, 144.432334), # N end of NW diagonal, i.e. NW corner
  c(-37.894749, 144.438305), # bend at main gate 
  c(-37.894693, 144.438324), # main gate
  c(-37.894803, 144.439214), # bend before N Z1/2 gate
  c(-37.894718, 144.439337), # N Z1/2 gate, i.e. NE corner 
  ## zone 2
  c(-37.892433, 144.440236), # N boundary internal aviary/Z2 i.e. NW corner
  c(-37.892803, 144.443374), # Z2 northern boundary bend 1
  c(-37.893634, 144.444076), # Z2 northern boundary bend 2
  c(-37.894585, 144.447739), # N end of Z2/Z3 boundary, i.e. NE corner
  c(-37.896515, 144.446789), # Z2/Z3 boundary bend 1
  c(-37.896726, 144.446099), # Z2/Z3 boundary bend 2
  c(-37.897964, 144.445706), # Z2/Z3 boundary bend 3
  c(-37.899960, 144.444517), # S end of Z2/Z3 boundary, i.e. SE corner
  c(-37.899908, 144.444288), # Z2/btrw NE corner
  c(-37.898280, 144.440662), # Z1/btrw pen NW corner
  ## zone 1
  c(-37.900692, 144.440368), # Z1/btrw SW corner
  c(-37.902610, 144.443002), # Z1/btrw SE corner
  c(-37.909538, 144.439648), # Z1 SE corner
  c(-37.908999, 144.434965), # Z1 southern boundary bend 1
  c(-37.907537, 144.433359), # Z1 southern boundary bend 2
  c(-37.905958, 144.430140), # Z1 southern boundary bend 3
  c(-37.905486, 144.429479), # Z1 southern boundary bend 4
  c(-37.904649, 144.427566), # Z1 SW corner
  c(-37.897319, 144.429048)  # S end of NW diagonal
  ) %>%  vect(type = "polygons", crs = "EPSG:4326") %>% t() %>%
  # add a buffer for GPS accuracy of 30m
  buffer(30)
```

Then filter for points from "Fauna" outside of the polygon. 

```{r}
# Convert df to points
points <- data_smooth %>%
  filter(id=="Fauna") %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Find points outside polygons
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside polygon 
ggmap(map_z15)+
  geom_point(data=outside, aes(x, y), colour = "yellow", alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_c()+
  theme_void()
```

There are only 65 points outside the fence (given a 30m buffer) which is within tolerance. Interestingly they are all clustered on the southern and eastern fenceline. 

## Apply filtering 

We apply all of the above steps to the full dataset. 

### 1) Temporal filtering

We removed points after the end of the study period (4/8/23 at the start of next experiment - translocation to Orana).

```{r}
# Import data from movebank
data_raw <- readr::read_csv(fs::dir_ls(path = "movebank")) %>%
  clean_names() %>%
  # Time in posix format
  mutate(datetime = as.POSIXct(study_local_timestamp, "%Y-%m-%d %H:%M:%S"),
         date = as.Date(datetime)) %>%
  # Remove days after end of study
  filter(date < "2023-08-04") %>%
  rename(id = individual_local_identifier)
```

### 2) Filtering by quality covariates

We used the following quality covariates:

* Altitude: set to a minimum of -10m (ground level allowing for some error) and a maximum of 60 (just above the 0.95 quartile on test data)
* HDOP: set to a maximum of 2
* Satellite count: set to a minimum of 4

```{r}
# read in FABDEM
fabdem <- rast("S38E144_FABDEM_V1-0.tif") 

# convert data to spatial points
coords <- data_raw %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Extract dem and add to dataframe
data_alt <- data_raw %>%
  mutate(terra::extract(fabdem, coords, ID = FALSE)) %>%
  rename(elevation = "S38E144_FABDEM_V1-0") %>%
  # calculate flight height
  mutate(altitude = height_above_msl - elevation)

# Apply quality covariate filters
data_qfilt <- data_alt %>%
  filter(gps_satellite_count >= 4) %>%
  filter(gps_hdop <=2) %>%
  filter(altitude < 60 & altitude >-10)

# Filtering effect
print(paste("Percentage original data removed: ", round(((nrow(data_raw)-nrow(data_qfilt)) / nrow(data_raw))*100), "%", sep = ""))
```

Percentage original data removed: 28%

### 3) Filtering biologically unrealistic movement

We defined (from test data) biologically realistic movement as speeds <2m/s (a note of caution: this shouldn't be used when the birds are undertaking long distance movements as faster speeds may be possible e.g. while gliding on wind), turning speeds of 0.5m/s, and delta speed as 0.4m/s. 

```{r}
# Append turning angle, incoming/outgoing/delta speeds to data frame per bird
birds <- unique(data_raw$id)

data_speed <- data.frame()

for(i in 1:length(birds)){
 subset <- filter(data_qfilt, id == birds[i])

 temp <- subset %>%
   mutate(speed_in  = atl_get_speed( 
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("in")),
    speed_out = atl_get_speed(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("out")),
    angle = atl_turning_angle(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime"),
    speed_delta = abs(speed_in - speed_out)
    )
 
 data_speed <- rbind(data_speed, temp)
}

# Apply turning angle and speed filtering
data_sfilt <- data_speed %>%
  filter(speed_in < 2) %>%
  filter(speed_delta < 0.4) %>%
  filter(!(speed_out >0.5 & angle <90))

# Filtering effect
print(paste("Percentage original data removed: ", round(((nrow(data_qfilt)-nrow(data_sfilt)) / nrow(data_qfilt))*100), "%", sep = ""))
```

Percentage original data removed: 7%

### 4) Median smoothing

To remove small-scale jitter. We used the smallest possible moving window (3) to retain as much real movement as possible. 

```{r}
# Apply median smooth by bird
data_smooth <- data.frame()

for(i in 1:length(birds)){
  
  subset <- filter(data_sfilt, id == birds[i])
  
  temp <- atl_median_smooth(data = subset, x = "location_lat", y = "location_long",
                                  time = "datetime", moving_window = 3)
  
  data_smooth <- rbind(data_smooth, temp)
}

# Plot smoothed data
ggmap(map_z14)+
  geom_path(data=data_smooth, aes(location_long, location_lat, colour = id), alpha = .7)+
  scale_colour_viridis_d()+
  theme_void()
```

Save data - dropping unneeded columns to save space. Originally I kept the utm easting and northing columns but I noticed a mismatch between the cleaned lat/lon and the utm, so have elected to transform the data when required instead. 

```{r}
# Convert data to spatial and reproject in utm
points <- data_smooth %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326") %>%
  # re-project into zone 55S
  project("EPSG:32755") %>%
  st_as_sf()

# allocate utm coords
coords <- st_coordinates(points$geometry)

# format data frame for saving to disk
data <- data_smooth %>%
  # select columns to keep
  dplyr::select(c("id", "datetime", "timestamp", "location_long", "location_lat", "acceleration_raw_x", "acceleration_raw_y", "acceleration_raw_z", "external_temperature", "altitude")) %>%
  # rename columns
  rename(longitude = location_long,
         latitude = location_lat,
         time_local = datetime,
         time_utc = timestamp) %>%
  # add utm xy columns 
  mutate(easting = st_coordinates(points$geometry)[,1],
         northing = st_coordinates(points$geometry)[,2]) %>%
  # add cohort metadata
  left_join(dplyr::select(metadata, c("id","cohort")))

# save to disk
write.csv(data, "data/data_cleaned.csv", row.names = FALSE)
```

# Movement analysis

Read in clean data.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne"))

# Plot cleaned data to check
ggmap(map_z14)+
  geom_path(data=data, aes(longitude, latitude, colour = id), alpha = .7)+
  scale_colour_viridis_d()+
  theme_void()
```

Calculate basic summary statistics. 

```{r}
# Summary statistic: number of tracked days
length(unique(data$date))

# Summary statistic: total number of tracked days per bird
print(data %>%
  group_by(id) %>%
  summarise(length(unique(date))), n=35)

print(data %>%
  group_by(id) %>%
  summarise(days = length(unique(date))) %>%
  summarise(birddays = sum(days)))
```

Birds were tracked for a total of 284 days between October 2022 and August 2023 for a total of 3533 tracking days (sum of each bird's tracking duration). 

Wobbles and Star tracked for less than two weeks and excluded from further analyses. 

```{r}
data <- data %>%
  filter(!id %in% c("Wobbles", "Star"))
```

## Day/night

Rather than splitting data on calendar days (because they are nocturnal and movement continues over midnight) we want to split the data by diurnal and nocturnal movement. We use the sunrise/sunset time (from suncalc) to add bird date to the data. This also provides additional filtering, because jitter while the bird is stationary at its roost overinflates movement estimates, so counting only noctunal movement gives a better estimate of real movement. Additionally, we add "bird date" to the data, a 24-hour period commencing at sunset (a better indication of a "day" from the bird's perspective than calendar day), so that movements over a night (crossing midnight) can be allocated to the correct grouping. 

```{r}
# Calculate if time is pre/post dawn/dusk
suntime <- getSunlightTimes(date = unique(data$date),
                            lat = -37.90,
                            lon = 144.43,
                            keep = c("sunrise", "sunset"),
                            tz = "Australia/Melbourne") %>%
  subset(dplyr::select = -c(lat, lon)) 

# Append to data frame
data_sun <- left_join(data, suntime) %>%
  mutate(tod = ifelse(time_local>sunrise & time_local<sunset, "day", "night")) %>%
  relocate(time_local, .after = tod) %>%
  na.omit()

# Plot to check - using scattermore to speed up display
ggplot(data_sun)+
  geom_scattermore(aes(easting, northing, colour = tod), alpha = 0.6)+
  coord_sf()+
  theme_void()

# Add "bird date" 
data_sun <- data_sun %>%
  # add column for how long past/to sunset
  mutate(suntime = as.numeric(difftime(time_local, sunset, units = "hours"))) %>%
  # negative sun-time values indicate it's the next day - 
  # therefore allocate previous day calendar date as "bird date"
  mutate(date_bird = as_date(ifelse(suntime > 0, date, date - 1)))

# Save day data
data_day <- data_sun %>%
  filter(tod == "day")

write.csv(data_day, "data/data_clean_day.csv", row.names = FALSE)

# Save night data
data_night <- data_sun %>%
  filter(tod == "night")

write.csv(data_night, "data/data_clean_night.csv", row.names = FALSE)
```

## Distance moved

How long does it take birds to settle? Do acclimation periods differ between cohorts?

Distance moved per night over time. Calculation is done per bird per day (bird date).

Test with one bird, "Fauna". 

```{r}
# read in night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # format time as posixct
  mutate(time_local = as.POSIXct(time_local))

# format as amt and calculate step lengths
steps <- data_night %>%
  filter(id=="Fauna") %>%
  # format as amt track - add columns as needed
  make_track(.x = easting, .y = northing, .t = time_local, id = id, date_bird = date_bird) %>%
  steps(keep_cols = "start")

# summarise per bird date
summary <- steps %>%
  group_by(date_bird) %>%
  summarise(daily_dist = sum(sl_))

# plot histogram
hist(summary$daily_dist)

# plot over time
ggplot(summary, aes(date_bird, daily_dist))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_void()
```

Apply to all birds.

```{r}
# for loop to calculate distance moved per bird date
birds <- unique(data_night$id)

distance_daily <- data.frame()

for(i in 1:length(birds)){
  # Subset to bird, convert data to spatial and reproject in utm
    points <- data_night %>%
    # subset to bird
    filter(id==birds[i]) %>%
    vect(geom = c("longitude", "latitude"), crs = "EPSG:4326") %>%
    # re-project into zone 55S
    project("EPSG:32755") %>%
    st_as_sf()

  # save coords
  coords <- st_coordinates(points$geometry)

  # format as amt and calculate step lengths
  steps <- points %>%
    # get utm xy columns 
    mutate(easting = st_coordinates(points$geometry)[,1],
         northing = st_coordinates(points$geometry)[,2]) %>%
    # format as amt track 
    make_track(.x = easting, .y = northing, .t = time_local, id = id, 
               # add additional columns as needed
               date_bird = date_bird) %>%
    steps(keep_cols = "start")

  # summarise per bird date
  summary <- steps %>%
    group_by(date_bird) %>%
    summarise(daily_dist = sum(sl_)) %>%
    mutate(id = birds[i])
  
  # write out
  distance_daily <- rbind(distance_daily, summary)
  
  # alert me
  print(paste("finished calculation for ", birds[i], sep = ""))
}

# save output
write.csv(distance_daily, "results/daily_distance_moved.csv", row.names = FALSE)
```

Plot distance moved as a density plot and movement over time, per bird.

```{r}
# plot histogram
hist(distance_daily$daily_dist)

# plot density by bird
ggplot(distance_daily)+
  geom_density_ridges(aes(daily_dist, id, fill = id), alpha = 0.7)+
  scale_fill_viridis_d()+
  theme_bw()+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  theme(legend.position = "none")+
  xlim(0,7000)+
  scale_y_discrete(expand = expansion(add = c(0, 2)))+
  xlab("Distance moved daily (m)") + 
  theme(axis.title.y=element_blank())
```

## Roost establishment

Look at the same idea as the previous section (a metric of establishment) but with diurnal roost movement rather than nightly distanced moved. 

First calculate roost locations. Test with one bird.

```{r}
# read in day data
data_day <- read.csv("data/data_clean_day.csv")

# filter to test bird
test <- data_day %>%
  filter(id == "Aurora")

# plot roosts coloured by date
ggmap(map_z15)+
  geom_density2d(data=test, aes(longitude, latitude, colour = date), inherit.aes = FALSE)+
  theme_void()+
  scale_colour_viridis_d()+
  theme(legend.position = "none")

# plot a series of dates to see if multiple roosts occur
dates <- seq(as.Date("2023-01-01"), as.Date("2023-01-12"), "days")
span <- filter(test, date %in% dates)

ggmap(map_z15)+
  geom_density2d(data=test, aes(longitude, latitude), colour = "yellow", inherit.aes = FALSE)+
  theme_void()+
  facet_wrap(~date)
```

On visual inspection, the vast majority of dates have a single roost. 

Approximate roosts positions using kmeans. Apply to all birds

```{r}
# locate kmeans center for a roost per bird per day
birds <- unique(data_day$id)
days <- unique(data_day$date)

roosts <- data.frame()

for (i in 1:length(birds)){
  for (j in 1:length(days)){
    
    #subset by bird and date
    subset <- subset(data_day, id == birds[i] & date == days[j],
                    dplyr::select= c(easting, northing))
    # skip days where not enough points
      if (length(subset$easting)<4){next}
    
    # find kmean centers
    kmean <- kmeans(subset, centers=1)
    
    # compile data
    out <- as.data.frame(cbind(kmean$centers, npoints = kmean$size)) %>%
      mutate(id = birds[i], date = days[j])
    
    roosts <- rbind(roosts, out)
    
  }
  print(paste("Finished calculation for ", birds[i], sep = ""))
}

# characteristics of cluster data
hist(roosts$npoints)
summary(roosts$npoints)

# plot roosts by number of points
ggplot(roosts)+
  geom_point(aes(easting, northing, size = npoints, colour = id))+
  geom_path(aes(easting, northing, group = id), alpha = 0.3)+
  coord_sf()+
  scale_colour_viridis_d()+
  theme_bw()

# plot for a single bird with date as colour
ggplot(data = filter(roosts, id == "Marmalade"))+
  geom_point(aes(easting, northing, size = npoints, colour = as.Date(date)))+
  geom_path(aes(easting, northing, group = id), alpha = 0.3)+
  coord_sf()+
  scale_colour_viridis_c()+
  theme_bw()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank())

# save daily roost locations
write.csv(roosts, "results/daily_roost_location.csv", row.names = FALSE)
```

How far between consecutive roosts? 

```{r}
# read in roost locations, format as spatial
roosts <- read.csv("data/daily_roost_location.csv") %>%
  dplyr::select(!"npoints") %>%
  vect(geom = c("easting", "northing"), crs = "EPSG:32755") %>%
  st_as_sf()

# calculate distance between successive roosts per bird
birds <- unique(roosts$id)
distance_roosts <- data.frame()

for(i in 1:length(birds)){
  
  # subset to individual
  points <- filter(roosts, id==birds[i]) %>%
    # date as posix
    mutate(date = as.POSIXct(date, format = "%Y-%m-%d")) %>%
    # ensure arranged by date
    arrange(date) %>%
    #add lag column for geometry comparison
    mutate(previous = lag(geometry))
  
  # allocate the release location as the first location
  release <- st_sfc(st_point(c(274423.45, 5801912.85) ), crs = 32755) %>%
    st_as_sf()
  
  points$previous[1] <- release$x
  
  # calculate the distance between successive points
  out <- points %>%
    mutate(distance_previous = 
             as.numeric(st_distance(points$geometry, points$previous, by_element = TRUE))) %>%
    dplyr::select(!"previous")
  
  # write out
  distance_roosts <- rbind(distance_roosts, out)
}

# hist
hist(distance_roosts$distance_previous)

# transform to latlon
distance_roosts_latlon <- distance_roosts %>%
  vect() %>%
  project("EPSG:4326") %>%
  st_as_sf() %>%
  mutate(date = as_date(date))

# plot roosts with colour as distance from previous
ggplot()+
  geom_sf(data = distance_roosts_latlon, aes(colour = distance_previous))+
  scale_colour_viridis_c()+ 
  theme_void()

# plot roosts with colour as date
ggmap(map_z15)+
  geom_sf(data = distance_roosts_latlon, aes(colour = date), inherit.aes = FALSE)+
  scale_colour_viridis_c(trans = "date")+
  theme_void()
```

There is a day Nutmeg seems to have spent 3km away from their previous roost. IS that true? Investigate this outlier.

```{r}
# Read in cleaned data 
nutmeg <- read.csv("data/data_cleaned.csv") %>%
  # select only Nutmeg
  filter(id == "Nutmeg") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne")) 

# Plot
ggmap(map_z13)+
  geom_point(data=nutmeg, aes(longitude, latitude, colour = date), alpha = 0.8)+
  scale_colour_viridis_c()+
  geom_path(data=nutmeg, aes(longitude, latitude), colour = "white", alpha = 0.4)+
  theme_void()
```

Yep that looks true! On 5-11-23, Nutmeg goes on a flight to the west of the sanctuary, stays over the day near the quarry, then returns to the sanctuary the next day. 

Points outside of fence?

```{r}
# Convert df to points
points <- vect(distance_roosts_latlon)

# Find points outside polygons
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside polygon 
ggmap(map_z15)+
  geom_point(data=outside, aes(x, y, colour = id), alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_d()+
  theme_void()
```

One real roost outside (Nutmeg's adventure as above) and 5 where birds were just roosting close to the fence. This is fine. 

Save output.

```{r}
# convert geometry to regular columns to save to disk
distance_roosts2 <- distance_roosts_latlon %>%
  st_drop_geometry() %>%
  mutate(longitude = st_coordinates(distance_roosts_latlon$geometry)[,1],
         latitude = st_coordinates(distance_roosts_latlon$geometry)[,2])

# plot on map without the far nutmeg point
ggmap(map_z15)+
  geom_path(data = filter(distance_roosts2, distance_previous<2000),
          aes(longitude, latitude, group = id), colour = "white", alpha = 0.6, inherit.aes = FALSE)+
    geom_point(data = filter(distance_roosts2, distance_previous<2000),
          aes(longitude, latitude, colour = distance_previous), inherit.aes = FALSE)+
  scale_colour_viridis_c()+
  theme_void()

# write to file
write.csv(distance_roosts2, "results/daily_distance_between_roosts.csv", row.names = FALSE)
```

## Release site fidelity

How far did they move from the release location? Based on daily roost distance from release location.

Calculate distance from daily roost to release location. 

Release location utm:(274423.45, 5801912.85) 
Release location lat/lon:(-37.902374, 144.434323)

```{r}
# read in roost locations, format as spatial
roosts <- read.csv("data/daily_roost_location.csv") %>%
  dplyr::select(!"npoints") %>%
  vect(geom = c("easting", "northing"), crs = "EPSG:32755") %>%
  st_as_sf()

# release coords as spatial
release  <- st_sfc(st_point(c(274423.45, 5801912.85) ), crs = 32755)

# calculate distance between roosts and release site
dist <- roosts %>%
  mutate(dist_release = as.numeric(st_distance(release, roosts))) %>%
  # keep max distance per day
  group_by(date, id) %>%
  filter(dist_release == max(dist_release)) %>%
  ungroup() %>%
  # add cohort information
  left_join(dplyr::select(metadata, c("cohort", "id"))) %>%
  # format date as a date
  mutate(date = as_date(date)) %>%
  # arrange by date
  arrange(date) %>%
  # drop geometry
  st_drop_geometry()

# save to file
write.csv(dist, "results/daily_roost_distance_from_release.csv", row.names = FALSE)
```

## Home range

Home range change is another way to investigate post-release behavioural modification. Previous studies have demonstrated decreasing home ranges over time as individuals first explore their new surrounds and then settle on a core area of exploitation. We define home range as 50% kernel utilisation distribution, with both nocturnal and diurnal fixes.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne"))%>%
  filter(!id %in% c("Wobbles", "Star"))

# set up data in spatial points dataframe
locs <- SpatialPointsDataFrame(coordinates(
  cbind(data$easting, data$northing)), data = data)

# home range polygon per bird per day 🐢🐢 2.5 hours
birds <- as.character(unique(data$id))
days <- unique(locs[["date"]])

hr_daily <- data.frame()

for (i in 1:length(birds)){
  for (j in 1:length(days)){
    points <- subset(locs, id == birds[i] & date == days[j],
                     select = id)
    if (length(points)<5){
      next
    }
    kud <- kernelUD(points[,1], h="href", grid=1000, extent = 4) %>% 
      getverticeshr(percent = 50)
    
    proj4string(kud) <- CRS("EPSG:32755")
    
    kud_df_utm <- st_as_sf(kud)%>%
      mutate(date = days[j])
    
    print(head(kud_df_utm, n= 1L))
    
    hr_daily <- rbind.data.frame(hr_daily, kud_df_utm)
  }}

# extract area per day i.e. drop geometry
hr_area <- st_drop_geometry(hr_daily)

# save to file
write.csv(hr_area, "results/daily_hr_area.csv", row.names = TRUE)
```

## Time budget HMM

Time budget can be another indicator of post-release behavioural modification. We expect them to become more efficient with their foraging over time as they learn where to find and exploit resources. So we expect to see more direct travel and less time spent foraging over time. 

How do they allocate their nocturnal movement? Hidden markov model.

```{r}
# read in cleaned night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # drop columns notneeded
  dplyr::select(!c(sunrise, sunset, suntime, tod)) %>%
  # format date time in posixct
  mutate(time_local = as.POSIXct(time_local),
         date_bird = as_date(date_bird))

# prep data for moveHMM
data_hmm <- data_night %>%
  prepData(type = "UTM", coordNames = c("easting", "northing"),
           covNames = c("acceleration_raw_x", "acceleration_raw_y", "acceleration_raw_z", "altitude")) %>%
# add vector of the dynamic body acceleration (VEDBA)
  mutate(vedba = ((sqrt(acceleration_raw_x^2 + acceleration_raw_y^2 + acceleration_raw_x^2))/1000))
```

### Test model

Create a test subset of one bird for one month (Nutmeg in June 2023). Investigate step and angle statistics to help define starting parameters. 

```{r}
# Test subset, Nutmeg 1 month
dates <- seq(as.Date("2023-06-01"), as.Date("2023-07-01"), "days")
test <- filter(data_hmm, id == "Aurora" & date_bird %in% dates)

# format as amt and calculate step lengths
steps <- test %>%
  # format as amt track - add columns as needed
  make_track(.x = x, .y = y, .t = time_local, id = id, date_bird = date_bird)

# check sample rate
summarize_sampling_rate(steps)

# resample track to 5 minutes
track_resample(rate = minutes(5), tolerance = minutes(1))

# step statistics
hist(test$step, xlab = "step", main = "", breaks = 30)
summary(test$step)

# angle statistics
hist(test$angle, breaks = seq(-pi, pi, length = 15), xlab = "angle", main = "")
summary(test$angle)

```

#### Number of states

Compare a three state and four state model to see what performs better.

```{r}

# 3 state model parameters
stepPar <- c(
  10, 60, 200,   # Means
  5, 20, 150,    # Standard deviations 
  0.15, 0, 0.5   # Zero-mass values
)

anglePar <- c(
  0, 0, 0,      # Means
  1.5, 7, 3     # Concentrations
)

# 3 state model
hmm3 <- momentuHMM::fitHMM(data = test, 
               nbStates = 3,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

hmm3
plot(hmm3)

# Step Parameters for 4 States
stepPar <- c(
  10, 60, 150, 300,   # Means 
  5, 15, 100, 150,    # Standard deviations 
  0.1, 0, 0.3, 0.15   # Zero-mass values 
)

# Angle Parameters for 4 States
anglePar <- c(
  0, 0, 0, 0,         # Means 
  1.5, 5, 2, 3        # Concentrations
)

# 4 state model
hmm4 <- momentuHMM::fitHMM(data = test, 
               nbStates = 4,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

hmm4
plot(hmm4)

# compare 3 and 4 state models
AIC(hmm3, hmm4)
```

Prefer the 4 state model both visually and on AIC.

Model      AIC
1  hmm4 19401.37
2  hmm3 19443.89

#### Optimise parameters

Try a range of starting values to optimise parameters.

```{r}
# For reproducibility
set.seed(12345)

# Number of tries with different starting values
niter <- 10

# Save list of fitted models
allm <- list()

# Save list of starting parameters
parameters <- list()

for(i in 1:niter) {
  # Step length mean
  stepMean0 <- runif(4, min = c(5, 50, 100, 200), max = c(50, 150, 300, 400))
  
  # Step length standard deviation
  stepSD0 <- runif(4, min = c(5, 30, 50, 100), max = c(30, 100, 150, 200))
  
  # Zero mass
  zeroMass0 <- runif(4, min = c(0.5, 0.05, 0.01, 0.2), max = c(0.9, 0.3, 0.1, 0.3))
  
  # Turning angle mean
  angleMean0 <- c(0, 0, 0, 0)
  
  # Turning angle concentration
  angleCon0 <- runif(4, min = c(0.5, 3, 5, 3), max = c(3, 10, 15, 10))
  
  # Parameter table
  parameters[[i]] <- data.frame(
    state = rep(1:4),
    stepMean0 = stepMean0,
    stepSD0 = stepSD0,
    zeroMass0 = zeroMass0,
    angleMean0 = angleMean0,
    angleCon0 = angleCon0
  )
  
  # Fit model
  stepPar0 <- c(stepMean0, stepSD0, zeroMass0)
  anglePar0 <- c(angleMean0, angleCon0)
  
  allm[[i]] <- tryCatch({
    momentuHMM::fitHMM(
      data = test,
      nbStates = 4,
      dist = list(step = "gamma", angle = "vm"),
      Par0 = list(step = stepPar0, angle = anglePar0),
      estAngleMean = list(angle = TRUE),
      formula = ~vedba
    )
  }, error = function(e) NULL)
}

# Extract likelihoods of fitted models
allnllk <- unlist(lapply(allm, function(m) m$mod$minimum))

# Index of best fitting model (smallest negative log-likelihood)
whichbest <- which.min(allnllk)

# Best fitting model
mbest <- allm[[whichbest]]
mbest
plot(mbest)
plotStates(mbest)

# Best starting parameters 
pbest_start <- parameters[[whichbest]]

# Best outcome parameters
pbest_outcome <- mbest$mle
```

Best outcome parameters:

$step
           state 1    state 2     state 3     state 4
mean     7.2211441 28.7419041 93.49649922 253.7447067
sd       5.6455927 23.2401216 53.89146576 312.9671872
zeromass 0.1559012  0.1669094  0.01833069   0.2101607

$angle
                state 1    state 2    state 3   state 4
mean          0.1170206 -0.1668971 0.02669791 0.2645331
concentration 1.1835577  1.3724136 2.71667136 1.9204624

$beta
               1 -> 2    1 -> 3    1 -> 4    2 -> 1     2 -> 3    2 -> 4
(Intercept) -5.204991 -8.829121 -2.213485 -6.221311 -10.254742 -4.297407
vedba        6.313020 -3.078513 -1.617744  5.398456  -4.197239  4.724587
               3 -> 1    3 -> 2     3 -> 4    4 -> 1    4 -> 2    4 -> 3
(Intercept) -8.220560 -2.225103  0.4526661 -2.324431 -0.453848  1.538068
vedba       -3.345948  1.189772 -2.1410536  1.063941  1.259101 -3.388000

$delta
               state 1   state 2      state 3      state 4
ID:Nutmeg 0.0004158271 0.9993644 5.228222e-05 0.0001674458

### Run HMM

Apply best parameters for a 4 state model to all birds.

```{r}
# Step Parameters 
stepPar <- c(
  7, 29, 93, 253,   # Means
  6, 23, 54, 313,    # Standard deviations 
  0.16, 0.17, 0.02, 0.21   # Zero-mass values 
)

# Angle Parameters for 4 States
anglePar <- c(
  0.11, -0.17, 0.03, 0.26,         # Means 
  1.18, 1.37, 2.72, 1.92        # Concentrations
)

# 4 state model (approx. 7 hours to run) 🐢🐢
hmm_all <- momentuHMM::fitHMM(data = data_hmm, 
               nbStates = 4,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

# see states
hmm_all

# plot results
plot(hmm_all)

# check residuals
plotPR(hmm_all)

# Decode states
data_hmm2 <- data_hmm %>%
  mutate(states = viterbi(hmm_all))

# save output
write.csv(data_hmm2, "data/data_hmm.csv", row.names = FALSE)

```

$step
$step$est
           state 1    state 2    state 3     state 4
mean     8.2208094 20.3895440 57.8629585 129.4745424
sd       6.6718586 17.2595917 33.1696834 142.4877739
zeromass 0.1835534  0.1435767  0.1017199   0.1056076

$step$se
             state 1     state 2     state 3    state 4
mean     0.059195569 0.158752114 0.504588470 1.62585187
sd       0.059392166 0.135826249 0.350108882 1.68770684
zeromass 0.001644487 0.001121659 0.002745764 0.00326152

$step$lower
           state 1    state 2     state 3      state 4
mean     8.1047882 20.0783956 56.87398323 126.28793127
sd       6.5554521 16.9933771 32.48348260 139.17992928
zeromass 0.1803303  0.1413783  0.09633832   0.09921516

$step$upper
           state 1    state 2    state 3     state 4
mean     8.3368306 20.7006924 58.8519337 132.6611535
sd       6.7882651 17.5258063 33.8558842 145.7956185
zeromass 0.1867766  0.1457751  0.1071015   0.1120001


$angle
$angle$est
                    state 1     state 2     state 3    state 4
mean          -0.0006350116 -0.02490599 0.005901283 0.02889899
concentration  0.9849618919  1.34078324 2.855987790 1.62310950

$angle$se
                  state 1     state 2     state 3    state 4
mean          0.008772497 0.004360951 0.005746417 0.01000978
concentration 0.009074356 0.008098515 0.040103562 0.01989011

$angle$lower
                  state 1    state 2      state 3     state 4
mean          -0.01782879 -0.0334533 -0.005361488 0.009280183
concentration  0.96717648  1.3249104  2.777386254 1.584125600

$angle$upper
                 state 1     state 2    state 3    state 4
mean          0.01655877 -0.01635868 0.01716405 0.04851779
concentration 1.00274730  1.35665604 2.93458933 1.66209339


$gamma
$gamma$est
            state 1    state 2      state 3    state 4
state 1 0.931458331 0.05761075 2.899808e-05 0.01090192
state 2 0.025798292 0.89292770 4.665911e-02 0.03461490
state 3 0.002059385 0.20857863 7.299991e-01 0.05936288
state 4 0.036632497 0.16340398 1.137106e-01 0.68625289

$gamma$se
            state 1     state 2     state 3      state 4
state 1 0.001852868 0.001856780         NaN 0.0009593681
state 2 0.001035936 0.001734979 0.001537815 0.0010952092
state 3 0.001406860 0.004757413 0.005098452 0.0034170704
state 4 0.002882481 0.006547791 0.005798381 0.0077365855

$gamma$lower
            state 1    state 2    state 3     state 4
state 1 0.927736437 0.05407762        NaN 0.009173398
state 2 0.023843831 0.88947937 0.04373596 0.032531334
state 3 0.000539143 0.19940768 0.71989062 0.053008962
state 4 0.031383508 0.15097250 0.10283144 0.670894349

$gamma$upper
            state 1    state 2    state 3    state 4
state 1 0.935001961 0.06135974        NaN 0.01295190
state 2 0.027908379 0.89628098 0.04976747 0.03682684
state 3 0.007832716 0.21805649 0.73987462 0.06642498
state 4 0.042720676 0.17664613 0.12557970 0.70121389

### Time budget

```{r}
# read in data with hmm states
data_hmm <- read.csv("data/data_hmm.csv")

# calculate proportion of fixes in each state per bird per day
budget_daily <- data_hmm %>%
  group_by(ID, date_bird) %>%
  # count of states
  count(states) %>%
  # pivot to wide format
  pivot_wider(names_from = 3, values_from = 4) %>%
  # rename state columns
  rename(state1 = 3,
         state2 = 4,
         state3 = 5,
         state4 = 6) %>%
  # replace NAs with zeros
  replace(is.na(.), 0) %>%
  # calculate proportion
  mutate(total = sum(state1, state2, state3, state4),
         state1p = state1/total,
         state2p = state2/total,
         state3p = state3/total,
         state4p = state4/total) %>%
  arrange(date_bird) %>%
  # rename ID
  rename(id = ID)

# save to file
write.csv(budget_daily, "results/daily_time_budget.csv", row.names = FALSE)

# summarise over time
budget <- budget_daily %>%
  # calculate mean and sd
  group_by(id) %>%
  summarise(s1m = mean(state1p),
            s2m = mean(state2p),
            s3m = mean(state3p),
            s4m = mean(state4p)) %>%
  pivot_longer(2:5, names_to = "state", values_to = "budget") %>%
  # add cohort
  left_join(select(metadata, c(id, cohort)))

# plot time budget mean by bird
ggplot(budget)+
  geom_bar(aes(x = id, y = budget, fill = state), position="fill", stat="identity")+
  theme_minimal()+
  scale_fill_viridis_d()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1))+
  facet_wrap(~cohort, scales="free_x")
```

# Conspecific interactions

The key issue addressed in this paper is whether social interaction occurs between residents and reinforcers, and if so whether this mediates post-release outcomes for the cohorts. 

## Proximity anaysis

First we need to determine interactions. Using GPS tracking data we cannot perfectly capture social interactions, but we can approximate these with proximity (distance and time) analysis. Given we have a large dataset we elected to use contact analysis in wildlifeDI.  

To determine the temporal interaction threshold we use the mean sampling rate.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne")) %>%
  # drop birds excluded from analyses
  filter(!id %in% c("Wobbles", "Star")) %>%
  # drop NAs
  na.omit()

# summarise sampling rate to decide on temporal interaction threshold
steps <- data %>%
  make_track(.x = easting, .y = northing, .t = time_local, id = id) %>%
  nest(data = -"id")

sampling_rates <- steps %>%
  transmute(id, summary = map(data, summarize_sampling_rate)) %>%
  unnest(summary)

mean(sampling_rates$mean)
```

The mean sampling rate for the cleaned data is 8 minutes. We will use a time parameter of 4 minutes (half the sampling interval) following advice from the wildlifeDI package vignette. 

First format tracks as move2 objects for use in wildlifeDI.

```{r}
# format track data as move2 object
move <- mt_as_move2(data, coords = c("easting", "northing"), time_column = "time_local", track_id_column = "id") %>%
  # add crs
  sf::st_set_crs("EPSG:32755") %>%
  # needed to omit NAs for conProcess to work
  na.omit()
```

We use a dcPlot of paired encounters across distance to approximate the distance threshold (using a subset to reduce processing time).

Our expert guesstimate was a threshold of 30m (based on visual observation of interactions between individuals in the field during monitoring). 

```{r}
# one week subset
temp <- seq.Date(from = as_date("2023-06-01"), to = as_date("2023-06-07"), by = "day")
move_subset <- filter(move, date %in% temp)

# plot distribution of paired fixes by distance
dcPlot(move_subset,tc=4*60,dmax=500)
dcPlot(move_subset,tc=4*60,dmax=100)
```

The majority of contacts took place <40m apart. I'll retain the expert guesstimate of 30m as the parameter. This is also within tolerance for the approximate GPS uncertainty of 20m (on cleaned data).

```{r}
# calculate proximity contact events 🐢🐢🐢 ran overnight 
contacts <- conProcess(move,dc=30,tc=4*60)

# ratio of contact to non-contact events 
table(contacts$contact)
```

A total of 349409  contacts have been identified in the track, that is 47% of fixes

Next we find periods of continuous contact and calculate some summary statistics about these interactions.

```{r}
# find periods of continous interaction, defined as within 1 hour
contact_period <- conPhase(contacts, pc=60*60)

# calculate summary statistics about interaction durations
contact_summary <- contact_period %>%
  sf::st_drop_geometry() %>%
  filter(!is.na(contact_pha)) %>%
  group_by(contact_pha) %>%
  summarise(nfix = n(),
            t1 = min(time_local),
            t2 = max(time_local),
            duration = as.numeric(
              difftime(max(time_local), min(time_local), units = "mins")),
            avg_d = mean(contact_d,na.rm=T),
            min_d = min(contact_d,na.rm=T),
            max_d = max(contact_d,na.rm=T))

# histogram contact distances
hist(contact_summary$avg_d)

# histogram contact durations
hist(contact_summary$duration)

# histogram number of contacts
hist(contacts$contact_n)
```

15m seems to be the average distance of an interaction - which makes me confident in the distance parameter of 30m. 

Most interactions were 0-8 hours.The longest interaction was 70 hours!

Format and save.

```{r}
# geometry to columns
contact2 <- contact_period %>%
  mutate(easting = sf::st_coordinates(.)[,1],
         northing = sf::st_coordinates(.)[,2]) %>%
  # drop geometry
  sf::st_drop_geometry() %>%
  # as data frame
  as.data.frame()

# save output
write.csv(contact2, "data/contact_events.csv", row.names = FALSE)
```

## Social network
  
We investigate social networks for 2 time periods:

  1) Residents only
  2) Residents and reinforcers
  
Read in tracking data with contacts columns. 

```{r}
# read in contact data
data <- read.csv("data/contact_events.csv") %>% 
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne"))
```
  
### Residents only

We define this as the period from the last resident released (2023-01-16) to the first reinforcer released (2023-06-07). 

```{r}
# define resident only date period
res_dates <- seq.Date(from = as_date("2023-01-16"), to = as_date("2023-06-06"), by = "day")

# subset to dates
data_resident <- data %>%
  filter(date %in% res_dates)
```

Create matrix of interactions. 

```{r}
# interaction list
res <- data_resident %>%
  select(c(id, contact_id, contact)) %>%
  group_by(id, contact_id) %>%
  summarise(contacts = sum(contact)) %>%
  # remove NAs
  na.omit() 

# summary statistics of contacts
hist(res$contacts)
mean(res$contacts)
sd(res$contacts)

# convert interaction to matrix
res <- res %>%
  # add first bird to first bird comparison 
  rbind(data.frame(id = "Aurora", contact_id = "Aurora", contacts = 0)) %>%
  # pivot to wide matrix
  pivot_wider(names_from = contact_id, values_from = contacts, values_fill = 0) %>%
  # convert bird id to row name labels
  column_to_rownames("id") %>%
  # move last column (from rbind) first
  relocate(Aurora) %>%
  # matrix
  as.matrix()
```

Plot social network using igraph. 

```{r}
# set seed to keep igraph layout static
set.seed(10) 

# edge network from interaction matrix
res_graph <- graph_from_adjacency_matrix(res, mode = "undirected", diag = FALSE, weighted = TRUE)

# plot with weighted edges
plot(res_graph, edge.width = E(res_graph)$weight/1000)

# calculate edge density i.e. number of observed edges against possible edges
edge_density(res_graph)

# calculate degree centrality i.e. number of edges
de <- degree(res_graph)

# plot with weighted edges and vary node size by degree centrality
plot(res_graph, edge.width = E(res_graph)$weight/1000, vertex.size=de*2)

# calculate node strength i.e. the sum of the weights of edges connected to the node
ns <- strength(res_graph)

# plot with weighted edges and vary node size by node strength
plot(res_graph, edge.width = E(res_graph)$weight/1000, vertex.size=ns/500)

# calculate betweeness (indicator a node is influential in a network)
b <- betweenness(res_graph)

# plot with weighted edges and vary node size by betweeness
plot(res_graph, edge.width = E(res_graph)$weight/1000, vertex.size=b)
```

Opting for a walktrap community clustering method because it is weighted data, we expect hierachical, and it is a small dense community.

```{r}
# detect communities
comm <- cluster_walktrap(res_graph)
length(comm)
dendPlot(comm)
modularity(comm)

# plot communities
plot(res_graph, vertex.color=membership(comm), edge.width = E(res_graph)$weight/1000)
```

The network density is 87%. The network is continuous but has three communities (modularity 0.430). This aligns with my observation of the birds from the tracking data.

### Residents and reinforcers

We define this as the period from the last reinforcer released (2023-06-11) to the end of the study period (2024-01-10). 

```{r}
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2024-01-10"), by = "day")

# subset to dates
data_reinforce <- data %>%
  filter(date %in% rein_dates)
```

Create matrix of interactions. 

```{r}
# interaction list
rein <- data_reinforce %>%
  select(c(id, contact_id, contact)) %>%
  group_by(id, contact_id) %>%
  summarise(contacts = sum(contact)) %>%
  # remove NAs
  na.omit() 

# summary statistics of contacts
hist(rein$contacts)
mean(rein$contacts)
sd(rein$contacts)

# convert interaction to matrix
rein <- rein %>%
  # add first bird to first bird comparison 
  rbind(data.frame(id = "Athena", contact_id = "Athena", contacts = 0)) %>%
  # pivot to wide matrix
  pivot_wider(names_from = contact_id, values_from = contacts, values_fill = 0) %>%
  # convert bird id to row name labels
  column_to_rownames("id") %>%
  # move last column (from rbind) first
  relocate(Athena) %>%
  # matrix
  as.matrix()
```

Plot social network using igraph. 

```{r}
# edge network from interaction matrix
rein_graph <- graph_from_adjacency_matrix(rein, mode = "undirected", diag = FALSE, weighted = TRUE)

# add cohort metadata
v <- data.frame(id = row.names(rein)) %>% left_join(select(metadata, c(id, cohort)))

V(rein_graph)$cohort <- v[match(V(rein_graph)$name, v$id), "cohort"]

# set node shape by cohort
V(rein_graph)[V(rein_graph)$cohort == "Reinforcing"]$shape <- "square"
V(rein_graph)[V(rein_graph)$cohort == "Resident"]$shape <- "circle"

# plot with weighted edges and colour by cohort
plot(rein_graph, edge.width = E(rein_graph)$weight/100)

# detect communities
comm <- cluster_walktrap(rein_graph)
length(comm)
modularity(comm)
dendPlot(comm)

# plot communities
plot(rein_graph, vertex.color=membership(comm), edge.width = E(rein_graph)$weight/200)
```

Modularity scores for different cluster methods:

  * edge betweeness: 0.087
  * walktrap: 0.263
  * fast greedy: 0.263
  * optimal: 0.263
  
Next we calculate individual statistics for level of social integration and contribution.

```{r}
# calculate individual metrics
metrics <- data.frame(weighted_edges = strength(rein_graph, mode = "all")) %>%
  rownames_to_column(var = "id") %>%
  cbind(closeness = as.numeric(closeness(rein_graph, normalized = TRUE))) %>%
  cbind(eigenvector = as.numeric(eigen_centrality(rein_graph)$vector))

# save to file
write.csv(metrics, "results/social_metrics.csv", row.names = FALSE)
```

# Statistical analysis

## Comparison residents and reinforcers for establishment period

All comparisons were made for the first 55 days post-release, since this is the lowest common denominator of duration tracked for the reinforcing cohort.

### m1: Distance moved

Is there a difference between residents and reinforcers in their distance moved?

```{r}
# read in data and filter to establishment period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort", "start_date"))) %>%
  # format dates as dates
  mutate(date_bird = as_date(date_bird),
         start_date = as_date(start_date)) %>%
  # calculate time since release
  mutate(elapsed = as.numeric(date_bird - start_date)) %>%
  # limit to first 55 days 
  filter(elapsed <56) %>%
  # re-level so residents are the reference group for stats
  mutate(cohort = relevel(factor(cohort), ref = "Resident"))

# create cohort means
sum1 <- datam1 %>%
  group_by(elapsed, cohort) %>%
  summarise(daily_dist = mean(daily_dist)) %>%
  arrange(elapsed)

# plot daily distance by cohort
ggplot(datam1)+
  geom_boxplot(aes(cohort,daily_dist))+
  theme_minimal()+
  xlab("Cohort") + 
  ylab("Daily distance moved (m)")

# plot daily distance over time as cohort means
ggplot(sum1)+
  geom_path(aes(elapsed, daily_dist, color = cohort))+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Daily distance moved (m)")

# plot daily distance over time as linear model
ggplot(datam1)+
  geom_smooth(aes(elapsed, daily_dist, color = cohort), method = "lm")+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Daily distance moved (m)")
```

I expected to see an initial spike in movement followed by a decrease, indicating an acclimation period - like seen in previous studies of bighorn sheep. But instead we found a gradual increase over time post-release for both groups.

```{r}
# distribution of movement data
hist(datam1$daily_dist)
ggqqplot(datam1$daily_dist)

# correct left skew
hist(sqrt(datam1$daily_dist))
ggqqplot(sqrt(datam1$daily_dist))

# test whether establishment differs between the groups
m1 <- lmer(sqrt(daily_dist) ~ cohort * elapsed + (1|id), data = datam1)
summary(m1)

# check residuals
hist(residuals(m1))
ggqqplot(residuals(m1))
```

We found significant effects of cohort, elapsed time, and the interaction of these on the daily distance moved. Residents changed their movement more steeply over time than reinforcers.

### m2: Roost establishment

Do the cohorts differ in their roost establishment?

```{r}
# read in data and filter to establishment period
datam2 <- read.csv("results/daily_distance_between_roosts.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort", "start_date"))) %>%
  # format dates as dates
  mutate(date = as_date(date),
         start_date = as_date(start_date)) %>%
  # calculate time since release
  mutate(elapsed = as.numeric(date - start_date)) %>%
  # limit to first 55 days 
  filter(elapsed <56)

# create cohort means
sum2 <- datam2 %>%
  group_by(elapsed, cohort) %>%
  summarise(distance_previous = mean(distance_previous)) %>%
  arrange(elapsed)

# plot daily roost distance by cohort
ggplot(datam2)+
  geom_boxplot(aes(cohort,distance_previous))+
  theme_minimal()+
  xlab("Cohort") + 
  ylab("Daily distance between roosts (m)")

# plot daily roost distance over time as cohort means
ggplot(sum2)+
  geom_path(aes(elapsed, distance_previous, color = cohort))+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Daily distance between roosts (m)")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))

# plot daily roost distance over time as linear model
ggplot(datam2)+
  geom_smooth(aes(elapsed, distance_previous, color = cohort), method = "lm")+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Daily distance between roosts (m)")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))
```

Distance between roosts sites might be the better indication of acclimation than daily distance moved - here we saw the expected initial high movement followed by settling in, which we didn't see for daily distance moved. This takes about 10 days in residents but only 4 in reinforcers. However, after this point the reinforcers maintain higher movement (because of switching between the two roost locations, alternating between the central woodland and the eastern boundary).

```{r}
# distribution of movement data
hist(datam2$distance_previous)
ggqqplot(datam2$distance_previous)

# correct left skew
hist(log(datam2$distance_previous))
ggqqplot(log(datam2$distance_previous))

# test whether establishment differs between the groups
m2 <- lmer(log(distance_previous) ~ cohort * elapsed + (1|id), data = datam2)
summary(m2)

# check residuals
hist(residuals(m2))
ggqqplot(residuals(m2))
```

We found a significant effects of cohort, elapsed time, and the interaction of these on the daily distance between roosts. Both cohorts decreased their movement over time, but residents decreased more steeply than reinforcers (estimate: -0.01104).

### m3: Release site fidelity

Does release site fidelity differ between the cohorts?

```{r}
# read in data and filter to establishment period
datam3 <- read.csv("results/daily_roost_distance_from_release.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort", "start_date"))) %>%
  # format dates as dates
  mutate(date = as_date(date),
         start_date = as_date(start_date)) %>%
  # calculate time since release
  mutate(elapsed = as.numeric(date - start_date)) %>%
  # limit to first 55 days 
  filter(elapsed <56)

# create cohort means
sum3 <- datam3 %>%
  group_by(elapsed, cohort) %>%
  summarise(dist_release = mean(dist_release)) %>%
  arrange(elapsed)

# plot release site distance by cohort
ggplot(datam3)+
  geom_boxplot(aes(cohort,dist_release))+
  theme_minimal()+
  xlab("Cohort") + 
  ylab("Distance from release site (m)")

# plot release site distance over time as cohort means
ggplot(sum3)+
  geom_path(aes(elapsed, dist_release, color = cohort))+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Distance from release site (m)")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))

# plot release site distance over time as linear model
ggplot(datam3)+
  geom_smooth(aes(elapsed, dist_release, color = cohort), method = "lm")+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Distance from release site (m)")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))
```

The reinforcers did not move as far from the release location as the residents, who moved away and stayed away. The reinforcers then gradually increased their distance from the release site.

```{r}
# distribution of movement data
hist(datam3$dist_release)
ggqqplot(datam3$dist_release)

# remove very large outliers from Nutmeg going on a couple day ventures outside
datam3 <- filter(datam3, dist_release <3000)

hist(datam3$dist_release)
ggqqplot(datam3$dist_release)

# correct left skew - still not great but a bit better
hist(sqrt(datam3$dist_release))
ggqqplot(sqrt(datam3$dist_release))

# test whether establishment differs between the groups
m3 <- lmer(sqrt(dist_release) ~ cohort * elapsed + (1|id), data = datam3)
summary(m3)

# check residuals - not as good as m1 and m2 but okay
hist(residuals(m3))
ggqqplot(residuals(m3))
```

Residents exhibit higher initial values for dist_release, but their rate of increase over time is slower than that of the baseline cohort. There is a significant difference between cohorts at time zero (+5.31, p = 0.0282).

The variance for the random intercept (40.76) is more than double the residual variance (16.67). This indicates substantial between-individual variability in dist_release, consistent with a significant contribution of individual differences.

### m4: Home range establishment

Is there a difference between reinforcers and residents in home range size over time?

```{r}
# read in data and filter to establishment period
datam4 <- read.csv("results/daily_hr_area.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort", "start_date"))) %>%
  # format dates as dates
  mutate(date = as_date(date),
         start_date = as_date(start_date)) %>%
  # calculate time since release
  mutate(elapsed = as.numeric(date - start_date)) %>%
  # limit to first 55 days 
  filter(elapsed <56)

# create cohort means
sum4 <- datam4 %>%
  group_by(elapsed, cohort) %>%
  summarise(area = mean(area)) %>%
  arrange(elapsed)

# plot home range size by cohort
ggplot(datam4)+
  geom_boxplot(aes(cohort, area))+
  theme_minimal()+
  xlab("Cohort") + 
  ylab("Home range (50% KUD) area (hectares)")

# plot home range size over time as cohort means
ggplot(sum4)+
  geom_path(aes(elapsed, area, color = cohort))+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Home range (50% KUD) area (hectares)")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))

# plot home range size over time as linear model
ggplot(datam4)+
  geom_smooth(aes(elapsed, area, color = cohort), method = "lm")+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Home range (50% KUD) area (hectares)")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))
```

Reinforcers initially have much large home ranges (due to the shuttle between the central woodland and the eastern fence line) than the residents, before picking a core roost.

```{r}
# distribution of movement data
hist(datam4$area)
ggqqplot(datam4$area)

# correct left skew
hist(log(datam4$area))
ggqqplot(log(datam4$area))

# test whether establishment differs between the groups
m4 <- lmer(log(area) ~ cohort * elapsed + (1|id), data = datam4)
summary(m4)

# check residuals
hist(residuals(m4))
ggqqplot(residuals(m4))
```

Resident home ranges during establishment are significantly smaller than reinforcers. Residents show an increase in area over time relative to reinforcers, even though the main effect of elapsed is non-significant.

The divergent trend suggests differences in spatial behavior over time between the cohorts.

Limited between-individual differences in baseline log-area compared to within-individual variation.

### m5: Time budget

Do cohorts vary in their time budget during establishment?

```{r}
# read in data and filter to establishment period
datam5 <- read.csv("results/daily_time_budget.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort", "start_date"))) %>%
  # format dates as dates
  mutate(date = as_date(date_bird),
         start_date = as_date(start_date)) %>%
  # calculate time since release
  mutate(elapsed = as.numeric(date - start_date)) %>%
  # limit to first 55 days 
  filter(elapsed <56)

# create cohort means
sum5 <- datam5 %>%
  group_by(elapsed, cohort) %>%
  summarise(state1p = mean(state1p),
            state2p = mean(state2p),
            state3p = mean(state3p),
            state4p = mean(state4p)) %>%
  arrange(elapsed)

# plot state 2 allocation over time as cohort means
ggplot(sum5)+
  geom_path(aes(elapsed, state2p, color = cohort))+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Allocation of time to foraging effort")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))

# plot state 2 allocationover time as linear model
ggplot(datam5)+
  geom_smooth(aes(elapsed, state2p, color = cohort), method = "lm")+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Allocation of time to foraging effort")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))
```

Reinforcers start with a higher allocation of time investment in state 2 (foraging), but the groups converge on the same allocation by the end of the establishment period.

Time budget is bounded as 0-1 so we use glmmTMB to do a beta distrubtion with a logit link.

```{r}
# distribution of state data - right skewed but log/sqrt didn't help
hist(datam5$state2p)
ggqqplot(datam5$state2p)

# add a small constant to the handful of 0s and 1s
datam5 <- datam5 %>%
  mutate(state2AD = (datam5$state2p + 0.001) / 1.002)

# test whether state 2 allocation differs between the groups
m5 <- glmmTMB(state2AD ~ cohort * elapsed, data = datam5,
               family = beta_family(link = "logit"))
summary(m5)

# check residuals
hist(residuals(m4))
ggqqplot(residuals(m4))
```

Significant effects of cohort and cohort*time. The effect of elapsed time depends on the cohort, with residents increasing more over time than reinforcers.

## Comparison by social group for reinforcement period

We hypothesised members of the mixed resident-reinforcer social group would proceed more quickly through the PRBM phases than those in the reinforcer only group. I also want to compare both reinforcer groups to the residents to see if one is more simialar than the other (noting this is now for the reinforcement time period, rather than the establishment periods as done in models1-5; i.e. now comparing at the same dates, rather than different dates but same elapsed time post-release).

```{r}
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")

# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2024-01-10"), by = "day")
```

### m6: Distance moved

```{r}
# read in data and filter to reinforcement period
datam6 <- read.csv("results/daily_distance_moved.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date_bird)) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "exclusive", ifelse(cohort == "Resident", "mixed-resident", "mixed-reinforcer"))) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates)

# create social group means
sum6 <- datam6 %>%
  group_by(date, social) %>%
  summarise(daily_dist = mean(daily_dist)) %>%
  arrange(date)

# plot daily distance by social group
ggplot(datam6)+
  geom_boxplot(aes(social,daily_dist))+
  theme_minimal()+
  xlab("Social group") + 
  ylab("Daily distance moved (m)")

# plot daily distance over time as social group means
ggplot(sum6)+
  geom_path(aes(date, daily_dist, color = social))+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Daily distance moved (m)")

# plot daily distance over time as linear model
ggplot(datam6)+
  geom_smooth(aes(date, daily_dist, color = social), method = "lm")+
  theme_minimal() +
  xlab("Days post-release") + 
  ylab("Daily distance moved (m)")
```

Very slight difference in the positive trend over time, with residents highest, followed by mixed-reinforcers and then exclusive-reinforcers.

```{r}
# distribution of movement data
hist(datam6$daily_dist)
ggqqplot(datam6$daily_dist)

# correct left skew
hist(sqrt(datam6$daily_dist))
ggqqplot(sqrt(datam6$daily_dist))

# test whether establishment differs between the groups
m6 <- lmer(sqrt(daily_dist) ~ social * scale(date) + (1|id), data = datam6)
summary(m6)
emmeans(m6, pairwise ~ social, adjust = "tukey", type = "response")

# check residuals
hist(residuals(m6))
ggqqplot(residuals(m6))
```

The effect of time on distance traveled differs between the social conditions. However, overall no significant difference between social groups.

### m7: Roost establishment

```{r}
# read in data and filter to reinforcement period
datam7 <- read.csv("results/daily_distance_between_roosts.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "exclusive", ifelse(cohort == "Resident", "mixed-resident", "mixed-reinforcer"))) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates)

# create cohort means
sum7 <- datam7 %>%
  group_by(date, social) %>%
  summarise(distance_previous = mean(distance_previous)) %>%
  arrange(date)

# plot daily roost distance by social group
ggplot(datam7)+
  geom_boxplot(aes(social,distance_previous))+
  theme_minimal()+
  xlab("Social group") + 
  ylab("Daily distance between roosts (m)")

# plot daily roost distance over time as social group means
ggplot(sum7)+
  geom_path(aes(date, distance_previous, color = social))+
  theme_minimal() +
  xlab("Date") + 
  ylab("Daily distance between roosts (m)")

# plot daily roost distance over time as linear model
ggplot(datam7)+
  geom_smooth(aes(date, distance_previous, color = social), method = "lm")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Daily distance between roosts (m)")
```

The mixed group converges with the residents, whereas the exclusive group continues to increase.

```{r}
# distribution of movement data
hist(datam7$distance_previous)
ggqqplot(datam7$distance_previous)

# correct left skew
hist(log(datam7$distance_previous))
ggqqplot(log(datam7$distance_previous))

# test whether establishment differs between the groups
m7 <- lmer(log(distance_previous) ~ social * scale(date) + (1|id), data = datam7)
summary(m7)
emmeans(m7, pairwise ~ social, adjust = "tukey", type = "response")

# check residuals
hist(residuals(m7))
ggqqplot(residuals(m7))
```

Both mixed-reinforcer and mixed-resident groups exhibit lower roost displacements compared to the exclusive group. The magnitude of the effect is more pronounced in the mixed-resident group, but both comparisons are statistically significant.

### m8: Release site fidelity

Does release site fidelity differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam8 <- read.csv("results/daily_roost_distance_from_release.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "exclusive", ifelse(cohort == "Resident", "mixed-resident", "mixed-reinforcer"))) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates)

# create cohort means
sum8 <- datam8 %>%
  group_by(date, social) %>%
  summarise(dist_release = mean(dist_release)) %>%
  arrange(date)

# plot release site distance by social group
ggplot(datam8)+
  geom_boxplot(aes(social, dist_release))+
  theme_minimal()+
  xlab("Social group") + 
  ylab("Distance from release site (m)")

# plot release site distance over time as social group means
ggplot(sum8)+
  geom_path(aes(date, dist_release, color = social))+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance from release site (m)")

# plot release site distance over time as linear model
ggplot(datam8)+
  geom_smooth(aes(date, dist_release, color = social), method = "lm")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance from release site (m)")
```

The reinforcers in the mixed group stayed similarly close to the release site as the residents (who were occupying an area of the woodland near the release site when the reinforcement translocation occurred), whereas the exclusive group left the area.

```{r}
# distribution of movement data
hist(datam8$dist_release)
ggqqplot(datam8$dist_release)

# correct left skew - still not great but a bit better
hist(sqrt(datam8$dist_release))
ggqqplot(sqrt(datam8$dist_release))

# test whether establishment differs between the social groups
m8 <- lmer(sqrt(dist_release) ~ social * scale(date) + (1|id), data = datam8)
summary(m8)
emmeans(m8, pairwise ~ social, adjust = "tukey", type = "response")

# check residuals
hist(residuals(m8))
ggqqplot(residuals(m8))
```

Both mixed-reinforcer and mixed-resident groups have significantly lower dist_release compared to the exclusive group.

Significant negative interactions between social group and date for both mixed-reinforcer (-3.0415, p < 0.00001) and mixed-resident (-2.6524, p < 0.00001) groups, indicating that the increase in dist_release over time is less pronounced for these groups compared to the exclusive group.

## Effect on residents pre- and post-reinforcement

# Survival analysis

## Reinforcers and residents

Do reinforcers survive better than the residents? 

This is hard to answer because not tracked as long and some birds were subsequently moved to Orana (right censored data). Attempt to answer this using Kaplan Meier Analysis

Start by looking at the overall survival probabilities for all birds.

```{r m6}
# Format data for Kaplan Meier Analysis - where death is TRUE i.e. 1
surv_data <- metadata %>%
  # remove columns not needed
  dplyr::select(!c(location, abbbs, band, alive, release_year)) %>%
  # add survival time (persistence) - right censored data
  mutate(time = end_date - start_date) %>%
  # add status - whether death occurs
  mutate(status = ifelse(is.na(mortality), 0, 1))

km <- with(surv_data, Surv(time, status))
  
# Fit a basic survival model
kmfit <- survfit(Surv(time, status) ~ 1, data = surv_data)

# Estimated survival probabilities
summary(kmfit, times = c(1, 10, 30, 54, 100, 365))

# plot
autoplot(kmfit)
```

The probability of survival to 1 year is 53% (upper CI = 79%, lower CI = 36%). 

The probability of survival to 54 days (the study period) is 91% (upper CI = 100%, lower CI = 83%).

Now compare cohorts

```{r}
# Fit a survival model by cohort
kmfit_cohort <- survfit(Surv(time, status) ~ cohort, data = surv_data)

summary(kmfit_cohort, times = c(1,30,54))

# plot
autoplot(kmfit_cohort)

# Fit Cox Model
cox <- coxph(Surv(time, status) ~ cohort, data = surv_data)
summary(cox)
```

The probability of survival to 54 days for residents is 87% (upper CI = 79%, lower CI = 71%). 

The probability of survival to 54 days for reinforcers is 95% (upper CI = 79%, lower CI = 86%). 

So reinforcers are slightly more likely to survive, however this effect is not significant (p=0.754). There were two disease events (one in each cohort) that accounted for most of the early deaths. Potentially the stress of translocation caused these individuals to succumb to illness. 

## Reinforcers by social group

During the social analysis step we found that post-reinforcement there were two sub-groups to the community:

  1) a group with just reinforcers, and 
  2) a blended group of all remaining residents and half the reinforcers.
  
I hypothesise the group with the residents would survive better because of the enhanced potential for learning. 

Compare to 55 days (minimum common denominator deployment period for reinforcers).

```{r}
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")

# Format data for Kaplan Meier Analysis - where death is TRUE i.e. 1
surv_data <- metadata %>%
  # remove columns not needed
  dplyr::select(!c(location, abbbs, band, alive, release_year)) %>%
  # add survival time (persistence) - right censored data
  mutate(time = end_date - start_date) %>%
  # add status - whether death occurs
  mutate(status = ifelse(is.na(mortality), 0, 1)) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "exclusive", "mixed")) %>%
  # select only reinforcers
  filter(cohort == "Reinforcing")

# Fit a survival model by social group
kmfit_social <- survfit(Surv(time, status) ~ social, data = surv_data)

summary(kmfit_social, times = c(1,30,54))

# plot
autoplot(kmfit_social)

# Fit Cox Model
cox <- coxph(Surv(time, status) ~ social, data = surv_data)
summary(cox)
```

No difference in survival for reinforcers of different social memberships.
