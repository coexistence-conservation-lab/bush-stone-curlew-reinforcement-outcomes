---
title: "bsc_reinforcement_analyses"
author: "Shoshana Rapley"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)

# Packages
pacman::p_load(adehabitatHR, amt, atlastools, beepr, effects, emmeans, ggeffects, ggfortify, ggmap, ggnewscale, ggforce, ggpubr, ggraph, ggridges, ggspatial, glmmTMB, gtools, igraph, janitor, jtools, lme4, lmerTest, move2, momentuHMM, MuMIn, performance, plotrix, readxl, scales, scattermore, sf, sjPlot, sp, suncalc, survival, survminer, terra, tidygraph, tidyterra, tidyverse, viridis, wildlifeDI)

# Google API key for ggmaps
ggmap::register_google(key = readChar("apikey_google.txt", nchars = file.info("apikey_google.txt")$size))

# Background map MR zones 1 and 2
map_z14 <- get_map(c(144.4380, -37.9000), zoom=14, maptype = "satellite")
map_z15 <- get_map(c(144.4380, -37.9000), zoom=15, maptype = "satellite")

# Metadata - translocation information
metadata  <- read.csv("data/metadata.csv") %>%
  clean_names() %>%
  rename(id = identity,
         mortality = mortality_or_capture) %>%
  mutate(start_date = as_date(dmy(start_date)),
         end_date = as_date(dmy(end_date)),
         mortality = as_date(dmy(mortality)))

# Define fence polygons (zones 1 and 2)
mtr <- rbind(
  ## zone 1
  c(-37.897319, 144.429048), # S end of NW diagonal
  c(-37.894066, 144.432334), # N end of NW diagonal, i.e. NW corner
  c(-37.894749, 144.438305), # bend at main gate 
  c(-37.894693, 144.438324), # main gate
  c(-37.894803, 144.439214), # bend before N Z1/2 gate
  c(-37.894718, 144.439337), # N Z1/2 gate, i.e. NE corner 
  ## zone 2
  c(-37.892433, 144.440236), # N boundary internal aviary/Z2 i.e. NW corner
  c(-37.892803, 144.443374), # Z2 northern boundary bend 1
  c(-37.893634, 144.444076), # Z2 northern boundary bend 2
  c(-37.894585, 144.447739), # N end of Z2/Z3 boundary, i.e. NE corner
  c(-37.896515, 144.446789), # Z2/Z3 boundary bend 1
  c(-37.896726, 144.446099), # Z2/Z3 boundary bend 2
  c(-37.897964, 144.445706), # Z2/Z3 boundary bend 3
  c(-37.899960, 144.444517), # S end of Z2/Z3 boundary, i.e. SE corner
  c(-37.899908, 144.444288), # Z2/btrw NE corner
  c(-37.898280, 144.440662), # Z1/btrw pen NW corner
  ## zone 1
  c(-37.900692, 144.440368), # Z1/btrw SW corner
  c(-37.902610, 144.443002), # Z1/btrw SE corner
  c(-37.909538, 144.439648), # Z1 SE corner
  c(-37.908999, 144.434965), # Z1 southern boundary bend 1
  c(-37.907537, 144.433359), # Z1 southern boundary bend 2
  c(-37.905958, 144.430140), # Z1 southern boundary bend 3
  c(-37.905486, 144.429479), # Z1 southern boundary bend 4
  c(-37.904649, 144.427566), # Z1 SW corner
  c(-37.897319, 144.429048)  # S end of NW diagonal
  ) %>%  vect(type = "polygons", crs = "EPSG:4326") %>% 
  # transpose
  t() %>%
  # add a buffer for GPS accuracy of 30m for analysis, and 10m for mapping
  #buffer(10)
  buffer(30)
```

# Introduction

Reinforcement is a form of conservation translocation used to stabilise or enhance populations. Reinforcement is also a stage within other forms of translocation, which usually involve multiple release cohorts and therefore have cohorts released into the presence of conspecifics. Even a reintroduction project will have conspecifics present from the second release. Benefits of reinforcing release are assumed but rarely empirically tested – and if they are its usually from perspective of reinforcing individuals, not the population as a whole. Outcomes of reinforcement are mediated by social interactions, which are also assumed but not often empirically tested. 

Here we test the outcomes of reinforcement for a population of bush stone-curlew where all individuals in the population (resident and reinforcing) are accounted for and tracked with GPS. We ask: do the cohorts integrate? Do social interactions benefit the reinforcing cohort? And, do the residents change their behaviour?

## Translocation

We translocated 35 adult captive-bred bush stone-curlews from Mt Rothwell captive colony to Mt Rothwell Zone 1 (fenced sanctuary) in two stages. The first (pilot) cohort of 16 birds was released between October 2022 and June 2023. The second (reinforcing) cohort of 20 birds was released in June 2023. One bird in the first cohort was taken back into captivity after a single day and re-released in the second cohort; hence total 35 individuals.

## Telemetry

All translocated birds were fitted with a GPS tracker (Ornitrak20 from Ornitela) with a duty cycle of a fix every 60 seconds (or reduced when battery low). Telemetry data were stored on Movebank. We collected data from the release date of each individual until the 12th of January 2024 (when GPS devices were removed from all remaining birds except one, ahead of the 3G shutdown).

The study period for this analysis ends 5th August 2023, when half of the reinforcing cohort were translocated to a secondary site (Orana).

# Data cleaning

High throughput animal tracking data require filtering to remove erroneous points, while maintaining real movement data. We follow the workflow by [Gupte et al. (2021)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.13610), that is:

1) temporal filtering
2) filtering by quality covariates
3) filtering biologically unrealistic movement
4) median smoothing

## Test pipeline

We first tested the pipeline with a subset of the data (birds "Marmalade" & "Fauna"). Marmalade left the fenced area during the study while Fauna did not. 

### 1) Temporal filtering

We removed points after the end of the study period (5/8/23 at the start of next experiment - translocation to Orana).

```{r}
# import data from movebank
data_raw <- readr::read_csv("movebank/Fauna01.csv", show_col_types = FALSE) %>%
  rbind(readr::read_csv("movebank/Marmalade01.csv", show_col_types = FALSE)) %>%
  clean_names() %>%
  # Time in posix format
  mutate(datetime = as.POSIXct(study_local_timestamp, "%Y-%m-%d %H:%M:%S"),
         date = as.Date(datetime)) %>%
  # Remove days after end of tracking period
  filter(date < "2023-08-04") %>%
  rename(id = individual_local_identifier)

# plot raw data
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow", alpha = .6)+
  theme_void()+
  facet_wrap(~id)
```

### 2) Filtering by quality covariates

We filter using the following covariates: 

* satellite count
* horizontal dilution of precision (HDOP)
* altitude

In the past I've found filtering by satellite count and hdop can remove errors, but when applied with the wrong parameters they can have a high rate of false positives (removing real movement) and low rate of true positives (removing unrealistic movement) so we don't want to be overly aggressive with the application of these filters.

```{r}
# Histogram of satellite vales
hist(data_raw$gps_satellite_count)

# Plot track, colour by satellite values
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_raw, aes(location_long, location_lat, colour = gps_satellite_count))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

Most points have a satellite count >=4. Not many of the obvious spikes have low satellite count. We'll filter to include only satellite count >=4. 

Now look at the horizontal dilution of precision (HDOP).

```{r}
# Histogram of hdop vales
hist(data_raw$gps_hdop)

# Plot track, colour by hdop values
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_raw, aes(location_long, location_lat, colour = gps_hdop))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

There are a handful of massive hdop values (5-15) but the vast majority are =<2. Again the obvious spikes don't have high hdop values. We'll filter to only include hdop <=2. 

Next we'll apply filtering on the basis of altitude. 

Incorrect GPS fixes often have incorrect altitude. High altitude was not expected as no birds were undertaking long-distance flight, which is the only time high altitude is possible. All birds were wing-clipped on release and some later moulted and undertook short-distance flight, but not at high altitude. 

First we need to find flight height altitude by correcting for ground elevation. We are using the [FABDEM (Forest And Buildings removed Copernicus 30m DEM)](https://gee-community-catalog.org/projects/fabdem/).

```{r}
# read in FABDEM
fabdem <- rast("data/S38E144_FABDEM_V1-0.tif") 

# convert data to spatial points
coords <- data_raw %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Extract dem and add to dataframe
data_alt <- data_raw %>%
  mutate(terra::extract(fabdem, coords, ID = FALSE)) %>%
  rename(elevation = "S38E144_FABDEM_V1-0") %>%
  # calculate flight height
  mutate(altitude = height_above_msl - elevation)

# Histogram altitude
hist(data_alt$altitude)

# Summary statistics altitude
summary(data_alt$altitude)
quantile(data_alt$altitude, probs = 0.95)

# Plot track, colour by altitude values
ggmap(map_z13)+
  geom_path(data=data_alt, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_alt, aes(location_long, location_lat, colour = altitude))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

The median altitude (above the ground surface) was 9m. The min (-2060m) and max (8313m) altitude were considered unrealistic. Many of the obvious spikes have very high or negative altitude. 

We cut off the maximum altitude at 60 (just above the 0.95 quartile) and the minimum to -10m (ground level allowing for some error).

```{r}
# Apply quality covariate filters
data_qfilt <- data_alt %>%
  filter(gps_satellite_count >= 4) %>%
  filter(gps_hdop <=2) %>%
  filter(altitude < 60 & altitude >-10)

# Plot effect of filtering
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "purple", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow")+
  geom_point(data=data_qfilt, aes(location_long, location_lat), 
             colour = "purple")+
  theme_void()+
  facet_wrap(~id)
```

This successfully filtered out most of the obvious spikes.

### 3) Filtering biologically unrealistic movement

To remove spikes in the data we can filter out positions with extreme incoming and outgoing speeds. First we need to define biologically realistic incoming and outgoing speeds.

```{r}
# Append turning angle, incoming/outgoing speeds to data frame per bird
birds <- unique(data_raw$id)

data_speed <- data.frame()

for(i in 1:length(birds)){
 subset <- filter(data_qfilt, id == birds[i])

 temp <- subset %>%
   mutate(speed_in  = atl_get_speed( 
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("in")),
    speed_out = atl_get_speed(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("out")),
    angle = atl_turning_angle(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime"),
    speed_delta = abs(speed_in - speed_out)
    )
 
 data_speed <- rbind(data_speed, temp)
}

# Histogram incoming speeds
hist(data_speed$speed_in)

# Summary statistics incoming speeds
summary(data_speed$speed_in)
quantile(data_speed$speed_in, probs = 0.99, na.rm = TRUE)

# Histogram outgoing speeds
hist(data_speed$speed_out)

# Summary statistics outgoing speeds
summary(data_speed$speed_out)
quantile(data_speed$speed_out, probs = 0.95, na.rm = TRUE)

# Histogram turning angle
hist(data_speed$angle)

# Summary statistics turning angle
summary(data_speed$angle)

# Histogram difference between incoming and outgoing speed
hist(data_speed$speed_delta)

# Summary statistics difference between incoming and outgoing speed
summary(data_speed$speed_delta)
quantile(data_speed$speed_delta, probs = 0.95, na.rm = TRUE)

# Plot track, colour by speed
ggmap(map_z14)+
  geom_path(data=data_speed, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_speed, aes(location_long, location_lat, colour = speed_delta))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

Speeds were usually <2m/s and outgoing speeds while turning are likely <1m/s. A sharp turning angle was defined as <90 degrees. Sharp increase/decrease in speed also isn't expected, with the vast majority of difference between incoming and outgoing speed 0.1m/s.

We defined biologically realistic movement as speeds <2m/s (a note of caution: this shouldn't be used when the birds are undertaking long distance movements as faster speeds may be possible e.g. while gliding on wind), turning speeds of 0.5m/s, and delta speed as 0.4m/s. 

```{r}
# Apply turning angle filtering
data_sfilt <- data_speed %>%
  filter(speed_in < 2) %>%
  filter(speed_delta < 0.4) %>%
  filter(!(speed_out >0.5 & angle <90))

# Plot effect of filtering
ggmap(map_z14)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "purple", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow")+
  geom_point(data=data_qfilt, aes(location_long, location_lat), 
             colour = "orange")+
  geom_point(data=data_sfilt, aes(location_long, location_lat), 
             colour = "purple")+
  theme_void()+
  facet_wrap(~id)
```

### 4) Median smoothing

Even after speed/angle filtering, we retain some smaller-scale jitter. These are challenging to remove as they lie within the bounds of realistic movement. Median resampling is a method of smoothing the track to reduce jitter. We apply it sparingly, because an overly aggressive approach will cut down on real track tortuousity. 

```{r}
# Apply median smooth by bird
data_smooth <- data.frame()

for(i in 1:length(birds)){
  
  subset <- filter(data_sfilt, id == birds[i])
  
  temp <- atl_median_smooth(data = subset, x = "location_lat", y = "location_long",
                                  time = "datetime", moving_window = 3)
  
  data_smooth <- rbind(data_smooth, temp)
}

# Plot effect of smoothing
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)

# And zoom in to the fenced area
ggmap(map_z15)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)

# And visualise without filtered out data
ggmap(map_z15)+
    geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)
```

*_Visual check using fence polygon._*
We know Fauna didn't leave the study site during the tracking period so this is a good way to check if filtering was successful. Filter for points from "Fauna" outside of the polygon. 

```{r}
# Convert df to points
points <- data_smooth %>%
  filter(id=="Fauna") %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Find points outside polygons
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside polygon 
ggmap(map_z15)+
  geom_point(data=outside, aes(x, y), colour = "yellow", alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_c()+
  theme_void()
```

There are only 65 points outside the fence (given a 30m buffer) which is within tolerance. Interestingly they are all clustered on the southern and eastern fenceline, perhaps there was something about the topography or vegetation in that area that pronounced the errors.

Based on this test subset, I am happy with the filtering parameters for this location.

## Apply filtering 

We apply all of the above steps to the full dataset. 

### 1) Temporal filtering

We removed points after the end of the study period (5/8/23 at the start of next experiment - translocation to Orana).

```{r}
# Import data from movebank
data_raw <- readr::read_csv(fs::dir_ls(path = "movebank")) %>%
  clean_names() %>%
  # Time in posix format
  mutate(datetime = as.POSIXct(study_local_timestamp, "%Y-%m-%d %H:%M:%S"),
         date = as.Date(datetime)) %>%
  # Remove days after end of study
  filter(date < "2023-08-04") %>%
  rename(id = individual_local_identifier)
```

### 2) Filtering by quality covariates

We used the following quality covariates:

* Altitude: set to a minimum of -10m (ground level allowing for some error) and a maximum of 60 (just above the 0.95 quartile on test data)
* HDOP: set to a maximum of 2
* Satellite count: set to a minimum of 4

```{r}
# read in FABDEM
fabdem <- rast("data/S38E144_FABDEM_V1-0.tif") 

# convert data to spatial points
coords <- data_raw %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Extract dem and add to dataframe
data_alt <- data_raw %>%
  mutate(terra::extract(fabdem, coords, ID = FALSE)) %>%
  rename(elevation = "S38E144_FABDEM_V1-0") %>%
  # calculate flight height
  mutate(altitude = height_above_msl - elevation)

# Apply quality covariate filters
data_qfilt <- data_alt %>%
  filter(gps_satellite_count >= 4) %>%
  filter(gps_hdop <=2) %>%
  filter(altitude < 60 & altitude >-10)

# Filtering effect
print(paste("Percentage original data removed: ", round(((nrow(data_raw)-nrow(data_qfilt)) / nrow(data_raw))*100), "%", sep = ""))
```

Percentage original data removed: 28%

### 3) Filtering biologically unrealistic movement

We defined (from test data) biologically realistic movement as speeds <2m/s (a note of caution: this shouldn't be used when the birds are undertaking long distance movements as faster speeds may be possible e.g. while gliding on wind), turning speeds of 0.5m/s, and delta speed as 0.4m/s. 

```{r}
# Append turning angle, incoming/outgoing/delta speeds to data frame per bird
birds <- unique(data_raw$id)

data_speed <- data.frame()

for(i in 1:length(birds)){
 subset <- filter(data_qfilt, id == birds[i])

 temp <- subset %>%
   mutate(speed_in  = atl_get_speed( 
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("in")),
    speed_out = atl_get_speed(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("out")),
    angle = atl_turning_angle(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime"),
    speed_delta = abs(speed_in - speed_out)
    )
 
 data_speed <- rbind(data_speed, temp)
}

# Apply turning angle and speed filtering
data_sfilt <- data_speed %>%
  filter(speed_in < 2) %>%
  filter(speed_delta < 0.4) %>%
  filter(!(speed_out >0.5 & angle <90))

# Filtering effect
print(paste("Percentage original data removed: ", round(((nrow(data_qfilt)-nrow(data_sfilt)) / nrow(data_qfilt))*100), "%", sep = ""))
```

Percentage original data removed: 7%

### 4) Median smoothing

To remove small-scale jitter. We used the smallest possible moving window (3) to retain as much real movement as possible. 

```{r}
# Apply median smooth by bird
data_smooth <- data.frame()

for(i in 1:length(birds)){
  
  subset <- filter(data_sfilt, id == birds[i])
  
  temp <- atl_median_smooth(data = subset, x = "location_lat", y = "location_long",
                                  time = "datetime", moving_window = 3)
  
  data_smooth <- rbind(data_smooth, temp)
}

# Plot smoothed data
ggmap(map_z14)+
  geom_path(data=data_smooth, aes(location_long, location_lat, colour = id), alpha = .7)+
  scale_colour_viridis_d()+
  theme_void()
```

Dropping unneeded columns to reduce the size of the saved file. Originally I kept the utm easting and northing columns from movebank but I noticed a mismatch between the cleaned lat/lon and the utm, so have elected to transform the data when required instead. 

```{r}
# Convert data to spatial and reproject in utm
points <- data_smooth %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326") %>%
  # re-project into zone 55S
  project("EPSG:32755") %>%
  st_as_sf()

# allocate utm coords
coords <- st_coordinates(points$geometry)

# format data frame for saving to disk
data <- data_smooth %>%
  # select columns to keep
  dplyr::select(c("id", "datetime", "timestamp", "location_long", "location_lat", "acceleration_raw_x", "acceleration_raw_y", "acceleration_raw_z", "external_temperature", "altitude")) %>%
  # rename columns
  rename(longitude = location_long,
         latitude = location_lat,
         time_local = datetime,
         time_utc = timestamp) %>%
  # add utm xy columns 
  mutate(easting = st_coordinates(points$geometry)[,1],
         northing = st_coordinates(points$geometry)[,2]) %>%
  # add cohort metadata
  left_join(dplyr::select(metadata, c("id","cohort")))

# save to disk
write.csv(data, "data/data_cleaned.csv", row.names = FALSE)
```

# Movement analysis

Here we calculate PRBM metrics from tracking data to assess the establishment of reinforcers. The reinforcement period spans the 55 days between 11 June 2023 (last reinforcer released) and the 5th August 2023 (end of study period when reinforcers are translocated to Orana).

We also compare the response of the residents pre- and post-reinforcement to see if the reinforcement changes the behaviour of the residents. The pre-reinforcement period spans the 142 days between 16th January 2023 (last resident released) to 7th June 2023 (first reinforcer released).

I run these for all the dates to make it simpler (one dataframe instead of multiple per metric for each time period) and then filter to dates as required.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne"))

# Plot cleaned data to check
ggmap(map_z14)+
  geom_path(data=data, aes(longitude, latitude, colour = id), alpha = .7)+
  scale_colour_viridis_d()+
  theme_void()
```

Calculate basic summary statistics. 

```{r}
# Summary statistic: number of tracked days
length(unique(data$date))

# Summary statistic: total number of tracked days per bird
print(data %>%
  group_by(id) %>%
  summarise(length(unique(date))), n=35)

print(data %>%
  group_by(id) %>%
  summarise(days = length(unique(date))) %>%
  summarise(birddays = sum(days)))
```

Birds were tracked for a total of 284 days between October 2022 and August 2023 for a total of 3533 tracking days (sum of each bird's tracking duration). 

Wobbles and Star tracked for less than two weeks and excluded from further analyses. 

```{r}
data <- data %>%
  filter(!id %in% c("Wobbles", "Star"))
```

## Day/night

Rather than splitting data on calendar days (because they are nocturnal and movement continues over midnight) we want to split the data by diurnal and nocturnal movement. We use the sunrise/sunset time (from suncalc) to add bird date to the data. This also provides additional filtering, because jitter while the bird is stationary at its roost overinflates movement estimates, so counting only noctunal movement gives a better estimate of real movement. Additionally, we add "bird date" to the data, a 24-hour period commencing at sunset (a better indication of a "day" from the bird's perspective than calendar day), so that movements over a night (crossing midnight) can be allocated to the correct grouping. 

```{r}
# Calculate if time is pre/post dawn/dusk
suntime <- getSunlightTimes(date = unique(data$date),
                            lat = -37.90,
                            lon = 144.43,
                            keep = c("sunrise", "sunset"),
                            tz = "Australia/Melbourne") %>%
  subset(dplyr::select = -c(lat, lon)) 

# Append to data frame
data_sun <- left_join(data, suntime) %>%
  mutate(tod = ifelse(time_local>sunrise & time_local<sunset, "day", "night")) %>%
  relocate(time_local, .after = tod) %>%
  na.omit()

# Plot to check - using scattermore to speed up display
ggplot(data_sun)+
  geom_scattermore(aes(easting, northing, colour = tod), alpha = 0.6)+
  coord_sf()+
  theme_void()

# Add "bird date" 
data_sun <- data_sun %>%
  # add column for how long past/to sunset
  mutate(suntime = as.numeric(difftime(time_local, sunset, units = "hours"))) %>%
  # negative sun-time values indicate it's the next day - 
  # therefore allocate previous day calendar date as "bird date"
  mutate(date_bird = as_date(ifelse(suntime > 0, date, date - 1)))

# Save day data
data_day <- data_sun %>%
  filter(tod == "day")

write.csv(data_day, "data/data_clean_day.csv", row.names = FALSE)

# Save night data
data_night <- data_sun %>%
  filter(tod == "night")

write.csv(data_night, "data/data_clean_night.csv", row.names = FALSE)
```

## Distance moved

How long does it take birds to settle? 

Distance moved per night over time. Calculation is done per bird per day (bird date).

Test with one bird, "Fauna". 

```{r}
# read in night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # format time as posixct
  mutate(time_local = as.POSIXct(time_local))

# format as amt and calculate step lengths
steps <- data_night %>%
  filter(id=="Fauna") %>%
  # format as amt track - add columns as needed
  make_track(.x = easting, .y = northing, .t = time_local, id = id, date_bird = date_bird) %>%
  steps(keep_cols = "start")

# summarise per bird date
summary <- steps %>%
  group_by(date_bird) %>%
  summarise(daily_dist = sum(sl_))

# plot histogram
hist(summary$daily_dist)

# plot over time
ggplot(summary, aes(date_bird, daily_dist))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_void()
```

Apply to all birds.

```{r}
# for loop to calculate distance moved per bird date
birds <- unique(data_night$id)

distance_daily <- data.frame()

for(i in 1:length(birds)){
  # Subset to bird, convert data to spatial and reproject in utm
    points <- data_night %>%
    # subset to bird
    filter(id==birds[i]) %>%
    vect(geom = c("longitude", "latitude"), crs = "EPSG:4326") %>%
    # re-project into zone 55S
    project("EPSG:32755") %>%
    st_as_sf()

  # save coords
  coords <- st_coordinates(points$geometry)

  # format as amt and calculate step lengths
  steps <- points %>%
    # get utm xy columns 
    mutate(easting = st_coordinates(points$geometry)[,1],
         northing = st_coordinates(points$geometry)[,2]) %>%
    # format as amt track 
    make_track(.x = easting, .y = northing, .t = time_local, id = id, 
               # add additional columns as needed
               date_bird = date_bird) %>%
    steps(keep_cols = "start")

  # summarise per bird date
  summary <- steps %>%
    group_by(date_bird) %>%
    summarise(daily_dist = sum(sl_)) %>%
    mutate(id = birds[i])
  
  # write out
  distance_daily <- rbind(distance_daily, summary)
  
  # alert me
  print(paste("finished calculation for ", birds[i], sep = ""))
}

# save output
write.csv(distance_daily, "results/daily_distance_moved.csv", row.names = FALSE)
```

Plot distance moved as a density plot and movement over time, per bird.

```{r}
# plot histogram
hist(distance_daily$daily_dist)

# plot density by bird
ggplot(distance_daily)+
  geom_density_ridges(aes(daily_dist, id, fill = id), alpha = 0.7)+
  scale_fill_viridis_d()+
  theme_bw()+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  theme(legend.position = "none")+
  xlim(0,7000)+
  scale_y_discrete(expand = expansion(add = c(0, 2)))+
  xlab("Distance moved daily (m)") + 
  theme(axis.title.y=element_blank())
```

## Roost establishment

Look at the same idea as the previous section (a metric of establishment) but with diurnal roost movement rather than nightly distanced moved. 

First calculate roost locations. Test with one bird.

```{r}
# read in day data
data_day <- read.csv("data/data_clean_day.csv")

# filter to test bird
test <- data_day %>%
  filter(id == "Aurora")

# plot roosts coloured by date
ggmap(map_z15)+
  geom_density2d(data=test, aes(longitude, latitude, colour = date), inherit.aes = FALSE)+
  theme_void()+
  scale_colour_viridis_d()+
  theme(legend.position = "none")

# plot a series of dates to see if multiple roosts occur
dates <- seq(as.Date("2023-01-01"), as.Date("2023-01-12"), "days")
span <- filter(test, date %in% dates)

ggmap(map_z15)+
  geom_density2d(data=test, aes(longitude, latitude), colour = "yellow", inherit.aes = FALSE)+
  theme_void()+
  facet_wrap(~date)
```

On visual inspection, the vast majority of dates have a single roost. 

Approximate roosts positions using kmeans. Apply to all birds

```{r}
# locate kmeans center for a roost per bird per day
birds <- unique(data_day$id)
days <- unique(data_day$date)

roosts <- data.frame()

for (i in 1:length(birds)){
  for (j in 1:length(days)){
    
    #subset by bird and date
    subset <- subset(data_day, id == birds[i] & date == days[j],
                    dplyr::select= c(easting, northing))
    # skip days where not enough points
      if (length(subset$easting)<4){next}
    
    # find kmean centers
    kmean <- kmeans(subset, centers=1)
    
    # compile data
    out <- as.data.frame(cbind(kmean$centers, npoints = kmean$size)) %>%
      mutate(id = birds[i], date = days[j])
    
    roosts <- rbind(roosts, out)
    
  }
  print(paste("Finished calculation for ", birds[i], sep = ""))
}

# characteristics of cluster data
hist(roosts$npoints)
summary(roosts$npoints)

# plot roosts by number of points
ggplot(roosts)+
  geom_point(aes(easting, northing, size = npoints, colour = id))+
  geom_path(aes(easting, northing, group = id), alpha = 0.3)+
  coord_sf()+
  scale_colour_viridis_d()+
  theme_bw()

# plot for a single bird with date as colour
ggplot(data = filter(roosts, id == "Marmalade"))+
  geom_point(aes(easting, northing, size = npoints, colour = as.Date(date)))+
  geom_path(aes(easting, northing, group = id), alpha = 0.3)+
  coord_sf()+
  scale_colour_viridis_c()+
  theme_bw()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank())

# save daily roost locations
write.csv(roosts, "results/daily_roost_location.csv", row.names = FALSE)
```

How far between consecutive roosts? 

```{r}
# read in roost locations, format as spatial
roosts <- read.csv("data/daily_roost_location.csv") %>%
  dplyr::select(!"npoints") %>%
  vect(geom = c("easting", "northing"), crs = "EPSG:32755") %>%
  st_as_sf()

# calculate distance between successive roosts per bird
birds <- unique(roosts$id)
distance_roosts <- data.frame()

for(i in 1:length(birds)){
  
  # subset to individual
  points <- filter(roosts, id==birds[i]) %>%
    # date as posix
    mutate(date = as.POSIXct(date, format = "%Y-%m-%d")) %>%
    # ensure arranged by date
    arrange(date) %>%
    #add lag column for geometry comparison
    mutate(previous = lag(geometry))
  
  # allocate the release location as the first location
  release <- st_sfc(st_point(c(274423.45, 5801912.85) ), crs = 32755) %>%
    st_as_sf()
  
  points$previous[1] <- release$x
  
  # calculate the distance between successive points
  out <- points %>%
    mutate(distance_previous = 
             as.numeric(st_distance(points$geometry, points$previous, by_element = TRUE))) %>%
    dplyr::select(!"previous")
  
  # write out
  distance_roosts <- rbind(distance_roosts, out)
}

# hist
hist(distance_roosts$distance_previous)

# transform to latlon
distance_roosts_latlon <- distance_roosts %>%
  vect() %>%
  project("EPSG:4326") %>%
  st_as_sf() %>%
  mutate(date = as_date(date))

# plot roosts with colour as distance from previous
ggplot()+
  geom_sf(data = distance_roosts_latlon, aes(colour = distance_previous))+
  scale_colour_viridis_c()+ 
  theme_void()

# plot roosts with colour as date
ggmap(map_z15)+
  geom_sf(data = distance_roosts_latlon, aes(colour = date), inherit.aes = FALSE)+
  scale_colour_viridis_c(trans = "date")+
  theme_void()
```

There is a day Nutmeg seems to have spent 3km away from their previous roost. IS that true? Investigate this outlier.

```{r}
# Read in cleaned data 
nutmeg <- read.csv("data/data_cleaned.csv") %>%
  # select only Nutmeg
  filter(id == "Nutmeg") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne")) 

# Plot
ggmap(map_z13)+
  geom_point(data=nutmeg, aes(longitude, latitude, colour = date), alpha = 0.8)+
  scale_colour_viridis_c()+
  geom_path(data=nutmeg, aes(longitude, latitude), colour = "white", alpha = 0.4)+
  theme_void()
```

Yep that looks true! On 5-11-23, Nutmeg goes on a flight to the west of the sanctuary, stays over the day near the quarry, then returns to the sanctuary the next day. 

Points outside of fence?

```{r}
# Convert df to points
points <- vect(distance_roosts_latlon)

# Find points outside polygons
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside polygon 
ggmap(map_z15)+
  geom_point(data=outside, aes(x, y, colour = id), alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_d()+
  theme_void()
```

One real roost outside (Nutmeg's adventure as above) and 5 where birds were just roosting close to the fence. This is fine. 

Save output.

```{r}
# convert geometry to regular columns to save to disk
distance_roosts2 <- distance_roosts_latlon %>%
  st_drop_geometry() %>%
  mutate(longitude = st_coordinates(distance_roosts_latlon$geometry)[,1],
         latitude = st_coordinates(distance_roosts_latlon$geometry)[,2])

# plot on map without the far nutmeg point
ggmap(map_z15)+
  geom_path(data = filter(distance_roosts2, distance_previous<2000),
          aes(longitude, latitude, group = id), colour = "white", alpha = 0.6, inherit.aes = FALSE)+
    geom_point(data = filter(distance_roosts2, distance_previous<2000),
          aes(longitude, latitude, colour = distance_previous), inherit.aes = FALSE)+
  scale_colour_viridis_c()+
  theme_void()

# write to file
write.csv(distance_roosts2, "results/daily_distance_between_roosts.csv", row.names = FALSE)
```

## Release site fidelity

How far did they move from the release location? Based on daily roost distance from release location.

Calculate distance from daily roost to release location. 

Release location utm:(274423.45, 5801912.85) 
Release location lat/lon:(-37.902374, 144.434323)

```{r}
# read in roost locations, format as spatial
roosts <- read.csv("data/daily_roost_location.csv") %>%
  dplyr::select(!"npoints") %>%
  vect(geom = c("easting", "northing"), crs = "EPSG:32755") %>%
  st_as_sf()

# release coords as spatial
release  <- st_sfc(st_point(c(274423.45, 5801912.85) ), crs = 32755)

# calculate distance between roosts and release site
dist <- roosts %>%
  mutate(dist_release = as.numeric(st_distance(release, roosts))) %>%
  # keep max distance per day
  group_by(date, id) %>%
  filter(dist_release == max(dist_release)) %>%
  ungroup() %>%
  # add cohort information
  left_join(dplyr::select(metadata, c("cohort", "id"))) %>%
  # format date as a date
  mutate(date = as_date(date)) %>%
  # arrange by date
  arrange(date) %>%
  # drop geometry
  st_drop_geometry()

# save to file
write.csv(dist, "results/daily_roost_distance_from_release.csv", row.names = FALSE)
```

## Home range

Home range change is another way to investigate post-release behavioural modification. Previous studies have demonstrated decreasing home ranges over time as individuals first explore their new surrounds and then settle on a core area of exploitation. We define home range as 50% kernel utilisation distribution, with both nocturnal and diurnal fixes.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne"))%>%
  filter(!id %in% c("Wobbles", "Star"))

# set up data in spatial points dataframe
locs <- SpatialPointsDataFrame(coordinates(
  cbind(data$easting, data$northing)), data = data)

# home range polygon per bird per day 🐢🐢 2.5 hours
birds <- as.character(unique(data$id))
days <- unique(locs[["date"]])

hr_daily <- data.frame()

for (i in 1:length(birds)){
  for (j in 1:length(days)){
    points <- subset(locs, id == birds[i] & date == days[j],
                     select = id)
    if (length(points)<5){
      next
    }
    kud <- kernelUD(points[,1], h="href", grid=1000, extent = 4) %>% 
      getverticeshr(percent = 50)
    
    proj4string(kud) <- CRS("EPSG:32755")
    
    kud_df_utm <- st_as_sf(kud)%>%
      mutate(date = days[j])
    
    print(head(kud_df_utm, n= 1L))
    
    hr_daily <- rbind.data.frame(hr_daily, kud_df_utm)
  }}

# extract area per day i.e. drop geometry
hr_area <- st_drop_geometry(hr_daily)

# save to file
write.csv(hr_area, "results/daily_hr_area.csv", row.names = TRUE)
```

## Time budget HMM

Time budget can be another indicator of post-release behavioural modification. We expect them to become more efficient with their foraging over time as they learn where to find and exploit resources. So we expect to see more direct travel and less time spent foraging over time. 

How do they allocate their nocturnal movement? Hidden markov model.

```{r}
# read in cleaned night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # drop columns notneeded
  dplyr::select(!c(sunrise, sunset, suntime, tod)) %>%
  # format date time in posixct
  mutate(time_local = as.POSIXct(time_local),
         date_bird = as_date(date_bird))

# prep data for moveHMM
data_hmm <- data_night %>%
  prepData(type = "UTM", coordNames = c("easting", "northing"),
           covNames = c("acceleration_raw_x", "acceleration_raw_y", "acceleration_raw_z", "altitude")) %>%
# add vector of the dynamic body acceleration (VEDBA)
  mutate(vedba = ((sqrt(acceleration_raw_x^2 + acceleration_raw_y^2 + acceleration_raw_x^2))/1000))
```

### Test model

Create a test subset of one bird for one month (Nutmeg in June 2023). Investigate step and angle statistics to help define starting parameters. 

```{r}
# Test subset, Nutmeg 1 month
dates <- seq(as.Date("2023-06-01"), as.Date("2023-07-01"), "days")
test <- filter(data_hmm, id == "Aurora" & date_bird %in% dates)

# format as amt and calculate step lengths
steps <- test %>%
  # format as amt track - add columns as needed
  make_track(.x = x, .y = y, .t = time_local, id = id, date_bird = date_bird)

# check sample rate
summarize_sampling_rate(steps)

# resample track to 5 minutes
track_resample(rate = minutes(5), tolerance = minutes(1))

# step statistics
hist(test$step, xlab = "step", main = "", breaks = 30)
summary(test$step)

# angle statistics
hist(test$angle, breaks = seq(-pi, pi, length = 15), xlab = "angle", main = "")
summary(test$angle)

```

#### Number of states

Compare a three state and four state model to see what performs better.

```{r}

# 3 state model parameters
stepPar <- c(
  10, 60, 200,   # Means
  5, 20, 150,    # Standard deviations 
  0.15, 0, 0.5   # Zero-mass values
)

anglePar <- c(
  0, 0, 0,      # Means
  1.5, 7, 3     # Concentrations
)

# 3 state model
hmm3 <- momentuHMM::fitHMM(data = test, 
               nbStates = 3,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

hmm3
plot(hmm3)

# Step Parameters for 4 States
stepPar <- c(
  10, 60, 150, 300,   # Means 
  5, 15, 100, 150,    # Standard deviations 
  0.1, 0, 0.3, 0.15   # Zero-mass values 
)

# Angle Parameters for 4 States
anglePar <- c(
  0, 0, 0, 0,         # Means 
  1.5, 5, 2, 3        # Concentrations
)

# 4 state model
hmm4 <- momentuHMM::fitHMM(data = test, 
               nbStates = 4,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

hmm4
plot(hmm4)

# compare 3 and 4 state models
AIC(hmm3, hmm4)
```

Prefer the 4 state model both visually and on AIC.

Model      AIC
1  hmm4 19401.37
2  hmm3 19443.89

#### Optimise parameters

Try a range of starting values to optimise parameters.

```{r}
# For reproducibility
set.seed(12345)

# Number of tries with different starting values
niter <- 10

# Save list of fitted models
allm <- list()

# Save list of starting parameters
parameters <- list()

for(i in 1:niter) {
  # Step length mean
  stepMean0 <- runif(4, min = c(5, 50, 100, 200), max = c(50, 150, 300, 400))
  
  # Step length standard deviation
  stepSD0 <- runif(4, min = c(5, 30, 50, 100), max = c(30, 100, 150, 200))
  
  # Zero mass
  zeroMass0 <- runif(4, min = c(0.5, 0.05, 0.01, 0.2), max = c(0.9, 0.3, 0.1, 0.3))
  
  # Turning angle mean
  angleMean0 <- c(0, 0, 0, 0)
  
  # Turning angle concentration
  angleCon0 <- runif(4, min = c(0.5, 3, 5, 3), max = c(3, 10, 15, 10))
  
  # Parameter table
  parameters[[i]] <- data.frame(
    state = rep(1:4),
    stepMean0 = stepMean0,
    stepSD0 = stepSD0,
    zeroMass0 = zeroMass0,
    angleMean0 = angleMean0,
    angleCon0 = angleCon0
  )
  
  # Fit model
  stepPar0 <- c(stepMean0, stepSD0, zeroMass0)
  anglePar0 <- c(angleMean0, angleCon0)
  
  allm[[i]] <- tryCatch({
    momentuHMM::fitHMM(
      data = test,
      nbStates = 4,
      dist = list(step = "gamma", angle = "vm"),
      Par0 = list(step = stepPar0, angle = anglePar0),
      estAngleMean = list(angle = TRUE),
      formula = ~vedba
    )
  }, error = function(e) NULL)
}

# Extract likelihoods of fitted models
allnllk <- unlist(lapply(allm, function(m) m$mod$minimum))

# Index of best fitting model (smallest negative log-likelihood)
whichbest <- which.min(allnllk)

# Best fitting model
mbest <- allm[[whichbest]]
mbest
plot(mbest)
plotStates(mbest)

# Best starting parameters 
pbest_start <- parameters[[whichbest]]

# Best outcome parameters
pbest_outcome <- mbest$mle
```

Best outcome parameters:

$step
           state 1    state 2     state 3     state 4
mean     7.2211441 28.7419041 93.49649922 253.7447067
sd       5.6455927 23.2401216 53.89146576 312.9671872
zeromass 0.1559012  0.1669094  0.01833069   0.2101607

$angle
                state 1    state 2    state 3   state 4
mean          0.1170206 -0.1668971 0.02669791 0.2645331
concentration 1.1835577  1.3724136 2.71667136 1.9204624

$beta
               1 -> 2    1 -> 3    1 -> 4    2 -> 1     2 -> 3    2 -> 4
(Intercept) -5.204991 -8.829121 -2.213485 -6.221311 -10.254742 -4.297407
vedba        6.313020 -3.078513 -1.617744  5.398456  -4.197239  4.724587
               3 -> 1    3 -> 2     3 -> 4    4 -> 1    4 -> 2    4 -> 3
(Intercept) -8.220560 -2.225103  0.4526661 -2.324431 -0.453848  1.538068
vedba       -3.345948  1.189772 -2.1410536  1.063941  1.259101 -3.388000

$delta
               state 1   state 2      state 3      state 4
ID:Nutmeg 0.0004158271 0.9993644 5.228222e-05 0.0001674458

### Run HMM

Apply best parameters for a 4 state model to all birds.

```{r}
# Step Parameters 
stepPar <- c(
  7, 29, 93, 253,   # Means
  6, 23, 54, 313,    # Standard deviations 
  0.16, 0.17, 0.02, 0.21   # Zero-mass values 
)

# Angle Parameters for 4 States
anglePar <- c(
  0.11, -0.17, 0.03, 0.26,         # Means 
  1.18, 1.37, 2.72, 1.92        # Concentrations
)

# 4 state model (approx. 7 hours to run) 🐢🐢
hmm_all <- momentuHMM::fitHMM(data = data_hmm, 
               nbStates = 4,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

# see states
hmm_all

# plot results
plot(hmm_all)

# check residuals
plotPR(hmm_all)

# Decode states
data_hmm2 <- data_hmm %>%
  mutate(states = viterbi(hmm_all))

# save output
write.csv(data_hmm2, "data/data_hmm.csv", row.names = FALSE)

```

$step
$step$est
           state 1    state 2    state 3     state 4
mean     8.2208094 20.3895440 57.8629585 129.4745424
sd       6.6718586 17.2595917 33.1696834 142.4877739
zeromass 0.1835534  0.1435767  0.1017199   0.1056076

$step$se
             state 1     state 2     state 3    state 4
mean     0.059195569 0.158752114 0.504588470 1.62585187
sd       0.059392166 0.135826249 0.350108882 1.68770684
zeromass 0.001644487 0.001121659 0.002745764 0.00326152

$step$lower
           state 1    state 2     state 3      state 4
mean     8.1047882 20.0783956 56.87398323 126.28793127
sd       6.5554521 16.9933771 32.48348260 139.17992928
zeromass 0.1803303  0.1413783  0.09633832   0.09921516

$step$upper
           state 1    state 2    state 3     state 4
mean     8.3368306 20.7006924 58.8519337 132.6611535
sd       6.7882651 17.5258063 33.8558842 145.7956185
zeromass 0.1867766  0.1457751  0.1071015   0.1120001


$angle
$angle$est
                    state 1     state 2     state 3    state 4
mean          -0.0006350116 -0.02490599 0.005901283 0.02889899
concentration  0.9849618919  1.34078324 2.855987790 1.62310950

$angle$se
                  state 1     state 2     state 3    state 4
mean          0.008772497 0.004360951 0.005746417 0.01000978
concentration 0.009074356 0.008098515 0.040103562 0.01989011

$angle$lower
                  state 1    state 2      state 3     state 4
mean          -0.01782879 -0.0334533 -0.005361488 0.009280183
concentration  0.96717648  1.3249104  2.777386254 1.584125600

$angle$upper
                 state 1     state 2    state 3    state 4
mean          0.01655877 -0.01635868 0.01716405 0.04851779
concentration 1.00274730  1.35665604 2.93458933 1.66209339


$gamma
$gamma$est
            state 1    state 2      state 3    state 4
state 1 0.931458331 0.05761075 2.899808e-05 0.01090192
state 2 0.025798292 0.89292770 4.665911e-02 0.03461490
state 3 0.002059385 0.20857863 7.299991e-01 0.05936288
state 4 0.036632497 0.16340398 1.137106e-01 0.68625289

$gamma$se
            state 1     state 2     state 3      state 4
state 1 0.001852868 0.001856780         NaN 0.0009593681
state 2 0.001035936 0.001734979 0.001537815 0.0010952092
state 3 0.001406860 0.004757413 0.005098452 0.0034170704
state 4 0.002882481 0.006547791 0.005798381 0.0077365855

$gamma$lower
            state 1    state 2    state 3     state 4
state 1 0.927736437 0.05407762        NaN 0.009173398
state 2 0.023843831 0.88947937 0.04373596 0.032531334
state 3 0.000539143 0.19940768 0.71989062 0.053008962
state 4 0.031383508 0.15097250 0.10283144 0.670894349

$gamma$upper
            state 1    state 2    state 3    state 4
state 1 0.935001961 0.06135974        NaN 0.01295190
state 2 0.027908379 0.89628098 0.04976747 0.03682684
state 3 0.007832716 0.21805649 0.73987462 0.06642498
state 4 0.042720676 0.17664613 0.12557970 0.70121389

### Time budget

```{r}
# read in data with hmm states
data_hmm <- read.csv("data/data_hmm.csv")

# calculate proportion of fixes in each state per bird per day
budget_daily <- data_hmm %>%
  group_by(ID, date_bird) %>%
  # count of states
  count(states) %>%
  # pivot to wide format
  pivot_wider(names_from = 3, values_from = 4) %>%
  # rename state columns
  rename(state1 = 3,
         state2 = 4,
         state3 = 5,
         state4 = 6) %>%
  # replace NAs with zeros
  replace(is.na(.), 0) %>%
  # calculate proportion
  mutate(total = sum(state1, state2, state3, state4),
         state1p = state1/total,
         state2p = state2/total,
         state3p = state3/total,
         state4p = state4/total) %>%
  arrange(date_bird) %>%
  # rename ID
  rename(id = ID)

# save to file
write.csv(budget_daily, "results/daily_time_budget.csv", row.names = FALSE)

# summarise over time
budget <- budget_daily %>%
  # calculate mean and sd
  group_by(id) %>%
  summarise(s1m = mean(state1p),
            s2m = mean(state2p),
            s3m = mean(state3p),
            s4m = mean(state4p)) %>%
  pivot_longer(2:5, names_to = "state", values_to = "budget") %>%
  # add cohort
  left_join(select(metadata, c(id, cohort)))

# plot time budget mean by bird
ggplot(budget)+
  geom_bar(aes(x = id, y = budget, fill = state), position="fill", stat="identity")+
  theme_minimal()+
  scale_fill_viridis_d()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1))+
  facet_wrap(~cohort, scales="free_x")
```

# Conspecific interactions

The key issue addressed in this paper is whether social interaction occurs between residents and reinforcers, and if so whether this mediates post-release outcomes for the cohorts. 

## Proximity analysis

First we need to determine interactions. Using GPS tracking data we cannot perfectly capture social interactions, but we can approximate these with proximity (distance and time) analysis. I elected to use the coefficient of association because it produces few few I errors, owing to its simplicity ([Long et al 2014](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12198)) 

To determine the temporal interaction threshold we use the mean sampling rate.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne")) %>%
  # drop birds excluded from analyses
  filter(!id %in% c("Wobbles", "Star")) %>%
  # drop NAs
  na.omit()

# summarise sampling rate to decide on temporal interaction threshold
steps <- data %>%
  make_track(.x = easting, .y = northing, .t = time_local, id = id) %>%
  nest(data = -"id")

sampling_rates <- steps %>%
  transmute(id, summary = map(data, summarize_sampling_rate)) %>%
  unnest(summary)

mean(sampling_rates$mean)
```

The mean sampling rate for the cleaned data is 8 minutes. We will use a time parameter of 4 minutes (half the sampling interval) following advice from the wildlifeDI package vignette. 

First format tracks as move2 objects for use in wildlifeDI.

```{r}
# format track data as move2 object
move <- mt_as_move2(data, coords = c("easting", "northing"), time_column = "time_local", track_id_column = "id") %>%
  # add crs
  sf::st_set_crs("EPSG:32755") %>%
  # needed to omit NAs for wildlifeDI to work
  na.omit()
```

We use a dcPlot of paired encounters across distance to approximate the distance threshold (using a subset to reduce processing time).

Our practitioner guesstimate was a threshold of 30m (based on visual observation of interactions between individuals in the field during monitoring). 

```{r}
# one week subset
temp <- seq.Date(from = as_date("2023-06-01"), to = as_date("2023-06-07"), by = "day")
move_subset <- filter(move, date %in% temp)

# plot distribution of paired fixes by distance
dcPlot(move_subset,tc=4*60,dmax=500)
dcPlot(move_subset,tc=4*60,dmax=100)
```

The majority of contacts took place <40m apart. I'll retain the guesstimate of 30m as the parameter. This is also within tolerance for the approximate GPS uncertainty of approx 20m (on cleaned data).

We calculate prox for all dyads for the two time periods of interest:

  1) Residents only
  2) Residents and reinforcers
  
### Residents only

We define this as the period from the last resident released (2023-01-16) to the first reinforcer released (2023-06-07). 

```{r}
# define resident only date period
res_dates <- seq.Date(from = as_date("2023-01-16"), to = as_date("2023-06-06"), by = "day")

# subset to dates
data_resident <- move %>%
  filter(date %in% res_dates)

# Test for a single dyad
dyad <- filter(data_resident, id %in% c("Aurora", "Briar"))

checkTO(dyad)
Sys.time()
test <- Ca(dyad, tc=4*60, dc=30);Sys.time()
```

The test dyad took 47 seconds so I'm anticipating the full set of 78 interactions will take 1 hour. 

```{r}
# list of residents
residents <- unique(data_resident$id)

# All bird combinations
list <-combinations(n = 13, r = 2, v = residents, repeats.allowed = FALSE)
list1 <- list[,1]
list2 <- list[,2]

# Calculate interactions between all birds 🐢🐢
interact <- data.frame()

for(i in 1:length(list1)) {
  
  dyad <- filter(data_resident, id %in% c(list1[i], list2[i]))
  
  temp <- tryCatch({
    data.frame(Prox(dyad, tc=4*60, dc=30)) %>%
      clean_names()
  }, error = function(e) data.frame(ca = NA, bird1 = NA, bird2 = NA)) 
  
  print(paste("Finished", list1[i], "&", list2[i], i, "of 78", sep = " "))
  
  interact <- rbind(interact, temp)
}

# tidy up the output
interact2 <- interact %>%
  # remove unneeded columns
  select(id1, id2, prox) %>%
  # format prox numeric to 4 decimal places
  mutate(prox = as.numeric(format(round(prox, 4), nsmall = 4)))

# save to disk
write.csv(interact, "results/proximity_residents.csv", row.names = FALSE)

# summary statistics prox values
hist(interact2$prox)
summary(interact2$prox)
```

Mean proximity score is 13.1%, min is no interaction and max is 43.8%. 

### Residents and reinforcers

We define this as the period from the last reinforcer released (2023-06-11) to the end of the study period (when reinforcers moved to Orana 2023-08-05). Each dyad takes approx. 8 seconds so all 378 takes approx 1 hour to run. 

```{r}
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-05"), by = "day")

# subset to dates
data_reinforce <- move %>%
  filter(date %in% rein_dates)

# list of founders
founders <- unique(data_reinforce$id)

# All bird combinations
list <-combinations(n = 28, r = 2, v = founders, repeats.allowed = FALSE)
list1 <- list[,1]
list2 <- list[,2]

# Calculate interactions between all birds 🐢🐢
interact <- data.frame()

for(i in 1:length(list1)) {
  
  dyad <- filter(data_reinforce, id %in% c(list1[i], list2[i]))
  
  temp <- tryCatch({
    data.frame(Prox(dyad, tc=4*60, dc=30)) %>%
      clean_names()
  }, error = function(e) data.frame(ca = NA, bird1 = NA, bird2 = NA)) 
  
  print(paste("Finished", list1[i], "&", list2[i], i, "of 378", sep = " "))
  
  interact <- rbind(interact, temp)
}

# tidy up the output
interact2 <- interact %>%
  # remove unneeded columns
  select(id1, id2, prox) %>%
  # format prox numeric to 4 decimal places
  mutate(prox = as.numeric(format(round(prox, 4), nsmall = 4)))

# save to disk
write.csv(interact2, "results/proximity_reinforcers.csv", row.names = FALSE)

# summary statistics prox values
hist(interact2$prox)
summary(interact2$prox)
```

Summary stats here

## Social network

For social network analysis we use the proximity analysis of dyads completed above. Proximity networks are inferred interactions but with a highly complete data set - so we are trading off good temporal resolution and complete coverage of the population against little information on any one interaction. 

We use the package tidygraph as a wrapper for implement igraph graphics in the tidyverse API.

### Residents only

```{r}
# read in dyad proximity scores and convert to association matrix
prox1 <- read.csv("results/proximity_residents.csv") %>%
  # add rows for last and first bird self comparison
  rbind(data.frame(id1 = c("Valentine", "Aurora"),
                   id2 = c("Valentine", "Aurora"),
                   prox = c(NA, NA))) %>%
  # long to wide format
  pivot_wider(names_from = id2, values_from = prox) %>%
  # first column to rownames
  column_to_rownames("id1") %>%
  # relocate first bird to first column
  relocate(Aurora) %>%
  # format as matrix
  as.matrix()

# make symmetrical
prox1[lower.tri(prox1)] <- t(prox1)[lower.tri(prox1)]

# convert to graph object
network1 <- graph_from_adjacency_matrix(prox1, mode = "undirected", diag = FALSE, weighted = TRUE)

# network density - real edges divided by possible edges
edge_density(network1)

# network components - are all nodes connected?
components(network1)

# distance between nodes
distances(network1, algorithm="unweighted")

# proportion of node's neighbors that are connected to each other
summary(transitivity(network1, "local"))
```

We have a network of 13 individuals (nodes) and 68 edges with an edge density of 87.1%. The network is continuous (i.e. all nodes in network are connected) and the maximum degree of separation is two. 

First plot with weighted edges and nodes sized by degree centrality (number of edges - how many "friends" they have).

```{r}
# set seed to keep layout static
set.seed(4739)
networkfr1 <- create_layout(network1, layout = "fr") 

# plot with tidygraph (wrapper for igraph in tidy API)
ggraph(networkfr1)+
  # format edge colour, alpha and width by the weight (proximity)
  geom_edge_fan(aes(colour = weight, alpha = weight, linewidth = weight/2), 
                show.legend = FALSE)+
  scale_edge_color_continuous(low = "grey", high = "slateblue3")+ 
  # node basic
  geom_node_point(size = 7, shape = 16)+
  # add labels
  #geom_node_text(aes(label = name), nudge_y = 0.15)+
  # theme
  theme_void()
```

Next calculate community - first deciding on clustering algorithm.

Based on the suggestions by [Yang et al. (2016)](https://www.nature.com/articles/srep30750) I will try edge betweenness, walktrap, spinglass and infomap, because I have a small dense network and these perform well in that use case. 

```{r}
# community with edge betweenness
eb <- cluster_edge_betweenness(network1)
length(eb)
modularity(eb)
membership(eb)

# community with walktrap
w <- cluster_walktrap(network1)
length(w)
modularity(w)
membership(w)

# community with spinglass
sg <- cluster_spinglass(network1)
length(sg)
modularity(sg)
membership(sg)

# community with infomap
im <- cluster_infomap(network1)
length(im)
modularity(im)
membership(im)
```

They all turned out the same, I'll use walktrap. Plot with community.

```{r}
# add community to network layout
comm1 <- networkfr1 %>%
  mutate(community = as.factor(membership(w)))
```

### Residents and reinforcers

```{r}
# read in dyad proximity scores and convert to association matrix
prox2 <- read.csv("results/proximity_reinforcers.csv") %>%
  # add rows for last and first bird self comparison
  rbind(data.frame(id1 = c("Zeus", "Athena"),
                   id2 = c("Zeus", "Athena"),
                   prox = c(NA, NA))) %>%
  # long to wide format
  pivot_wider(names_from = id2, values_from = prox) %>%
  # first column to rownames
  column_to_rownames("id1") %>%
  # relocate first bird to first column
  relocate(Athena) %>%
  # format as matrix
  as.matrix()

# make symmetrical
prox2[lower.tri(prox2)] <- t(prox2)[lower.tri(prox2)]

# convert to graph object
network2 <- graph_from_adjacency_matrix(prox2, mode = "undirected", diag = FALSE, weighted = TRUE)

# network density - real edges divided by possible edges
edge_density(network2)

# network components - are all nodes connected?
components(network2)

# distance between nodes
distances(network2, algorithm="unweighted")

# proportion of node's neighbors that are connected to each other
summary(transitivity(network2, "local"))
```

We have a network of 28 individuals (nodes) and 377 edges with an edge density of 99.7% (only one dyad doesn't have an edge, Sofi & Daisy). The network is continuous (i.e. all nodes in network are connected) and the maximum degree of separation is two. 

Calculate community with walktrap method.

```{r}
# community with walktrap
w2 <- cluster_walktrap(network2, steps = 10)
length(w2)
modularity(w2)
membership(w2)

# set seed to keep layout static
set.seed(0000)
networkfr2 <- create_layout(network2, layout = "fr") 

# add community and cohort to network layout
comm2 <- networkfr2 %>%
  rename(id = name) %>%
  mutate(community = as.factor(membership(w2))) %>%
  left_join(select(metadata, c(id, cohort)))

hist(E(network2)$weight)
```

Interesting! The reinforcers split nearly perfectly in half, with nine members in an exclusive social group (consisting only of reinforcers) and eleven members in a mixed social group (along with all the residents). Daisy was off to the side but ended up in the mixed group. 

### SNA figure

```{r}
# resident network
n1 <- ggraph(comm1)+
  # community polygon
  geom_mark_hull(aes(x = x, y = y, fill = community), 
                 colour = "white", alpha = 0.2, expand = unit(0.5, "cm"),
                 show.legend = FALSE)+
  
  scale_fill_manual(values = c("grey10", "grey60"))+
  # format edge colour, alpha and width by the weight (proximity)
  geom_edge_fan(aes(colour = weight, alpha = weight, linewidth = weight/2),
                show.legend = FALSE)+
  scale_edge_color_continuous(low = "grey", high = "slateblue4")+ 
  # node basic
  geom_node_point(size = 5, shape = 16)+
  # theme
  expand_limits(x = c(-6, 3), y = c(-4.5, 0.4))+
  theme_graph(foreground = "black", border = TRUE,
              plot_margin = margin(10, 60, 0, 60))

# reinforcer network
n2 <- ggraph(comm2)+
  # communites polygons
  geom_mark_hull(aes(x = x, y = y, fill = community), 
                 colour = "white", alpha = 0.2, expand = unit(0.8, "cm"),
                 show.legend = FALSE)+
  scale_fill_manual(values = c("seagreen3", "#2E3FFF"))+
  # format edge colour, alpha and width by the weight (proximity)
  geom_edge_fan(aes(colour = weight, alpha = weight, width = weight),
                show.legend = FALSE)+
  scale_edge_color_continuous(low = "grey90", high = "slateblue4")+ 
  scale_edge_width(range = c(0.1, 3))+
  # node shape by cohort
  geom_node_point(aes(shape = cohort), size = 5, 
                  show.legend = FALSE)+
  scale_shape_manual(values=c(15, 16))+
  # theme
  expand_limits(x = c(2, 7), y = c(-3.8, 2.6))+
  theme_graph(foreground = "black", border = TRUE,
              plot_margin = margin(10, 20, 20, 20))

# multi panel
ggarrange(n1, n2, 
          labels = c("A", "B"),
          ncol = 1, nrow = 2,
          heights = c(0.5, 1))
```


# Statistical analysis: reinforcers

Instead of using dyad connections, we can use the social groups (which are serendipitously nearly evenly split among the reinforcers) to ask questions about conspecific interactions. Social groups can tell you more about the overall social environment than dyads alone (Farine and Whitehal 2015).

We hypothesised members of the mixed resident-reinforcer social group would proceed more quickly through the PRBM phases than those in the reinforcer only group. I also want to compare both reinforcer groups to the residents to see if one is more similar than the other.

Dates are from the last reinforcer released to the first reinforcer translocated to the secondary site. 

```{r}
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")

# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-05"), by = "day")
```

### m1: Distance moved

Does daily distance moved differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date_bird)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))

# create social group means
sum1 <- datam1 %>%
  group_by(date, social) %>%
  summarise(dist = mean(daily_dist),
            upper = dist + std.error(daily_dist),
            lower = dist - std.error(daily_dist)) %>%
  arrange(date)

# plot daily distance over time as social group means
ggplot(sum1, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-reinforcement") + 
  ylab("Daily distance moved (m)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam1$daily_dist)
ggqqplot(datam1$daily_dist)

# test difference between the groups with interaction of time as a quadratic
m1 <- glmmTMB(daily_dist ~ social * (scale(elapsed) + I(scale(elapsed)^2)) + (1|id), 
              data = datam1,
              na.action = "na.fail")

# model selection
dm1 <- dredge(m1)

dm1

# parsimonious model where delta <2 and fewest predictors 
# in this case only one model (the top ranked) delta AICc < 2
best1 <- get.models(dm1, delta == 0)[[1]] 

# check model
check_model(best1)

# summary
summary(best1)

# post-hoc comparison of slopes
emtrends(best1, pairwise ~ social, var = "elapsed")

# plot effects
plot_model(best1)

# marginal effects 
pred1 <- predict_response(best1, terms = c("elapsed [all]", "social"))

# plot predictions
ggplot(pred1, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-reinforcement") + 
  ylab("Predicted values of daily distance moved (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

**Results:**
The best fitting model included social group and time (linear and quadratic), the interaction between these, and individual as a random effect.

Distance moved per day increased with time post-release (estimate: 277.75 ± 41.19 SE, p < 0.001). Both reinforcer groups had significant negative quadratic responses over time compared to residents, meaning the increase of distance over time decelerated. 

The exclusive reinforcer group had a significantly lower slope of movement increase over time compared to the residents (p = 0.0143) and weakly lower compared to the mixed reinforcers (p=0.0459). 

**Interpretation:**
Reinforcers increase over time in response to the need to explore (find resources etc.) then stabilising - evidence of establishment. 

Also increase in movement may align with theoretical increase in fitness and physical capability with increased time out of captivity.

Movement by the residents might be influenced by factors unrelated to settlement. 

### m2: Roost fidelity

Does distance between roosts differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam2 <- read.csv("results/daily_distance_between_roosts.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable and scale it
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))

# create social group means
sum2 <- datam2 %>%
  group_by(date, social) %>%
  summarise(dist = mean(distance_previous),
            upper = dist + std.error(distance_previous),
            lower = dist - std.error(distance_previous)) %>%
  arrange(date)

# plot roost displacement over time as social group means
ggplot(sum2, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-reinforcement") + 
  ylab("Distance between consecutive roosts (m)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam2$distance_previous)
ggqqplot(datam2$distance_previous)

# correct left skew
hist(log1p(datam2$distance_previous))
ggqqplot(log1p(datam2$distance_previous))

# test difference between the groups with interaction of time as a quadratic
m2 <- glmmTMB(log1p(distance_previous) ~ social * (scale(elapsed) + I(scale(elapsed)^2)) + (1|id), 
              data = datam2,
              na.action = "na.fail")

# model selection
dm2 <- dredge(m2)

dm2

# parsimonious model where delta <2 and fewest predictors 
#  in this case only one model (the top ranked) delta AICc < 2
best2 <- get.models(dm2, delta == 0)[[1]]

# check model
check_model(best2)

# summary
summary(best2)

# plot effects
plot_model(best2)

# marginal effects 
pred2 <- predict_response(best2, terms = c("elapsed [all]", "social"))

# plot predictions
ggplot(pred2, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-reinforcement") + 
  ylab("Predicted values of roost displacement (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

**Results:**
The best fitting model included social group, time (linear and quadratic), the interaction between these (only quadratic) and individual as a random effect. 

Roost displacement generally decreased over time (estimate: -0.101 ± 0.032, p = 0.0014). However, this effect was mediated by social group, where exclusive reinforcers moved significantly further than residents (estimate: 0.71 ± 0.13, p < 0.001) and had a significant quadratic interaction (estimate: -0.21496 ± 0.09176, p = 0.01915) such that they initially increased before reaching a peak and declining. 

The mixed reinforcers were not significantly different from residents. 

**Interpretation:**
Distance between consecutive roosts is a metric for home range establishment in space. Shorter distances between consecutive roosts indicate an individual is staying within a patch and building up familiarity in the roost locations; whereas large distances between consecutive roosts indicate continued searching or lack of stability.

Group co-membership with residents improved roost establishment and fidelity. This could be due to signalling good habitat, thereby reducing the need to explore additional roost sites, or due to social bonds. 

Whereas the exclusive group showed a more "conventional" trend, of initial increase (with exploration) before declining (exploitation).

### m3: Release site fidelity

Does distance from the release site differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam3 <- read.csv("results/daily_roost_distance_from_release.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))

# create social group means
sum3 <- datam3 %>%
  group_by(date, social) %>%
  summarise(dist = mean(dist_release),
            upper = dist + std.error(dist_release),
            lower = dist - std.error(dist_release)) %>%
  arrange(date)

# plot distance from release site over time as social group means
ggplot(sum3, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-reinforcement") + 
  ylab("Distance from release site (m)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam3$dist_release)
ggqqplot(datam3$dist_release)

# correct left skew - still not great but a bit better
hist(sqrt(datam3$dist_release))
ggqqplot(sqrt(datam3$dist_release))

# test difference between the groups with interaction of time as a quadratic
m3 <- glmmTMB(sqrt(dist_release) ~ social * (scale(elapsed) + I(scale(elapsed)^2)) + (1|id), 
              data = datam3,
              na.action = "na.fail")

# model selection
dm3 <- dredge(m3)
dm3

# parsimonious model where delta <2 and fewest predictors 
# in this case there was only one model (the top ranked) with delta <2
best3 <- get.models(dm3, delta ==0)[[1]]

# check model
check_model(best3)

# summary
summary(best3)

# post-hoc comparison of means
emmeans(best3, pairwise ~ social, type = "response")

# post-hoc comparison of slopes
emtrends(best3, pairwise ~ social, var = "elapsed")

# plot effects
plot_model(best3)

# marginal effects 
pred3 <- predict_response(best3, terms = c("elapsed [all]", "social"))

# plot predictions
ggplot(pred3, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-reinforcement") + 
  ylab("Predicted values of distance from release site (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

**Results:**
The best fitting model included social group and time (linear and quadratic), the interaction between these, and individual as a random effect.

Distance from the release site significantly increased over time (estimate: 0.6600 ± 0.1704, p = 0.0001) and had a positive quadratic effect, indicating an acceleration of this increase (estimate: 1.2086 ± 0.1883, p < 0.0001). Mixed reinforcers did not differ from residents in the rate of increase. 

Exclusive reinforcers moved significantly further from the release site than both mixed reinforcers and residents (p < 0.0001). Exclusive reinforcers exhibit a marked deceleration compared to the other groups.

**Interpretation:**
Mixed reinforcers had greater release site fidelity than exclusive reinforcers. Tactically, site fidelity is importancde because, first, hyperdispersal increases chance of predation, and second, the release area has suitable resources for long-term survival and recruitment. 

An alternative explanation is that the exclusive birds were pushed away e.g. due to territoriality or population capacity- but I don't think this is the case because they continued to have interactions with the other group including some time roosting in the central woodland.

Deceleration in distance by the exclusive reinforcers was probably because they reached the edge of fenced reserve so couldn't move further away from the release site. 

#### Release site fidelity map

How do they move away from the release site over time

```{r}
ggmap(map_z15)+
  # plot roosts colour by time
  geom_point(aes(longitude, latitude, colour = date),
             size = 2, data = datam2, inherit.aes = FALSE)+
  # add release location
  geom_point(aes(144.434323, -37.902374), 
             colour = "white", size = 5, shape = 13, inherit.aes = FALSE)+
  # add fence
  geom_spatvector(data = mtr, inherit.aes = FALSE, fill = NA, colour = "white",
                  linetype = "longdash")+
  # wrap by period
  facet_wrap(~social)+
  # theme options
  scale_colour_viridis_c(trans = "date", name = "2023")+
  theme_void()+
  scale_y_continuous(expand = expansion(mult = c(0, 0.01)))+
  theme(legend.position="bottom",
        legend.key.width = unit(3, 'cm'),
        strip.text = element_text(size = 13))+
  # add north in just the resident facet panel
  annotation_north_arrow(data  = subset(datam2, social == "Resident"),
                         location = "tr", 
                         height = unit(0.8, "cm"), width = unit(0.7, "cm"),
                         style = north_arrow_orienteering(text_col = "black"))+
  # add scale bar in just the resident facet panel
  annotation_scale(data  = subset(datam2, social == "Resident"),
                   location = "br", text_col = "black",
                   pad_x = unit(0.1, "cm"), pad_y = unit(0.4, "cm"))
```

### m4: Home range size

Does home range size differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam4 <- read.csv("results/daily_hr_area.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))

# create social group means
sum4 <- datam4 %>%
  group_by(date, social) %>%
  summarise(dist = mean(area),
            upper = dist + std.error(area),
            lower = dist - std.error(area)) %>%
  arrange(date)

# plot homer range size over time as social group means
ggplot(sum4, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-reinforcement") + 
  ylab("Home range 50% KUD (ha)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam4$area)
ggqqplot(datam4$area)

# correct left skew
hist(log1p(datam4$area))
ggqqplot(log1p(datam4$area))

# test difference between the groups with interaction of time as a quadratic
m4 <- glmmTMB(log1p(area) ~ social * (scale(elapsed) + I(scale(elapsed)^2))+ (1|id), 
              data = datam4,
              na.action = "na.fail")

# model selection
dm4 <- dredge(m4)
dm4

# parsimonious model where delta <2 and fewest predictors 
# in this case there was only one model (the top ranked) with delta <2
best4 <- get.models(dm4, delta==0)[[1]]

# check model
check_model(best4)

# summary
summary(best4)

# post-hoc comparison of means
emmeans(best4, pairwise ~ social, type = "response")

# post-hoc comparison of slopes
emtrends(best4, pairwise ~ social, var = "elapsed")

# plot effects
plot_model(best4)

# marginal effects 
pred4 <- predict_response(best4, terms = c("elapsed [all]", "social"))

# plot predictions
ggplot(pred4, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-reinforcement") + 
  ylab("Predicted values of home range area (ha)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

**Results:**
The best fitting model included social group and time (linear and quadratic), the interaction between these, and individual as a random effect.

No linear effect (i.e. no increase over time). However, the quadratic term is significant and negative (estimate: -0.20688 ± 0.0366, p < 0.001) i.e., an initial increase followed by a decrease, although the trend over time varies across social groups. The mixed reinforcers show a slight deceleration (-0.095, p = 0.045) and the exclusive reinforcers show a stronger deceleration  (-0.17, p < 0.001) compared to residents. Exclusive reinforcers decrease home range size singificatly more than both other groups (p < 0.0002).

All groups have significantly different home range size. 

**Interpretation:**
Stabilising home range area (significant negative quadratic term) indicates progression along establishment occurs for both groups - this is similar to roost site fidelity, showing exploration then contraction. 

Exclusive reinforcers have the smallest home ranges, perhaps related to distance moved - they decline their home range size significantly more than mixed reinforcers. Mixed reinforcers may be benefiting from habitat cues, prompting them to explore more, or from perceived safety being in the larger group. 

### m5: Time budget

Does time allocated to foraging differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam5 <- read.csv("results/daily_time_budget.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date_bird)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive")))

# create social group means
sum5 <- datam5 %>%
  group_by(date, social) %>%
  summarise(dist = mean(state2p),
            upper = dist + std.error(state2p),
            lower = dist - std.error(state2p)) %>%
  arrange(date)

# and pivot longer for barchart
datam5bar <- datam5 %>%
  select(!3:7) %>%
  pivot_longer(3:6, names_to = "state", values_to = "proportion")

# plot time budget by social group
ggplot(datam5bar)+
  geom_bar(aes(x = social, y = proportion, fill = state),
           position="fill", stat="identity")+
  xlab("Social group")+ 
  ylab("Time budget allocation")+
  theme_minimal()+
  scale_fill_viridis_d()

# plot foraging allocation over time as social group means
ggplot(sum5, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-reinforcement") + 
  ylab("Proportion time allocated to foraging %") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of allocation
hist(datam5$state2p)
ggqqplot(datam5$state2p)

# Adjust values slightly so that 0 < x < 1
datam5 <- datam5 %>%
  mutate(adjusted = (state2p + 0.001) / 1.002)

hist(datam5$adjusted)
ggqqplot(datam5$adjusted)

# test difference between the groups with interaction of time as a quadratic
m5 <- glmmTMB(adjusted ~ social * (scale(elapsed) + I(scale(elapsed)^2)) + (1|id), 
              data = datam5,
              family = beta_family(link = "logit"),
              na.action = "na.fail")

# model selection
dm5 <- dredge(m5)
dm5

# parsimonious model where delta <2 and fewest predictors 
# in this case the second model had delta AICc of 1 and 2 fewer predictors
best5 <- get.models(dm5, delta<2)[[2]]

# check model
check_model(best5)

# summary
summary(best5)

# post-hoc comparison of means
emmeans(best5, pairwise ~ social, type = "response")

# post-hoc comparison of slopes
emtrends(best5, pairwise ~ social, var = "elapsed")

# plot effects
plot_model(best5)

# marginal effects 
pred5 <- predict_response(best5, terms = c("elapsed [all]", "social"),
                          bias_correction = TRUE)

# plot predictions
ggplot(pred5, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-reinforcement") + 
  ylab("Predicted values of time allocated to foraging %") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

**Results:**
The best fitting model included social group and time (quadratic only), the interaction between social group and the quadratic, and individual as a random effect.

The reinforcer groups (both mixed and exclusive) are more likely to exhibit higher foraging allocation (mean 64% for mixed and 67% for exclusive) than the residents (mean 47%, p < 0.0001). The reinforcers did not differ from one another. 

Linear time was not included in the model - instead a significant positive quadratic effect.The quadratic effect was significantly less for reinforcers than residents (p < 0.034). 

**Interpretation:**
Both reinforcers have higher allocations than the residents, probably because residents have overall better foraging efficiency. 

The quadratic trend may be associated with seasonal food availability.

### m6: Weight change

In addition to the movement-based metrics of performance I wanted to look at health check data. Weight change post-release is a good indicator of performance, where some loss is expected but less steep decline (trending towards stability) indicates better performance.

We were unable to compare residents to reinforcers for weight change because we did not have weight measurements for the six individuals released in January 2023 (backpacks fitted in the December trip and released by Mt Rothwell staff rather than me going back down there). So we can only compare reinforcers, but interested to see how the social group memberships contrast.

Unlike the movement data, the study period is for 70 days because weights were taken after the 55 minimum common tracking period. 

```{r}
# read in data and clean up
datam6 <- read_xlsx("data/healthchecks.xlsx") %>%
  clean_names() %>%
  rename(id = identity) %>%
  select(id, date, weight) %>%
  # add metadata
  left_join(select(metadata, c(id, start_date, cohort))) %>%
  drop_na() %>%
  # format dates
  mutate(date = as_date(date),
         start_date = as_date(start_date)) %>%
  # calculate elapsed time and add status
  mutate(elapsed = as.numeric(date - start_date)) %>%
  # keep only reinforcers
  filter(cohort == "Reinforcing") %>%
  # add social group membership %>%
   mutate(social = as_factor(ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed")))) %>%
  # keep only the latest pre-release values and assign to pre/post release
  group_by(id) %>%
  filter(elapsed > 0 | elapsed == max(elapsed[elapsed <= 0])) %>%
  ungroup() %>%
  mutate(status = as_factor(ifelse(elapsed > 0, "post-release", "pre-release"))) %>%
  arrange(id) %>%
  # filter to study period
  filter(elapsed <70)

# plot weight pre and post-release
ggplot(datam6)+
  geom_boxplot(aes(social, weight))+
  theme_minimal()+
  facet_wrap(~status)
```

We have pre and post data for 18 of the 20 reinforcers. All lost weight. The mixed social group started out on average lower than the exclusive group.

Next I calculated the change in weight both in grams and as a proportion of starting weight (to account for variation in body sizes).

```{r}
# calculate weight change in grams and as a proportion of starting weight
sum6 <- datam6 %>%
  select(c(id, social, weight, status)) %>%
  pivot_wider(names_from = status, values_from = weight) %>%
  clean_names() %>%
  drop_na() %>%
  # add change columns
  mutate(diff = pre_release - post_release,
         proportion = diff/pre_release) %>%
  # format social group as factor
  mutate(social = as_factor(social))

# plot total weight differences by social group
ggplot(sum6)+
  geom_boxplot(aes(social, diff))+
  theme_minimal()

# plot proportional weight differences by social group
ggplot(sum6)+
  geom_boxplot(aes(social, proportion))+
  theme_minimal()
```

Although total weight change seems on average lower in the mixed group, proportionally it does not look like a lot of difference.

```{r}
# check distribution of the difference
hist(sum6$diff)
ggqqplot(sum6$diff)

# test whether weight change differs between the social groups
# as total difference
m6a <- glmmTMB(diff ~ social, data = sum6)
summary(m6a)
# and as a proportion of starting weight
m6b <- glmmTMB(proportion ~ social, data = sum6)
summary(m6b)

# predictions
pred6b <- predict_response(m6b, terms = c("social"))

# plot predictions
ggplot(pred6b, aes(x, predicted, colour = x))+
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high))+
  xlab("Social group membership") + 
  ylab("Predicted values of proportion starting weight lost")+
  theme_classic()+
  scale_y_continuous(limits = c(0, 0.3))
```

There is no significant differences between groups for weight loss.

I want to model predicted effects of overall weight change so I can model a geom_line of pre and post translocation (I think the geom_pointrange looks boring).

```{r}
# weight change over time between social groups
m6 <- glmmTMB(weight ~ social * status, data = datam6)
summary(m6)

# predictions
pred6 <- predict_response(m6, terms = c("status", "social"))

# plot predictions
ggplot(pred6, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high, group = group)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab(element_blank())+ 
  ylab("Predicted weight (g)") +
  theme_minimal()
```

Significant effect of status (pre and post release) No difference between groups.

## Figures

Multi-plot of predicted values for all PRBM metrics by social group over time.

```{r}
# set default theme options for all plots
pal <- c("#AFACAC","#2E3EDC", "#07A567")

theme <- function(){
  list(
    geom_line(aes(colour = group)),
    geom_ribbon(alpha = 0.2),
    xlab(element_blank()),
    scale_x_continuous(breaks=seq(0, 50, 10)),
    theme_classic(),
    ggplot2::theme(axis.title.y = element_text(hjust = 0.1, size = 10)),
    scale_color_manual(values = pal,
                       name = "Cohort and social group membership"),
    scale_fill_manual(values = pal,,
                      name = "Cohort and social group membership")
  )
}

# list of plots
g1 <- ggplot(pred1, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  xlab("Days post-reinforcement") + 
  ylab("Daily distance moved (m)")+
  theme()

g2 <- ggplot(pred2, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  xlab("Days post-reinforcement") + 
  ylab("Roost displacement (m)")+
  theme()

g3 <- ggplot(pred3, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  xlab("Days post-reinforcement") + 
  ylab("Distance from release (m)")+
  theme()

g4 <- ggplot(pred4, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  xlab("Days post-reinforcement") + 
  ylab("Home range area (ha)")+
  theme()

g5 <- ggplot(pred5, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  xlab("Days post-reinforcement") + 
  ylab("Time allocated to foraging")+
  theme()

g6 <- ggplot(pred6, aes(x, predicted, fill = group, 
                        ymin = conf.low, ymax = conf.high, group = group)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  theme_classic()+
  xlab(element_blank())+
  ylab("Weight (g)") +
  scale_colour_manual(values = c("#2E3EDC", "#07A567"))+
  scale_fill_manual(values = c("#2E3EDC", "#07A567"))+
  ggplot2::theme(axis.title.y = element_text(hjust = 0.3, size = 10))

# multi plot 3x2
ggarrange(g1, g2, g3, g4, g5, g6,
          ncol = 3, nrow = 2,
          labels = c("A", "B", "C", "D", "E", "F"),
          common.legend = TRUE, legend = "bottom")
```

Multi plot of all effects.

```{r}
# effects
e1 <- plot_model(best1)[["data"]] %>%
  mutate(variable = "Daily distance moved")

e2 <- plot_model(best2)[["data"]] %>%
  mutate(variable = "Roost displacement")

e3 <- plot_model(best3)[["data"]] %>%
  mutate(variable = "Release site fidelity")

e4 <- plot_model(best4)[["data"]] %>%
  mutate(variable = "Home range area")

e5 <- plot_model(best5)[["data"]] %>%
  mutate(variable = "Time allocated to foraging")

e6 <- plot_model(m6)[["data"]] %>%
  mutate(variable = "Weight")

# combine effects
effects <- rbind(e1, e2, e3, e4, e5, e6) %>%
  # add column for point size by strength of evidence (p values)
  mutate(strength  = ifelse(p.stars == "*", 2, 
                            ifelse(p.stars == "**", 3,
                                   ifelse(p.stars == "***", 4, 1))))

# plot effects
ggplot(effects)+
  geom_pointrange(aes(estimate, term, 
                      xmin = conf.low, xmax = conf.high, 
                      size = strength, colour = group),
                  show.legend = FALSE)+
  geom_vline(xintercept=c(0), linetype="longdash")+
  facet_wrap(~variable, scales = "free_x")+
  scale_size_continuous(range = c(0.3, 1))+
  xlab(element_blank())+
  ylab(element_blank())+
  theme_classic()
```

# Statistical analysis residents

We want to know if the residents change their behaviour in response to the reinforcing release. To test this we compare their movement metrics before and after the reinforcement for the same period i.e. 60 days either side. Unlike the reinforcer dates, we are measuring post-release from the *first* reinforcer released, rather than the last - because these 3 days still have potential to impact the residents. 

```{r}
# define pre-release date period
pre_dates <- seq.Date(from = as_date("2023-04-08"), to = as_date("2023-06-06"), by = "day")

# define post-release date period
post_dates <- seq.Date(from = as_date("2023-06-07"), to = as_date("2023-08-05"), by = "day")

# all dates
dates <- c(pre_dates, post_dates)
```

## m7: Distance moved

Do residents change their distance moved after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam7 <- read.csv("results/daily_distance_moved.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as numeric
  mutate(date = as_date(date_bird)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement"))) %>%
  # format date as numeric
  mutate(date = as.numeric(date))

# create social group means
sum7 <- datam7 %>%
  group_by(date) %>%
  summarise(dist = mean(daily_dist),
            upper = dist + std.error(daily_dist),
            lower = dist - std.error(daily_dist)) %>%
  arrange(date)

# plot daily distance over time as social group means
ggplot(sum7, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path() +
  geom_ribbon(alpha = 0.2) +
  xlab("Days post-reinforcement") + 
  ylab("Daily distance moved (m)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()+
  geom_vline(aes(xintercept = as_date("2023-06-07")), colour = "purple")

# distribution of movement data
hist(datam7$daily_dist)
ggqqplot(datam7$daily_dist)

# test difference pre and post reinforcement
m7 <- glmmTMB(daily_dist ~ period * (scale(date) + I(scale(date)^2)) + (1|id), 
              data = datam7,
              na.action = "na.fail")

# model selection
dm7 <- dredge(m7)
dm7

# parsimonious model where delta <2 and fewest predictors 
# in this case only one model (top ranked) had delta AICc <2
best7 <- get.models(dm7, delta<2)[[1]]

# check model
check_model(best7)

# summary
summary(best7)

# plot effects
plot_model(best7)
```

**Results:**
The best fitting model included period (pre or post reinforcement), date (linear and quadratic), the interaction between these, and individual as a random factor.

Residents moved significantly less distance post reinforcement and the trend was different. 

**Interpretation:**


**Plot**

Unlike the reinforcer data, we are comparing the residents pre- and post-reinforcement. So the predictions need to be bounded into valid date range. 

```{r}
# Generate prediction data only within valid date ranges
release_date <- as.numeric(as_date("2023-06-07"))

pred_data_pre <- expand.grid(
  date = seq(min(datam7$date[datam7$period == "pre-reinforcement"]),
             release_date - 1, by = 1),
  period = "pre-reinforcement"
)

pred_data_post <- expand.grid(
  date = seq(release_date, max(datam7$date[datam7$period == "post-reinforcement"]), by = 1),
  period = "post-reinforcement"
)

# Combine and add necessary covariates (date2, id, etc.)
pred7 <- rbind(pred_data_pre, pred_data_post) %>%
  mutate(id = NA)

# Predict values using the valid dataset
values7 <- predict(best7, newdata = pred7, type = "response", se.fit = TRUE) %>%
  as.data.frame() 

# Add predictions to dataframe
pred7 <- pred7 %>%
  mutate(predicted = values7$fit,
         lower = values7$fit - 1.96 * values7$se.fit,
         upper = values7$fit + 1.96 * values7$se.fit) %>%
  # convert date back to date
  mutate(date = as_date(date))

# plot predictions
ggplot(pred7, aes(date, predicted, ymin = lower, ymax = upper, group = period)) +
  geom_line(aes(colour = period))+
  geom_ribbon(aes(fill = period), alpha = 0.2)+
  xlab(element_blank()) + 
  ylab("Predicted values of daily distance moved (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

## m8: Roost fidelty

Do residents change their distance between roosts after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam8 <- read.csv("results/daily_distance_between_roosts.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement"))) %>%
  # without major outliers from Nutmeg beyond the fence
  filter(distance_previous < 2000)

# create cohort mean
sum8 <- datam8 %>%
  group_by(date) %>%
  summarise(distance_previous = mean(distance_previous)) %>%
  arrange(date) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# plot means
ggplot(datam8)+
  geom_boxplot(aes(period, distance_previous))+
  theme_minimal()

# plot residents over time
ggplot(sum8)+
  geom_path(aes(date, distance_previous))+
  geom_vline(aes(xintercept = as_date("2023-06-07")), colour = "purple")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance between consecutive roosts (m)")

# plot as a linear model
ggplot(datam8)+
  geom_smooth(aes(date, distance_previous, colour = period), method = "lm")+
  theme_minimal()+
  xlab("Date") + 
  ylab("Distance between consecutive roosts (m)")
```

The linear model plot is a bit misleading because it's adding a trendline to what is basically static and then a spike either side of release - also I'm unsure why there is a spike just before release. Maybe because I was in the reserve and bothering them?

```{r}
# summarise to period
per8 <- datam8 %>%
  group_by(period, id) %>%
  summarise(distance_previous = mean(distance_previous))

# distribution of movement data
hist(per8$distance_previous)
ggqqplot(per8$distance_previous)

# test difference between the groups with interaction of time
m8 <- lmer(distance_previous ~ period + (1|id), data = per8)
summary(m8)

# check residuals
hist(residuals(m8))
ggqqplot(residuals(m8))
```

No difference in roost site displacement.

## m9: Release-site fidelity

Do residents change their distance from the release site after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam9 <- read.csv("results/daily_roost_distance_from_release.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# create cohort mean
sum9 <- datam9 %>%
  group_by(date) %>%
  summarise(dist_release = mean(dist_release)) %>%
  arrange(date) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# plot means
ggplot(datam9)+
  geom_boxplot(aes(period, dist_release))+
  theme_minimal()

# plot residents over time
ggplot(sum9)+
  geom_path(aes(date, dist_release))+
  geom_vline(aes(xintercept = as_date("2023-06-06")), colour = "purple")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance from release site (m)")

# plot as a linear model
ggplot(datam9)+
  geom_smooth(aes(date, dist_release, colour = period), method = "lm")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance from release site (m)")
```

The residents had already gradually been moving back in from zone 2 to zone 1 but the reinforcement attracted them to the central woodland north of the release site. 

```{r}
# summarise to period
per9 <- datam9 %>%
  group_by(period, id) %>%
  summarise(dist_release = mean(dist_release))

# distribution of movement data
hist(per9$dist_release)
ggqqplot(per9$dist_release)

# test difference between the groups with interaction of time
m9 <- lmer(dist_release ~ period + (1|id), data = per9)
summary(m9)

# check residuals
hist(residuals(m9))
ggqqplot(residuals(m9))
```

Not the best model and weird distribution of data. There is a difference in how far they are from the release site post-release (0.000356).

### Resident change map

I think it would be helpful to visualise their roost locations on a map.

```{r}
ggmap(map_z15)+
  # plot roosts colour by time
  geom_point(aes(longitude, latitude, colour = date),
             size = 2, data = datam8, inherit.aes = FALSE)+
  # add release location
  geom_point(aes(144.434323, -37.902374), 
             colour = "white", size = 5, shape = 13, inherit.aes = FALSE)+
  # add fence
  geom_spatvector(data = mtr, inherit.aes = FALSE, fill = NA, colour = "white",
                  linetype = "longdash")+
  # wrap by period
  facet_wrap(~period)+
  # theme options
  scale_colour_viridis_c(trans = "date", name = "2023")+
  theme_void()+
  scale_y_continuous(expand = expansion(mult = c(0, 0.01)))+
  theme(legend.position="bottom",
        legend.key.width = unit(4, 'cm'),
        strip.text = element_text(size = 15))
```

## m10: Home range size

Do residents change their home range size after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam10 <- read.csv("results/daily_hr_area.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement"))) %>%
  # remove crazy outlier from Nutmeg's excursion
  filter(area < 100)

# create cohort mean
sum10 <- datam10 %>%
  group_by(date) %>%
  summarise(area = mean(area)) %>%
  arrange(date) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# plot means
ggplot(datam10)+
  geom_boxplot(aes(period, area))+
  theme_minimal()

# plot residents over time
ggplot(sum10)+
  geom_path(aes(date, area))+
  geom_vline(aes(xintercept = as_date("2023-06-06")), colour = "purple")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Home range size (ha)")

# plot as a linear model
ggplot(datam10)+
  geom_smooth(aes(date, area, colour = period), method = "lm")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Home range size (ha)")
```

Doesn't look like much difference.

```{r}
# summarise to period
per10 <- datam10 %>%
  group_by(period, id) %>%
  summarise(area = mean(area))

# distribution of movement data
hist(per10$area)
ggqqplot(per10$area)

# test difference between the groups with interaction of time
m10 <- lmer(area ~ period + (1|id), data = per10)
summary(m10)

# check residuals
hist(residuals(m10))
ggqqplot(residuals(m10))
```

No difference. 

## Time over the fence

I suspect the flightless reinforcers acted as an anchor to the residents, most of whom had regained flight. How many days (night technically) over the fence?

```{r}
# read in night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # format time as posixct
  mutate(time_local = as.POSIXct(time_local),
         date_bird = as_date(date_bird)) %>%
  # add cohort info
  left_join(select(metadata, c(id, cohort))) %>%
  # keep only residents
  filter(cohort == "Resident") %>%
  # pre and post release period dates
  filter(date_bird %in% dates)

# convert to spatial points
points <- data_night %>%
  vect(geom = c("longitude", "latitude"), crs = "EPSG:4326")

# Find points outside fence
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside fence 
ggmap(map_z14)+
  geom_point(data=outside, aes(x, y, colour = id), alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_d()+
  theme_void()

# Days with points outside
excursion <- outside %>%
  group_by(id, date_bird) %>%
  summarise(count = length(id)) %>%
  # filter days <10 points unlikely to be an excursion
  filter(count >= 10)
```

It's really only Nutmeg and Marmalade with flight at this stage, so insufficient replication to answer this question.

# Survival analysis

## Reinforcers and residents

Do reinforcers survive better than the residents? 

This is hard to answer because not tracked as long and some birds were subsequently moved to Orana (right censored data). Attempt to answer this using Kaplan Meier Analysis

Start by looking at the overall survival probabilities for all birds.

```{r m6}
# Format data for Kaplan Meier Analysis - where death is TRUE i.e. 1
surv_data <- metadata %>%
  # remove columns not needed
  dplyr::select(!c(location, abbbs, band, alive, release_year)) %>%
  # add survival time (persistence) - right censored data
  mutate(time = end_date - start_date) %>%
  # add status - whether death occurs
  mutate(status = ifelse(is.na(mortality), 0, 1))

km <- with(surv_data, Surv(time, status))
  
# Fit a basic survival model
kmfit <- survfit(Surv(time, status) ~ 1, data = surv_data)

# Estimated survival probabilities
summary(kmfit, times = c(1, 10, 30, 55, 100, 365))

# plot
autoplot(kmfit)
```

The probability of survival to 1 year is 50% (CI: 34-75%). The probability of survival to 55 days (the study period) is 91% (CI: 83-100%).

Next we compare survial by cohorts.

```{r}
# Fit a survival model by cohort
kmfit_cohort <- survfit(Surv(time, status) ~ cohort, data = surv_data)

summary(kmfit_cohort, times = c(1,30,55))

# plot
autoplot(kmfit_cohort)

# Fit Cox Model
cox <- coxph(Surv(time, status) ~ cohort, data = surv_data)
summary(cox)
```

The probability of survival to 55 days for residents is 87% (CI: 71-100%) and for reinforcers is 95% (CI: 86-100%). So reinforcers are slightly more likely to survive, however this effect is not significant (p=0.754). There were two disease events (one in each cohort) that accounted for most of the early deaths. Potentially the stress of translocation caused these individuals to succumb to illness. 

## Reinforcers by social group

During the social analysis step we found that post-reinforcement there were two sub-groups to the community:

  1) a group with just reinforcers, and 
  2) a blended group of all remaining residents and half the reinforcers.
  
I hypothesise the group with the residents would survive better because of the enhanced potential for learning. 

Compare to 55 days (minimum common denominator deployment period for reinforcers).

```{r}
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")

# Format data for Kaplan Meier Analysis - where death is TRUE i.e. 1
surv_data <- metadata %>%
  # remove columns not needed
  dplyr::select(!c(location, abbbs, band, alive, release_year)) %>%
  # add survival time (persistence) - right censored data
  mutate(time = end_date - start_date) %>%
  # add status - whether death occurs
  mutate(status = ifelse(is.na(mortality), 0, 1)) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "exclusive", "mixed")) %>%
  # select only reinforcers
  filter(cohort == "Reinforcing")

# Fit a survival model by social group
kmfit_social <- survfit(Surv(time, status) ~ social, data = surv_data)

summary(kmfit_social, times = c(1,30,54))

# plot
autoplot(kmfit_social)

# Fit Cox Model
cox <- coxph(Surv(time, status) ~ social, data = surv_data)
summary(cox)
```

No difference in survival for reinforcers of different social memberships.