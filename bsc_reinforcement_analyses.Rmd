---
title: "bsc_reinforcement_analyses"
author: "Shoshana Rapley"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)

# Packages
pacman::p_load(adehabitatHR, amt, atlastools, beepr, effects, emmeans, ggeffects, ggfortify, ggmap, ggnewscale, ggforce, ggpubr, ggraph, ggridges, ggspatial, glmmTMB, gtools, igraph, janitor, jtools, lme4, lmerTest, move2, momentuHMM, MuMIn, performance, plotrix, readxl, scales, scattermore, sf, sjPlot, sp, suncalc, survival, survminer, terra, tidygraph, tidyterra, tidyverse, viridis, wildlifeDI)

# Google API key for ggmaps
ggmap::register_google(key = readChar("apikey_google.txt", nchars = file.info("apikey_google.txt")$size))

# Background map MR zones 1 and 2
map_z14 <- get_map(c(144.4380, -37.9000), zoom=14, maptype = "satellite")
map_z15 <- get_map(c(144.4380, -37.9000), zoom=15, maptype = "satellite")

# Metadata - translocation information
metadata  <- read.csv("data/metadata.csv") %>%
  clean_names() %>%
  rename(id = identity,
         mortality = mortality_or_capture) %>%
  mutate(start_date = as_date(dmy(start_date)),
         end_date = as_date(dmy(end_date)),
         mortality = as_date(dmy(mortality)))

# Define fence polygons (zones 1 and 2)
mtr <- rbind(
  ## zone 1
  c(-37.897319, 144.429048), # S end of NW diagonal
  c(-37.894066, 144.432334), # N end of NW diagonal, i.e. NW corner
  c(-37.894749, 144.438305), # bend at main gate 
  c(-37.894693, 144.438324), # main gate
  c(-37.894803, 144.439214), # bend before N Z1/2 gate
  c(-37.894718, 144.439337), # N Z1/2 gate, i.e. NE corner 
  ## zone 2
  c(-37.892433, 144.440236), # N boundary internal aviary/Z2 i.e. NW corner
  c(-37.892803, 144.443374), # Z2 northern boundary bend 1
  c(-37.893634, 144.444076), # Z2 northern boundary bend 2
  c(-37.894585, 144.447739), # N end of Z2/Z3 boundary, i.e. NE corner
  c(-37.896515, 144.446789), # Z2/Z3 boundary bend 1
  c(-37.896726, 144.446099), # Z2/Z3 boundary bend 2
  c(-37.897964, 144.445706), # Z2/Z3 boundary bend 3
  c(-37.899960, 144.444517), # S end of Z2/Z3 boundary, i.e. SE corner
  c(-37.899908, 144.444288), # Z2/btrw NE corner
  c(-37.898280, 144.440662), # Z1/btrw pen NW corner
  ## zone 1
  c(-37.900692, 144.440368), # Z1/btrw SW corner
  c(-37.902610, 144.443002), # Z1/btrw SE corner
  c(-37.909538, 144.439648), # Z1 SE corner
  c(-37.908999, 144.434965), # Z1 southern boundary bend 1
  c(-37.907537, 144.433359), # Z1 southern boundary bend 2
  c(-37.905958, 144.430140), # Z1 southern boundary bend 3
  c(-37.905486, 144.429479), # Z1 southern boundary bend 4
  c(-37.904649, 144.427566), # Z1 SW corner
  c(-37.897319, 144.429048)  # S end of NW diagonal
  ) %>%  vect(type = "polygons", crs = "EPSG:4326") %>% 
  # transpose
  t() %>%
  # add a buffer for GPS accuracy of 30m for analysis, and 10m for mapping
  #buffer(10)
  buffer(30)
```

# Introduction

Reinforcement is a form of conservation translocation used to stabilise or enhance populations. Reinforcement is also a stage within other forms of translocation, which usually involve multiple release cohorts and therefore have cohorts released into the presence of conspecifics. Even a reintroduction project will have conspecifics present from the second release. Benefits of reinforcing release are assumed but rarely empirically tested â€“ and if they are its usually from perspective of reinforcing individuals, not the population as a whole. Outcomes of reinforcement are mediated by social interactions, which are also assumed but not often empirically tested. 

Here we test the outcomes of reinforcement for a population of bush stone-curlew where all individuals in the population (resident and reinforcing) are accounted for and tracked with GPS. We ask: do the cohorts integrate? Do social interactions benefit the reinforcing cohort? And, do the residents change their behaviour?

## Translocation

We translocated 35 adult captive-bred bush stone-curlews from Mt Rothwell captive colony to Mt Rothwell Zone 1 (fenced sanctuary) in two stages. The first (pilot) cohort of 16 birds was released between October 2022 and June 2023. The second (reinforcing) cohort of 20 birds was released in June 2023. One bird in the first cohort was taken back into captivity after a single day and re-released in the second cohort; hence total 35 individuals.

## Telemetry

All translocated birds were fitted with a GPS tracker (Ornitrak20 from Ornitela) with a duty cycle of a fix every 60 seconds (or reduced when battery low). Telemetry data were stored on Movebank. We collected data from the release date of each individual until the 12th of January 2024 (when GPS devices were removed from all remaining birds except one, ahead of the 3G shutdown).

The study period for this analysis ends 5th August 2023, when half of the reinforcing cohort were translocated to a secondary site (Orana).

# Data cleaning

High throughput animal tracking data require filtering to remove erroneous points, while maintaining real movement data. We follow the workflow by [Gupte et al. (2021)](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.13610), that is:

1) temporal filtering
2) filtering by quality covariates
3) filtering biologically unrealistic movement
4) median smoothing

## Test pipeline

We first tested the pipeline with a subset of the data (birds "Marmalade" & "Fauna"). Marmalade left the fenced area during the study while Fauna did not. 

### 1) Temporal filtering

We removed points after the end of the study period (5/8/23 at the start of next experiment - translocation to Orana).

```{r}
# import data from movebank
data_raw <- readr::read_csv("movebank/Fauna01.csv", show_col_types = FALSE) %>%
  rbind(readr::read_csv("movebank/Marmalade01.csv", show_col_types = FALSE)) %>%
  clean_names() %>%
  # Time in posix format
  mutate(datetime = as.POSIXct(study_local_timestamp, "%Y-%m-%d %H:%M:%S"),
         date = as.Date(datetime)) %>%
  # Remove days after end of tracking period
  filter(date < "2023-08-04") %>%
  rename(id = individual_local_identifier)

# plot raw data
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow", alpha = .6)+
  theme_void()+
  facet_wrap(~id)
```

### 2) Filtering by quality covariates

We filter using the following covariates: 

* satellite count
* horizontal dilution of precision (HDOP)
* altitude

In the past I've found filtering by satellite count and hdop can remove errors, but when applied with the wrong parameters they can have a high rate of false positives (removing real movement) and low rate of true positives (removing unrealistic movement) so we don't want to be overly aggressive with the application of these filters.

```{r}
# Histogram of satellite vales
hist(data_raw$gps_satellite_count)

# Plot track, colour by satellite values
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_raw, aes(location_long, location_lat, colour = gps_satellite_count))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

Most points have a satellite count >=4. Not many of the obvious spikes have low satellite count. We'll filter to include only satellite count >=4. 

Now look at the horizontal dilution of precision (HDOP).

```{r}
# Histogram of hdop vales
hist(data_raw$gps_hdop)

# Plot track, colour by hdop values
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_raw, aes(location_long, location_lat, colour = gps_hdop))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

There are a handful of massive hdop values (5-15) but the vast majority are =<2. Again the obvious spikes don't have high hdop values. We'll filter to only include hdop <=2. 

Next we'll apply filtering on the basis of altitude. 

Incorrect GPS fixes often have incorrect altitude. High altitude was not expected as no birds were undertaking long-distance flight, which is the only time high altitude is possible. All birds were wing-clipped on release and some later moulted and undertook short-distance flight, but not at high altitude. 

First we need to find flight height altitude by correcting for ground elevation. We are using the [FABDEM (Forest And Buildings removed Copernicus 30m DEM)](https://gee-community-catalog.org/projects/fabdem/).

```{r}
# read in FABDEM
fabdem <- rast("data/S38E144_FABDEM_V1-0.tif") 

# convert data to spatial points
coords <- data_raw %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Extract dem and add to dataframe
data_alt <- data_raw %>%
  mutate(terra::extract(fabdem, coords, ID = FALSE)) %>%
  rename(elevation = "S38E144_FABDEM_V1-0") %>%
  # calculate flight height
  mutate(altitude = height_above_msl - elevation)

# Histogram altitude
hist(data_alt$altitude)

# Summary statistics altitude
summary(data_alt$altitude)
quantile(data_alt$altitude, probs = 0.95)

# Plot track, colour by altitude values
ggmap(map_z13)+
  geom_path(data=data_alt, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_alt, aes(location_long, location_lat, colour = altitude))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

The median altitude (above the ground surface) was 9m. The min (-2060m) and max (8313m) altitude were considered unrealistic. Many of the obvious spikes have very high or negative altitude. 

We cut off the maximum altitude at 60 (just above the 0.95 quartile) and the minimum to -10m (ground level allowing for some error).

```{r}
# Apply quality covariate filters
data_qfilt <- data_alt %>%
  filter(gps_satellite_count >= 4) %>%
  filter(gps_hdop <=2) %>%
  filter(altitude < 60 & altitude >-10)

# Plot effect of filtering
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "purple", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow")+
  geom_point(data=data_qfilt, aes(location_long, location_lat), 
             colour = "purple")+
  theme_void()+
  facet_wrap(~id)
```

This successfully filtered out most of the obvious spikes.

### 3) Filtering biologically unrealistic movement

To remove spikes in the data we can filter out positions with extreme incoming and outgoing speeds. First we need to define biologically realistic incoming and outgoing speeds.

```{r}
# Append turning angle, incoming/outgoing speeds to data frame per bird
birds <- unique(data_raw$id)

data_speed <- data.frame()

for(i in 1:length(birds)){
 subset <- filter(data_qfilt, id == birds[i])

 temp <- subset %>%
   mutate(speed_in  = atl_get_speed( 
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("in")),
    speed_out = atl_get_speed(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("out")),
    angle = atl_turning_angle(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime"),
    speed_delta = abs(speed_in - speed_out)
    )
 
 data_speed <- rbind(data_speed, temp)
}

# Histogram incoming speeds
hist(data_speed$speed_in)

# Summary statistics incoming speeds
summary(data_speed$speed_in)
quantile(data_speed$speed_in, probs = 0.99, na.rm = TRUE)

# Histogram outgoing speeds
hist(data_speed$speed_out)

# Summary statistics outgoing speeds
summary(data_speed$speed_out)
quantile(data_speed$speed_out, probs = 0.95, na.rm = TRUE)

# Histogram turning angle
hist(data_speed$angle)

# Summary statistics turning angle
summary(data_speed$angle)

# Histogram difference between incoming and outgoing speed
hist(data_speed$speed_delta)

# Summary statistics difference between incoming and outgoing speed
summary(data_speed$speed_delta)
quantile(data_speed$speed_delta, probs = 0.95, na.rm = TRUE)

# Plot track, colour by speed
ggmap(map_z14)+
  geom_path(data=data_speed, aes(location_long, location_lat), colour = "white")+
  geom_point(data=data_speed, aes(location_long, location_lat, colour = speed_delta))+
  scale_colour_viridis_c()+
  theme_void()+
  facet_wrap(~id)
```

Speeds were usually <2m/s and outgoing speeds while turning are likely <1m/s. A sharp turning angle was defined as <90 degrees. Sharp increase/decrease in speed also isn't expected, with the vast majority of difference between incoming and outgoing speed 0.1m/s.

We defined biologically realistic movement as speeds <2m/s (a note of caution: this shouldn't be used when the birds are undertaking long distance movements as faster speeds may be possible e.g. while gliding on wind), turning speeds of 0.5m/s, and delta speed as 0.4m/s. 

```{r}
# Apply turning angle filtering
data_sfilt <- data_speed %>%
  filter(speed_in < 2) %>%
  filter(speed_delta < 0.4) %>%
  filter(!(speed_out >0.5 & angle <90))

# Plot effect of filtering
ggmap(map_z14)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "purple", alpha = .6)+
  geom_point(data=data_raw, aes(location_long, location_lat), 
             colour = "yellow")+
  geom_point(data=data_qfilt, aes(location_long, location_lat), 
             colour = "orange")+
  geom_point(data=data_sfilt, aes(location_long, location_lat), 
             colour = "purple")+
  theme_void()+
  facet_wrap(~id)
```

### 4) Median smoothing

Even after speed/angle filtering, we retain some smaller-scale jitter. These are challenging to remove as they lie within the bounds of realistic movement. Median resampling is a method of smoothing the track to reduce jitter. We apply it sparingly, because an overly aggressive approach will cut down on real track tortuousity. 

```{r}
# Apply median smooth by bird
data_smooth <- data.frame()

for(i in 1:length(birds)){
  
  subset <- filter(data_sfilt, id == birds[i])
  
  temp <- atl_median_smooth(data = subset, x = "location_lat", y = "location_long",
                                  time = "datetime", moving_window = 3)
  
  data_smooth <- rbind(data_smooth, temp)
}

# Plot effect of smoothing
ggmap(map_z13)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)

# And zoom in to the fenced area
ggmap(map_z15)+
  geom_path(data=data_raw, aes(location_long, location_lat), 
            colour = "yellow", alpha = .6)+
  geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)

# And visualise without filtered out data
ggmap(map_z15)+
    geom_path(data=data_smooth, aes(location_long, location_lat), 
            colour = "purple", alpha = .7)+
  facet_wrap(~id)
```

*_Visual check using fence polygon._*
We know Fauna didn't leave the study site during the tracking period so this is a good way to check if filtering was successful. Filter for points from "Fauna" outside of the polygon. 

```{r}
# Convert df to points
points <- data_smooth %>%
  filter(id=="Fauna") %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Find points outside polygons
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside polygon 
ggmap(map_z15)+
  geom_point(data=outside, aes(x, y), colour = "yellow", alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_c()+
  theme_void()
```

There are only 65 points outside the fence (given a 30m buffer) which is within tolerance. Interestingly they are all clustered on the southern and eastern fenceline, perhaps there was something about the topography or vegetation in that area that pronounced the errors.

Based on this test subset, I am happy with the filtering parameters for this location.

## Apply filtering 

We apply all of the above steps to the full dataset. 

### 1) Temporal filtering

We removed points after the end of the study period (5/8/23 at the start of next experiment - translocation to Orana).

```{r}
# Import data from movebank
data_raw <- readr::read_csv(fs::dir_ls(path = "movebank")) %>%
  clean_names() %>%
  # Time in posix format
  mutate(datetime = as.POSIXct(study_local_timestamp, "%Y-%m-%d %H:%M:%S"),
         date = as.Date(datetime)) %>%
  # Remove days after end of study
  filter(date < "2023-08-04") %>%
  rename(id = individual_local_identifier)
```

### 2) Filtering by quality covariates

We used the following quality covariates:

* Altitude: set to a minimum of -10m (ground level allowing for some error) and a maximum of 60 (just above the 0.95 quartile on test data)
* HDOP: set to a maximum of 2
* Satellite count: set to a minimum of 4

```{r}
# read in FABDEM
fabdem <- rast("data/S38E144_FABDEM_V1-0.tif") 

# convert data to spatial points
coords <- data_raw %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326")

# Extract dem and add to dataframe
data_alt <- data_raw %>%
  mutate(terra::extract(fabdem, coords, ID = FALSE)) %>%
  rename(elevation = "S38E144_FABDEM_V1-0") %>%
  # calculate flight height
  mutate(altitude = height_above_msl - elevation)

# Apply quality covariate filters
data_qfilt <- data_alt %>%
  filter(gps_satellite_count >= 4) %>%
  filter(gps_hdop <=2) %>%
  filter(altitude < 60 & altitude >-10)

# Filtering effect
print(paste("Percentage original data removed: ", round(((nrow(data_raw)-nrow(data_qfilt)) / nrow(data_raw))*100), "%", sep = ""))
```

Percentage original data removed: 28%

### 3) Filtering biologically unrealistic movement

We defined (from test data) biologically realistic movement as speeds <2m/s (a note of caution: this shouldn't be used when the birds are undertaking long distance movements as faster speeds may be possible e.g. while gliding on wind), turning speeds of 0.5m/s, and delta speed as 0.4m/s. 

```{r}
# Append turning angle, incoming/outgoing/delta speeds to data frame per bird
birds <- unique(data_raw$id)

data_speed <- data.frame()

for(i in 1:length(birds)){
 subset <- filter(data_qfilt, id == birds[i])

 temp <- subset %>%
   mutate(speed_in  = atl_get_speed( 
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("in")),
    speed_out = atl_get_speed(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime", type = c("out")),
    angle = atl_turning_angle(
           data = subset, x = "utm_easting", y = "utm_northing", time = "datetime"),
    speed_delta = abs(speed_in - speed_out)
    )
 
 data_speed <- rbind(data_speed, temp)
}

# Apply turning angle and speed filtering
data_sfilt <- data_speed %>%
  filter(speed_in < 2) %>%
  filter(speed_delta < 0.4) %>%
  filter(!(speed_out >0.5 & angle <90))

# Filtering effect
print(paste("Percentage original data removed: ", round(((nrow(data_qfilt)-nrow(data_sfilt)) / nrow(data_qfilt))*100), "%", sep = ""))
```

Percentage original data removed: 7%

### 4) Median smoothing

To remove small-scale jitter. We used the smallest possible moving window (3) to retain as much real movement as possible. 

```{r}
# Apply median smooth by bird
data_smooth <- data.frame()

for(i in 1:length(birds)){
  
  subset <- filter(data_sfilt, id == birds[i])
  
  temp <- atl_median_smooth(data = subset, x = "location_lat", y = "location_long",
                                  time = "datetime", moving_window = 3)
  
  data_smooth <- rbind(data_smooth, temp)
}

# Plot smoothed data
ggmap(map_z14)+
  geom_path(data=data_smooth, aes(location_long, location_lat, colour = id), alpha = .7)+
  scale_colour_viridis_d()+
  theme_void()
```

Dropping unneeded columns to reduce the size of the saved file. Originally I kept the utm easting and northing columns from movebank but I noticed a mismatch between the cleaned lat/lon and the utm, so have elected to transform the data when required instead. 

```{r}
# Convert data to spatial and reproject in utm
points <- data_smooth %>%
  vect(geom = c("location_long", "location_lat"), crs = "EPSG:4326") %>%
  # re-project into zone 55S
  project("EPSG:32755") %>%
  st_as_sf()

# allocate utm coords
coords <- st_coordinates(points$geometry)

# format data frame for saving to disk
data <- data_smooth %>%
  # select columns to keep
  dplyr::select(c("id", "datetime", "timestamp", "location_long", "location_lat", "acceleration_raw_x", "acceleration_raw_y", "acceleration_raw_z", "external_temperature", "altitude")) %>%
  # rename columns
  rename(longitude = location_long,
         latitude = location_lat,
         time_local = datetime,
         time_utc = timestamp) %>%
  # add utm xy columns 
  mutate(easting = st_coordinates(points$geometry)[,1],
         northing = st_coordinates(points$geometry)[,2]) %>%
  # add cohort metadata
  left_join(dplyr::select(metadata, c("id","cohort")))

# save to disk
write.csv(data, "data/data_cleaned.csv", row.names = FALSE)
```

# Movement analysis

Here we calculate PRBM metrics from tracking data to assess the establishment of reinforcers. The reinforcement period spans the 55 days between 11 June 2023 (last reinforcer released) and the 5th August 2023 (end of study period when reinforcers are translocated to Orana).

We also compare the response of the residents pre- and post-reinforcement to see if the reinforcement changes the behaviour of the residents. The pre-reinforcement period spans the 142 days between 16th January 2023 (last resident released) to 7th June 2023 (first reinforcer released).

I run these for all the dates to make it simpler (one dataframe instead of multiple per metric for each time period) and then filter to dates as required.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne"))

# Plot cleaned data to check
ggmap(map_z14)+
  geom_path(data=data, aes(longitude, latitude, colour = id), alpha = .7)+
  scale_colour_viridis_d()+
  theme_void()
```

Calculate basic summary statistics. 

```{r}
# Summary statistic: number of tracked days
length(unique(data$date))

# Summary statistic: total number of tracked days per bird
print(data %>%
  group_by(id) %>%
  summarise(length(unique(date))), n=35)

print(data %>%
  group_by(id) %>%
  summarise(days = length(unique(date))) %>%
  summarise(birddays = sum(days)))
```

Birds were tracked for a total of 284 days between October 2022 and August 2023 for a total of 3533 tracking days (sum of each bird's tracking duration). 

Wobbles and Star tracked for less than two weeks and excluded from further analyses. 

```{r}
data <- data %>%
  filter(!id %in% c("Wobbles", "Star"))
```

## Day/night

Rather than splitting data on calendar days (because they are nocturnal and movement continues over midnight) we want to split the data by diurnal and nocturnal movement. We use the sunrise/sunset time (from suncalc) to add bird date to the data. This also provides additional filtering, because jitter while the bird is stationary at its roost overinflates movement estimates, so counting only noctunal movement gives a better estimate of real movement. Additionally, we add "bird date" to the data, a 24-hour period commencing at sunset (a better indication of a "day" from the bird's perspective than calendar day), so that movements over a night (crossing midnight) can be allocated to the correct grouping. 

```{r}
# Calculate if time is pre/post dawn/dusk
suntime <- getSunlightTimes(date = unique(data$date),
                            lat = -37.90,
                            lon = 144.43,
                            keep = c("sunrise", "sunset"),
                            tz = "Australia/Melbourne") %>%
  subset(dplyr::select = -c(lat, lon)) 

# Append to data frame
data_sun <- left_join(data, suntime) %>%
  mutate(tod = ifelse(time_local>sunrise & time_local<sunset, "day", "night")) %>%
  relocate(time_local, .after = tod) %>%
  na.omit()

# Plot to check - using scattermore to speed up display
ggplot(data_sun)+
  geom_scattermore(aes(easting, northing, colour = tod), alpha = 0.6)+
  coord_sf()+
  theme_void()

# Add "bird date" 
data_sun <- data_sun %>%
  # add column for how long past/to sunset
  mutate(suntime = as.numeric(difftime(time_local, sunset, units = "hours"))) %>%
  # negative sun-time values indicate it's the next day - 
  # therefore allocate previous day calendar date as "bird date"
  mutate(date_bird = as_date(ifelse(suntime > 0, date, date - 1)))

# Save day data
data_day <- data_sun %>%
  filter(tod == "day")

write.csv(data_day, "data/data_clean_day.csv", row.names = FALSE)

# Save night data
data_night <- data_sun %>%
  filter(tod == "night")

write.csv(data_night, "data/data_clean_night.csv", row.names = FALSE)
```

## Distance moved

How long does it take birds to settle? 

Distance moved per night over time. Calculation is done per bird per day (bird date).

Test with one bird, "Fauna". 

```{r}
# read in night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # format time as posixct
  mutate(time_local = as.POSIXct(time_local))

# format as amt and calculate step lengths
steps <- data_night %>%
  filter(id=="Fauna") %>%
  # format as amt track - add columns as needed
  make_track(.x = easting, .y = northing, .t = time_local, id = id, date_bird = date_bird) %>%
  steps(keep_cols = "start")

# summarise per bird date
summary <- steps %>%
  group_by(date_bird) %>%
  summarise(daily_dist = sum(sl_))

# plot histogram
hist(summary$daily_dist)

# plot over time
ggplot(summary, aes(date_bird, daily_dist))+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_void()
```

Apply to all birds.

```{r}
# for loop to calculate distance moved per bird date
birds <- unique(data_night$id)

distance_daily <- data.frame()

for(i in 1:length(birds)){
  # Subset to bird, convert data to spatial and reproject in utm
    points <- data_night %>%
    # subset to bird
    filter(id==birds[i]) %>%
    vect(geom = c("longitude", "latitude"), crs = "EPSG:4326") %>%
    # re-project into zone 55S
    project("EPSG:32755") %>%
    st_as_sf()

  # save coords
  coords <- st_coordinates(points$geometry)

  # format as amt and calculate step lengths
  steps <- points %>%
    # get utm xy columns 
    mutate(easting = st_coordinates(points$geometry)[,1],
         northing = st_coordinates(points$geometry)[,2]) %>%
    # format as amt track 
    make_track(.x = easting, .y = northing, .t = time_local, id = id, 
               # add additional columns as needed
               date_bird = date_bird) %>%
    steps(keep_cols = "start")

  # summarise per bird date
  summary <- steps %>%
    group_by(date_bird) %>%
    summarise(daily_dist = sum(sl_)) %>%
    mutate(id = birds[i])
  
  # write out
  distance_daily <- rbind(distance_daily, summary)
  
  # alert me
  print(paste("finished calculation for ", birds[i], sep = ""))
}

# save output
write.csv(distance_daily, "results/daily_distance_moved.csv", row.names = FALSE)
```

Plot distance moved as a density plot and movement over time, per bird.

```{r}
# plot histogram
hist(distance_daily$daily_dist)

# plot density by bird
ggplot(distance_daily)+
  geom_density_ridges(aes(daily_dist, id, fill = id), alpha = 0.7)+
  scale_fill_viridis_d()+
  theme_bw()+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  theme(legend.position = "none")+
  xlim(0,7000)+
  scale_y_discrete(expand = expansion(add = c(0, 2)))+
  xlab("Distance moved daily (m)") + 
  theme(axis.title.y=element_blank())
```

## Roost establishment

Look at the same idea as the previous section (a metric of establishment) but with diurnal roost movement rather than nightly distanced moved. 

First calculate roost locations. Test with one bird.

```{r}
# read in day data
data_day <- read.csv("data/data_clean_day.csv")

# filter to test bird
test <- data_day %>%
  filter(id == "Aurora")

# plot roosts coloured by date
ggmap(map_z15)+
  geom_density2d(data=test, aes(longitude, latitude, colour = date), inherit.aes = FALSE)+
  theme_void()+
  scale_colour_viridis_d()+
  theme(legend.position = "none")

# plot a series of dates to see if multiple roosts occur
dates <- seq(as.Date("2023-01-01"), as.Date("2023-01-12"), "days")
span <- filter(test, date %in% dates)

ggmap(map_z15)+
  geom_density2d(data=test, aes(longitude, latitude), colour = "yellow", inherit.aes = FALSE)+
  theme_void()+
  facet_wrap(~date)
```

On visual inspection, the vast majority of dates have a single roost. 

Approximate roosts positions using kmeans. Apply to all birds

```{r}
# locate kmeans center for a roost per bird per day
birds <- unique(data_day$id)
days <- unique(data_day$date)

roosts <- data.frame()

for (i in 1:length(birds)){
  for (j in 1:length(days)){
    
    #subset by bird and date
    subset <- subset(data_day, id == birds[i] & date == days[j],
                    dplyr::select= c(easting, northing))
    # skip days where not enough points
      if (length(subset$easting)<4){next}
    
    # find kmean centers
    kmean <- kmeans(subset, centers=1)
    
    # compile data
    out <- as.data.frame(cbind(kmean$centers, npoints = kmean$size)) %>%
      mutate(id = birds[i], date = days[j])
    
    roosts <- rbind(roosts, out)
    
  }
  print(paste("Finished calculation for ", birds[i], sep = ""))
}

# characteristics of cluster data
hist(roosts$npoints)
summary(roosts$npoints)

# plot roosts by number of points
ggplot(roosts)+
  geom_point(aes(easting, northing, size = npoints, colour = id))+
  geom_path(aes(easting, northing, group = id), alpha = 0.3)+
  coord_sf()+
  scale_colour_viridis_d()+
  theme_bw()

# plot for a single bird with date as colour
ggplot(data = filter(roosts, id == "Marmalade"))+
  geom_point(aes(easting, northing, size = npoints, colour = as.Date(date)))+
  geom_path(aes(easting, northing, group = id), alpha = 0.3)+
  coord_sf()+
  scale_colour_viridis_c()+
  theme_bw()+
  theme(axis.line=element_blank(),
      axis.text.x=element_blank(),
      axis.text.y=element_blank(),
      axis.ticks=element_blank(),
      axis.title.x=element_blank(),
      axis.title.y=element_blank())

# save daily roost locations
write.csv(roosts, "results/daily_roost_location.csv", row.names = FALSE)
```

How far between consecutive roosts? 

```{r}
# read in roost locations, format as spatial
roosts <- read.csv("data/daily_roost_location.csv") %>%
  dplyr::select(!"npoints") %>%
  vect(geom = c("easting", "northing"), crs = "EPSG:32755") %>%
  st_as_sf()

# calculate distance between successive roosts per bird
birds <- unique(roosts$id)
distance_roosts <- data.frame()

for(i in 1:length(birds)){
  
  # subset to individual
  points <- filter(roosts, id==birds[i]) %>%
    # date as posix
    mutate(date = as.POSIXct(date, format = "%Y-%m-%d")) %>%
    # ensure arranged by date
    arrange(date) %>%
    #add lag column for geometry comparison
    mutate(previous = lag(geometry))
  
  # allocate the release location as the first location
  release <- st_sfc(st_point(c(274423.45, 5801912.85) ), crs = 32755) %>%
    st_as_sf()
  
  points$previous[1] <- release$x
  
  # calculate the distance between successive points
  out <- points %>%
    mutate(distance_previous = 
             as.numeric(st_distance(points$geometry, points$previous, by_element = TRUE))) %>%
    dplyr::select(!"previous")
  
  # write out
  distance_roosts <- rbind(distance_roosts, out)
}

# hist
hist(distance_roosts$distance_previous)

# transform to latlon
distance_roosts_latlon <- distance_roosts %>%
  vect() %>%
  project("EPSG:4326") %>%
  st_as_sf() %>%
  mutate(date = as_date(date))

# plot roosts with colour as distance from previous
ggplot()+
  geom_sf(data = distance_roosts_latlon, aes(colour = distance_previous))+
  scale_colour_viridis_c()+ 
  theme_void()

# plot roosts with colour as date
ggmap(map_z15)+
  geom_sf(data = distance_roosts_latlon, aes(colour = date), inherit.aes = FALSE)+
  scale_colour_viridis_c(trans = "date")+
  theme_void()
```

There is a day Nutmeg seems to have spent 3km away from their previous roost. IS that true? Investigate this outlier.

```{r}
# Read in cleaned data 
nutmeg <- read.csv("data/data_cleaned.csv") %>%
  # select only Nutmeg
  filter(id == "Nutmeg") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne")) 

# Plot
ggmap(map_z13)+
  geom_point(data=nutmeg, aes(longitude, latitude, colour = date), alpha = 0.8)+
  scale_colour_viridis_c()+
  geom_path(data=nutmeg, aes(longitude, latitude), colour = "white", alpha = 0.4)+
  theme_void()
```

Yep that looks true! On 5-11-23, Nutmeg goes on a flight to the west of the sanctuary, stays over the day near the quarry, then returns to the sanctuary the next day. 

Points outside of fence?

```{r}
# Convert df to points
points <- vect(distance_roosts_latlon)

# Find points outside polygons
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside polygon 
ggmap(map_z15)+
  geom_point(data=outside, aes(x, y, colour = id), alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_d()+
  theme_void()
```

One real roost outside (Nutmeg's adventure as above) and 5 where birds were just roosting close to the fence. This is fine. 

Save output.

```{r}
# convert geometry to regular columns to save to disk
distance_roosts2 <- distance_roosts_latlon %>%
  st_drop_geometry() %>%
  mutate(longitude = st_coordinates(distance_roosts_latlon$geometry)[,1],
         latitude = st_coordinates(distance_roosts_latlon$geometry)[,2])

# plot on map without the far nutmeg point
ggmap(map_z15)+
  geom_path(data = filter(distance_roosts2, distance_previous<2000),
          aes(longitude, latitude, group = id), colour = "white", alpha = 0.6, inherit.aes = FALSE)+
    geom_point(data = filter(distance_roosts2, distance_previous<2000),
          aes(longitude, latitude, colour = distance_previous), inherit.aes = FALSE)+
  scale_colour_viridis_c()+
  theme_void()

# write to file
write.csv(distance_roosts2, "results/daily_distance_between_roosts.csv", row.names = FALSE)
```

## Release site fidelity

How far did they move from the release location? Based on daily roost distance from release location.

Calculate distance from daily roost to release location. 

Release location utm:(274423.45, 5801912.85) 
Release location lat/lon:(-37.902374, 144.434323)

```{r}
# read in roost locations, format as spatial
roosts <- read.csv("data/daily_roost_location.csv") %>%
  dplyr::select(!"npoints") %>%
  vect(geom = c("easting", "northing"), crs = "EPSG:32755") %>%
  st_as_sf()

# release coords as spatial
release  <- st_sfc(st_point(c(274423.45, 5801912.85) ), crs = 32755)

# calculate distance between roosts and release site
dist <- roosts %>%
  mutate(dist_release = as.numeric(st_distance(release, roosts))) %>%
  # keep max distance per day
  group_by(date, id) %>%
  filter(dist_release == max(dist_release)) %>%
  ungroup() %>%
  # add cohort information
  left_join(dplyr::select(metadata, c("cohort", "id"))) %>%
  # format date as a date
  mutate(date = as_date(date)) %>%
  # arrange by date
  arrange(date) %>%
  # drop geometry
  st_drop_geometry()

# save to file
write.csv(dist, "results/daily_roost_distance_from_release.csv", row.names = FALSE)
```

## Home range

Home range change is another way to investigate post-release behavioural modification. Previous studies have demonstrated decreasing home ranges over time as individuals first explore their new surrounds and then settle on a core area of exploitation. We define home range as 50% kernel utilisation distribution, with both nocturnal and diurnal fixes.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne"),
         time_utc = as.POSIXct(time_utc, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "UTC")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne"))%>%
  filter(!id %in% c("Wobbles", "Star"))

# set up data in spatial points dataframe
locs <- SpatialPointsDataFrame(coordinates(
  cbind(data$easting, data$northing)), data = data)

# home range polygon per bird per day ðŸ¢ðŸ¢ 2.5 hours
birds <- as.character(unique(data$id))
days <- unique(locs[["date"]])

hr_daily <- data.frame()

for (i in 1:length(birds)){
  for (j in 1:length(days)){
    points <- subset(locs, id == birds[i] & date == days[j],
                     select = id)
    if (length(points)<5){
      next
    }
    kud <- kernelUD(points[,1], h="href", grid=1000, extent = 4) %>% 
      getverticeshr(percent = 50)
    
    proj4string(kud) <- CRS("EPSG:32755")
    
    kud_df_utm <- st_as_sf(kud)%>%
      mutate(date = days[j])
    
    print(head(kud_df_utm, n= 1L))
    
    hr_daily <- rbind.data.frame(hr_daily, kud_df_utm)
  }}

# extract area per day i.e. drop geometry
hr_area <- st_drop_geometry(hr_daily)

# save to file
write.csv(hr_area, "results/daily_hr_area.csv", row.names = TRUE)
```

## Time budget HMM

Time budget can be another indicator of post-release behavioural modification. We expect them to become more efficient with their foraging over time as they learn where to find and exploit resources. So we expect to see more direct travel and less time spent foraging over time. 

How do they allocate their nocturnal movement? Hidden markov model.

```{r}
# read in cleaned night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # drop columns notneeded
  dplyr::select(!c(sunrise, sunset, suntime, tod)) %>%
  # format date time in posixct
  mutate(time_local = as.POSIXct(time_local),
         date_bird = as_date(date_bird))

# prep data for moveHMM
data_hmm <- data_night %>%
  prepData(type = "UTM", coordNames = c("easting", "northing"),
           covNames = c("acceleration_raw_x", "acceleration_raw_y", "acceleration_raw_z", "altitude")) %>%
# add vector of the dynamic body acceleration (VEDBA)
  mutate(vedba = ((sqrt(acceleration_raw_x^2 + acceleration_raw_y^2 + acceleration_raw_x^2))/1000))
```

### Test model

Create a test subset of one bird for one month (Nutmeg in June 2023). Investigate step and angle statistics to help define starting parameters. 

```{r}
# Test subset, Nutmeg 1 month
dates <- seq(as.Date("2023-06-01"), as.Date("2023-07-01"), "days")
test <- filter(data_hmm, id == "Aurora" & date_bird %in% dates)

# format as amt and calculate step lengths
steps <- test %>%
  # format as amt track - add columns as needed
  make_track(.x = x, .y = y, .t = time_local, id = id, date_bird = date_bird)

# check sample rate
summarize_sampling_rate(steps)

# resample track to 5 minutes
track_resample(rate = minutes(5), tolerance = minutes(1))

# step statistics
hist(test$step, xlab = "step", main = "", breaks = 30)
summary(test$step)

# angle statistics
hist(test$angle, breaks = seq(-pi, pi, length = 15), xlab = "angle", main = "")
summary(test$angle)

```

#### Number of states

Compare a three state and four state model to see what performs better.

```{r}

# 3 state model parameters
stepPar <- c(
  10, 60, 200,   # Means
  5, 20, 150,    # Standard deviations 
  0.15, 0, 0.5   # Zero-mass values
)

anglePar <- c(
  0, 0, 0,      # Means
  1.5, 7, 3     # Concentrations
)

# 3 state model
hmm3 <- momentuHMM::fitHMM(data = test, 
               nbStates = 3,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

hmm3
plot(hmm3)

# Step Parameters for 4 States
stepPar <- c(
  10, 60, 150, 300,   # Means 
  5, 15, 100, 150,    # Standard deviations 
  0.1, 0, 0.3, 0.15   # Zero-mass values 
)

# Angle Parameters for 4 States
anglePar <- c(
  0, 0, 0, 0,         # Means 
  1.5, 5, 2, 3        # Concentrations
)

# 4 state model
hmm4 <- momentuHMM::fitHMM(data = test, 
               nbStates = 4,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

hmm4
plot(hmm4)

# compare 3 and 4 state models
AIC(hmm3, hmm4)
```

Prefer the 4 state model both visually and on AIC.

Model      AIC
1  hmm4 19401.37
2  hmm3 19443.89

#### Optimise parameters

Try a range of starting values to optimise parameters.

```{r}
# For reproducibility
set.seed(12345)

# Number of tries with different starting values
niter <- 10

# Save list of fitted models
allm <- list()

# Save list of starting parameters
parameters <- list()

for(i in 1:niter) {
  # Step length mean
  stepMean0 <- runif(4, min = c(5, 50, 100, 200), max = c(50, 150, 300, 400))
  
  # Step length standard deviation
  stepSD0 <- runif(4, min = c(5, 30, 50, 100), max = c(30, 100, 150, 200))
  
  # Zero mass
  zeroMass0 <- runif(4, min = c(0.5, 0.05, 0.01, 0.2), max = c(0.9, 0.3, 0.1, 0.3))
  
  # Turning angle mean
  angleMean0 <- c(0, 0, 0, 0)
  
  # Turning angle concentration
  angleCon0 <- runif(4, min = c(0.5, 3, 5, 3), max = c(3, 10, 15, 10))
  
  # Parameter table
  parameters[[i]] <- data.frame(
    state = rep(1:4),
    stepMean0 = stepMean0,
    stepSD0 = stepSD0,
    zeroMass0 = zeroMass0,
    angleMean0 = angleMean0,
    angleCon0 = angleCon0
  )
  
  # Fit model
  stepPar0 <- c(stepMean0, stepSD0, zeroMass0)
  anglePar0 <- c(angleMean0, angleCon0)
  
  allm[[i]] <- tryCatch({
    momentuHMM::fitHMM(
      data = test,
      nbStates = 4,
      dist = list(step = "gamma", angle = "vm"),
      Par0 = list(step = stepPar0, angle = anglePar0),
      estAngleMean = list(angle = TRUE),
      formula = ~vedba
    )
  }, error = function(e) NULL)
}

# Extract likelihoods of fitted models
allnllk <- unlist(lapply(allm, function(m) m$mod$minimum))

# Index of best fitting model (smallest negative log-likelihood)
whichbest <- which.min(allnllk)

# Best fitting model
mbest <- allm[[whichbest]]
mbest
plot(mbest)
plotStates(mbest)

# Best starting parameters 
pbest_start <- parameters[[whichbest]]

# Best outcome parameters
pbest_outcome <- mbest$mle
```

Best outcome parameters:

$step
           state 1    state 2     state 3     state 4
mean     7.2211441 28.7419041 93.49649922 253.7447067
sd       5.6455927 23.2401216 53.89146576 312.9671872
zeromass 0.1559012  0.1669094  0.01833069   0.2101607

$angle
                state 1    state 2    state 3   state 4
mean          0.1170206 -0.1668971 0.02669791 0.2645331
concentration 1.1835577  1.3724136 2.71667136 1.9204624

$beta
               1 -> 2    1 -> 3    1 -> 4    2 -> 1     2 -> 3    2 -> 4
(Intercept) -5.204991 -8.829121 -2.213485 -6.221311 -10.254742 -4.297407
vedba        6.313020 -3.078513 -1.617744  5.398456  -4.197239  4.724587
               3 -> 1    3 -> 2     3 -> 4    4 -> 1    4 -> 2    4 -> 3
(Intercept) -8.220560 -2.225103  0.4526661 -2.324431 -0.453848  1.538068
vedba       -3.345948  1.189772 -2.1410536  1.063941  1.259101 -3.388000

$delta
               state 1   state 2      state 3      state 4
ID:Nutmeg 0.0004158271 0.9993644 5.228222e-05 0.0001674458

### Run HMM

Apply best parameters for a 4 state model to all birds.

```{r}
# Step Parameters 
stepPar <- c(
  7, 29, 93, 253,   # Means
  6, 23, 54, 313,    # Standard deviations 
  0.16, 0.17, 0.02, 0.21   # Zero-mass values 
)

# Angle Parameters for 4 States
anglePar <- c(
  0.11, -0.17, 0.03, 0.26,         # Means 
  1.18, 1.37, 2.72, 1.92        # Concentrations
)

# 4 state model (approx. 7 hours to run) ðŸ¢ðŸ¢
hmm_all <- momentuHMM::fitHMM(data = data_hmm, 
               nbStates = 4,
               dist = list(step = "gamma", angle = "vm"),
               Par0 = list(step = stepPar, angle = anglePar),
               estAngleMean = list(angle=TRUE),
               formula = ~vedba
               )

# see states
hmm_all

# plot results
plot(hmm_all)

# check residuals
plotPR(hmm_all)

# Decode states
data_hmm2 <- data_hmm %>%
  mutate(states = viterbi(hmm_all))

# save output
write.csv(data_hmm2, "data/data_hmm.csv", row.names = FALSE)

```

$step
$step$est
           state 1    state 2    state 3     state 4
mean     8.2208094 20.3895440 57.8629585 129.4745424
sd       6.6718586 17.2595917 33.1696834 142.4877739
zeromass 0.1835534  0.1435767  0.1017199   0.1056076

$step$se
             state 1     state 2     state 3    state 4
mean     0.059195569 0.158752114 0.504588470 1.62585187
sd       0.059392166 0.135826249 0.350108882 1.68770684
zeromass 0.001644487 0.001121659 0.002745764 0.00326152

$step$lower
           state 1    state 2     state 3      state 4
mean     8.1047882 20.0783956 56.87398323 126.28793127
sd       6.5554521 16.9933771 32.48348260 139.17992928
zeromass 0.1803303  0.1413783  0.09633832   0.09921516

$step$upper
           state 1    state 2    state 3     state 4
mean     8.3368306 20.7006924 58.8519337 132.6611535
sd       6.7882651 17.5258063 33.8558842 145.7956185
zeromass 0.1867766  0.1457751  0.1071015   0.1120001


$angle
$angle$est
                    state 1     state 2     state 3    state 4
mean          -0.0006350116 -0.02490599 0.005901283 0.02889899
concentration  0.9849618919  1.34078324 2.855987790 1.62310950

$angle$se
                  state 1     state 2     state 3    state 4
mean          0.008772497 0.004360951 0.005746417 0.01000978
concentration 0.009074356 0.008098515 0.040103562 0.01989011

$angle$lower
                  state 1    state 2      state 3     state 4
mean          -0.01782879 -0.0334533 -0.005361488 0.009280183
concentration  0.96717648  1.3249104  2.777386254 1.584125600

$angle$upper
                 state 1     state 2    state 3    state 4
mean          0.01655877 -0.01635868 0.01716405 0.04851779
concentration 1.00274730  1.35665604 2.93458933 1.66209339


$gamma
$gamma$est
            state 1    state 2      state 3    state 4
state 1 0.931458331 0.05761075 2.899808e-05 0.01090192
state 2 0.025798292 0.89292770 4.665911e-02 0.03461490
state 3 0.002059385 0.20857863 7.299991e-01 0.05936288
state 4 0.036632497 0.16340398 1.137106e-01 0.68625289

$gamma$se
            state 1     state 2     state 3      state 4
state 1 0.001852868 0.001856780         NaN 0.0009593681
state 2 0.001035936 0.001734979 0.001537815 0.0010952092
state 3 0.001406860 0.004757413 0.005098452 0.0034170704
state 4 0.002882481 0.006547791 0.005798381 0.0077365855

$gamma$lower
            state 1    state 2    state 3     state 4
state 1 0.927736437 0.05407762        NaN 0.009173398
state 2 0.023843831 0.88947937 0.04373596 0.032531334
state 3 0.000539143 0.19940768 0.71989062 0.053008962
state 4 0.031383508 0.15097250 0.10283144 0.670894349

$gamma$upper
            state 1    state 2    state 3    state 4
state 1 0.935001961 0.06135974        NaN 0.01295190
state 2 0.027908379 0.89628098 0.04976747 0.03682684
state 3 0.007832716 0.21805649 0.73987462 0.06642498
state 4 0.042720676 0.17664613 0.12557970 0.70121389

### Time budget

```{r}
# read in data with hmm states
data_hmm <- read.csv("data/data_hmm.csv")

# calculate proportion of fixes in each state per bird per day
budget_daily <- data_hmm %>%
  group_by(ID, date_bird) %>%
  # count of states
  count(states) %>%
  # pivot to wide format
  pivot_wider(names_from = 3, values_from = 4) %>%
  # rename state columns
  rename(state1 = 3,
         state2 = 4,
         state3 = 5,
         state4 = 6) %>%
  # replace NAs with zeros
  replace(is.na(.), 0) %>%
  # calculate proportion
  mutate(total = sum(state1, state2, state3, state4),
         state1p = state1/total,
         state2p = state2/total,
         state3p = state3/total,
         state4p = state4/total) %>%
  arrange(date_bird) %>%
  # rename ID
  rename(id = ID)

# save to file
write.csv(budget_daily, "results/daily_time_budget.csv", row.names = FALSE)

# summarise over time
budget <- budget_daily %>%
  # calculate mean and sd
  group_by(id) %>%
  summarise(s1m = mean(state1p),
            s2m = mean(state2p),
            s3m = mean(state3p),
            s4m = mean(state4p)) %>%
  pivot_longer(2:5, names_to = "state", values_to = "budget") %>%
  # add cohort
  left_join(select(metadata, c(id, cohort)))

# plot time budget mean by bird
ggplot(budget)+
  geom_bar(aes(x = id, y = budget, fill = state), position="fill", stat="identity")+
  theme_minimal()+
  scale_fill_viridis_d()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.x = element_text(angle = 90, vjust = 0, hjust = 1))+
  facet_wrap(~cohort, scales="free_x")
```

# Conspecific interactions

The key issue addressed in this paper is whether social interaction occurs between residents and reinforcers, and if so whether this mediates post-release outcomes for the cohorts. 

## Proximity analysis

First we need to determine interactions. Using GPS tracking data we cannot perfectly capture social interactions, but we can approximate these with proximity (distance and time) analysis. I elected to use the coefficient of association because it produces few few I errors, owing to its simplicity ([Long et al 2014](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2656.12198)) 

To determine the temporal interaction threshold we use the mean sampling rate.

```{r}
# Read in cleaned data 
data <- read.csv("data/data_cleaned.csv") %>%
  # Time in posix format
  mutate(time_local = as.POSIXct(time_local, format = "%Y-%m-%d %H:%M:%OS", 
                                 tz = "Australia/Melbourne")) %>%
  # Add date
  mutate(date = as_date(time_local, tz = "Australia/Melbourne")) %>%
  # drop birds excluded from analyses
  filter(!id %in% c("Wobbles", "Star")) %>%
  # drop NAs
  na.omit()

# summarise sampling rate to decide on temporal interaction threshold
steps <- data %>%
  make_track(.x = easting, .y = northing, .t = time_local, id = id) %>%
  nest(data = -"id")

sampling_rates <- steps %>%
  transmute(id, summary = map(data, summarize_sampling_rate)) %>%
  unnest(summary)

mean(sampling_rates$mean)
```

The mean sampling rate for the cleaned data is 8 minutes. We will use a time parameter of 4 minutes (half the sampling interval) following advice from the wildlifeDI package vignette. 

First format tracks as move2 objects for use in wildlifeDI.

```{r}
# format track data as move2 object
move <- mt_as_move2(data, coords = c("easting", "northing"), time_column = "time_local", track_id_column = "id") %>%
  # add crs
  sf::st_set_crs("EPSG:32755") %>%
  # needed to omit NAs for wildlifeDI to work
  na.omit()
```

We use a dcPlot of paired encounters across distance to approximate the distance threshold (using a subset to reduce processing time).

Our practitioner guesstimate was a threshold of 30m (based on visual observation of interactions between individuals in the field during monitoring). 

```{r}
# one week subset
temp <- seq.Date(from = as_date("2023-06-01"), to = as_date("2023-06-07"), by = "day")
move_subset <- filter(move, date %in% temp)

# plot distribution of paired fixes by distance
dcPlot(move_subset,tc=4*60,dmax=500)
dcPlot(move_subset,tc=4*60,dmax=100)
```

The majority of contacts took place <40m apart. I'll retain the guesstimate of 30m as the parameter. This is also within tolerance for the approximate GPS uncertainty of approx 20m (on cleaned data).

We calculate prox for all dyads for the two time periods of interest:

  1) Residents only
  2) Residents and reinforcers
  
### Residents only

We define this as the period from the last resident released (2023-01-16) to the first reinforcer released (2023-06-07). 

```{r}
# define resident only date period
res_dates <- seq.Date(from = as_date("2023-01-16"), to = as_date("2023-06-06"), by = "day")

# subset to dates
data_resident <- move %>%
  filter(date %in% res_dates)

# Test for a single dyad
dyad <- filter(data_resident, id %in% c("Aurora", "Briar"))

checkTO(dyad)
Sys.time()
test <- Ca(dyad, tc=4*60, dc=30);Sys.time()
```

The test dyad took 47 seconds so I'm anticipating the full set of 78 interactions will take 1 hour. 

```{r}
# list of residents
residents <- unique(data_resident$id)

# All bird combinations
list <-combinations(n = 13, r = 2, v = residents, repeats.allowed = FALSE)
list1 <- list[,1]
list2 <- list[,2]

# Calculate interactions between all birds ðŸ¢ðŸ¢
interact <- data.frame()

for(i in 1:length(list1)) {
  
  dyad <- filter(data_resident, id %in% c(list1[i], list2[i]))
  
  temp <- tryCatch({
    data.frame(Prox(dyad, tc=4*60, dc=30)) %>%
      clean_names()
  }, error = function(e) data.frame(ca = NA, bird1 = NA, bird2 = NA)) 
  
  print(paste("Finished", list1[i], "&", list2[i], i, "of 78", sep = " "))
  
  interact <- rbind(interact, temp)
}

# tidy up the output
interact2 <- interact %>%
  # remove unneeded columns
  select(id1, id2, prox) %>%
  # format prox numeric to 4 decimal places
  mutate(prox = as.numeric(format(round(prox, 4), nsmall = 4)))

# save to disk
write.csv(interact, "results/proximity_residents.csv", row.names = FALSE)

# summary statistics prox values
hist(interact2$prox)
summary(interact2$prox)
```

Mean proximity score is 13.1%, min is no interaction and max is 43.8%. 

### Residents and reinforcers

We define this as the period from the last reinforcer released (2023-06-11) to the end of the study period (when reinforcers moved to Orana 2023-08-05). Each dyad takes approx. 8 seconds so all 378 takes approx 1 hour to run. 

```{r}
# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-05"), by = "day")

# subset to dates
data_reinforce <- move %>%
  filter(date %in% rein_dates)

# list of founders
founders <- unique(data_reinforce$id)

# All bird combinations
list <-combinations(n = 28, r = 2, v = founders, repeats.allowed = FALSE)
list1 <- list[,1]
list2 <- list[,2]

# Calculate interactions between all birds ðŸ¢ðŸ¢
interact <- data.frame()

for(i in 1:length(list1)) {
  
  dyad <- filter(data_reinforce, id %in% c(list1[i], list2[i]))
  
  temp <- tryCatch({
    data.frame(Prox(dyad, tc=4*60, dc=30)) %>%
      clean_names()
  }, error = function(e) data.frame(ca = NA, bird1 = NA, bird2 = NA)) 
  
  print(paste("Finished", list1[i], "&", list2[i], i, "of 378", sep = " "))
  
  interact <- rbind(interact, temp)
}

# tidy up the output
interact2 <- interact %>%
  # remove unneeded columns
  select(id1, id2, prox) %>%
  # format prox numeric to 4 decimal places
  mutate(prox = as.numeric(format(round(prox, 4), nsmall = 4)))

# save to disk
write.csv(interact2, "results/proximity_reinforcers.csv", row.names = FALSE)

# summary statistics prox values
hist(interact2$prox)
summary(interact2$prox)
```

Summary stats here

## Social network

For social network analysis we use the proximity analysis of dyads completed above. Proximity networks are inferred interactions but with a highly complete data set - so we are trading off good temporal resolution and complete coverage of the population against little information on any one interaction. 

We use the package tidygraph as a wrapper for implement igraph graphics in the tidyverse API.

### Residents only

```{r}
# read in dyad proximity scores and convert to association matrix
prox1 <- read.csv("results/proximity_residents.csv") %>%
  # add rows for last and first bird self comparison
  rbind(data.frame(id1 = c("Valentine", "Aurora"),
                   id2 = c("Valentine", "Aurora"),
                   prox = c(NA, NA))) %>%
  # long to wide format
  pivot_wider(names_from = id2, values_from = prox) %>%
  # first column to rownames
  column_to_rownames("id1") %>%
  # relocate first bird to first column
  relocate(Aurora) %>%
  # format as matrix
  as.matrix()

# make symmetrical
prox1[lower.tri(prox1)] <- t(prox1)[lower.tri(prox1)]

# convert to graph object
network1 <- graph_from_adjacency_matrix(prox1, mode = "undirected", diag = FALSE, weighted = TRUE)

# network density - real edges divided by possible edges
edge_density(network1)

# network components - are all nodes connected?
components(network1)

# distance between nodes
distances(network1, algorithm="unweighted")

# proportion of node's neighbors that are connected to each other
summary(transitivity(network1, "local"))
```

We have a network of 13 individuals (nodes) and 68 edges with an edge density of 87.1%. The network is continuous (i.e. all nodes in network are connected) and the maximum degree of separation is two. 

First plot with weighted edges and nodes sized by degree centrality (number of edges - how many "friends" they have).

```{r}
# set seed to keep layout static
set.seed(4739)
networkfr1 <- create_layout(network1, layout = "fr") 

# plot with tidygraph (wrapper for igraph in tidy API)
ggraph(networkfr1)+
  # format edge colour, alpha and width by the weight (proximity)
  geom_edge_fan(aes(colour = weight, alpha = weight, linewidth = weight/2), 
                show.legend = FALSE)+
  scale_edge_color_continuous(low = "grey", high = "slateblue3")+ 
  # node basic
  geom_node_point(size = 7, shape = 16)+
  # add labels
  #geom_node_text(aes(label = name), nudge_y = 0.15)+
  # theme
  theme_void()
```

Next calculate community - first deciding on clustering algorithm.

Based on the suggestions by [Yang et al. (2016)](https://www.nature.com/articles/srep30750) I will try edge betweenness, walktrap, spinglass and infomap, because I have a small dense network and these perform well in that use case. 

```{r}
# community with edge betweenness
eb <- cluster_edge_betweenness(network1)
length(eb)
modularity(eb)
membership(eb)

# community with walktrap
w <- cluster_walktrap(network1)
length(w)
modularity(w)
membership(w)

# community with spinglass
sg <- cluster_spinglass(network1)
length(sg)
modularity(sg)
membership(sg)

# community with infomap
im <- cluster_infomap(network1)
length(im)
modularity(im)
membership(im)
```

They all turned out the same, I'll use walktrap. Plot with community.

```{r}
# add community to network layout
comm1 <- networkfr1 %>%
  mutate(community = as.factor(membership(w)))
```

### Residents and reinforcers

```{r}
# read in dyad proximity scores and convert to association matrix
prox2 <- read.csv("results/proximity_reinforcers.csv") %>%
  # add rows for last and first bird self comparison
  rbind(data.frame(id1 = c("Zeus", "Athena"),
                   id2 = c("Zeus", "Athena"),
                   prox = c(NA, NA))) %>%
  # long to wide format
  pivot_wider(names_from = id2, values_from = prox) %>%
  # first column to rownames
  column_to_rownames("id1") %>%
  # relocate first bird to first column
  relocate(Athena) %>%
  # format as matrix
  as.matrix()

# make symmetrical
prox2[lower.tri(prox2)] <- t(prox2)[lower.tri(prox2)]

# convert to graph object
network2 <- graph_from_adjacency_matrix(prox2, mode = "undirected", diag = FALSE, weighted = TRUE)

# network density - real edges divided by possible edges
edge_density(network2)

# network components - are all nodes connected?
components(network2)

# distance between nodes
distances(network2, algorithm="unweighted")

# proportion of node's neighbors that are connected to each other
summary(transitivity(network2, "local"))
```

We have a network of 28 individuals (nodes) and 377 edges with an edge density of 99.7% (only one dyad doesn't have an edge, Sofi & Daisy). The network is continuous (i.e. all nodes in network are connected) and the maximum degree of separation is two. 

Calculate community with walktrap method.

```{r}
# community with walktrap
w2 <- cluster_walktrap(network2, steps = 10)
length(w2)
modularity(w2)
membership(w2)

# set seed to keep layout static
set.seed(0000)
networkfr2 <- create_layout(network2, layout = "fr") 

# add community and cohort to network layout
comm2 <- networkfr2 %>%
  rename(id = name) %>%
  mutate(community = as.factor(membership(w2))) %>%
  left_join(select(metadata, c(id, cohort)))

hist(E(network2)$weight)
```

Interesting! The reinforcers split nearly perfectly in half, with nine members in an exclusive social group (consisting only of reinforcers) and eleven members in a mixed social group (along with all the residents). Daisy was off to the side but ended up in the mixed group. 

### SNA figure

```{r}
# resident network
n1 <- ggraph(comm1)+
  # community polygon
  geom_mark_hull(aes(x = x, y = y, fill = community), 
                 colour = "white", alpha = 0.2, expand = unit(0.5, "cm"),
                 show.legend = FALSE)+
  
  scale_fill_manual(values = c("grey10", "grey60"))+
  # format edge colour, alpha and width by the weight (proximity)
  geom_edge_fan(aes(colour = weight, alpha = weight, linewidth = weight/2),
                show.legend = FALSE)+
  scale_edge_color_continuous(low = "grey", high = "slateblue4")+ 
  # node basic
  geom_node_point(size = 5, shape = 16)+
  # theme
  expand_limits(x = c(-6, 3), y = c(-4.5, 0.4))+
  theme_graph(foreground = "black", border = TRUE,
              plot_margin = margin(10, 60, 0, 60))

# reinforcer network
n2 <- ggraph(comm2)+
  # communites polygons
  geom_mark_hull(aes(x = x, y = y, fill = community), 
                 colour = "white", alpha = 0.2, expand = unit(0.8, "cm"),
                 show.legend = FALSE)+
  scale_fill_manual(values = c("seagreen3", "#2E3FFF"))+
  # format edge colour, alpha and width by the weight (proximity)
  geom_edge_fan(aes(colour = weight, alpha = weight, width = weight),
                show.legend = FALSE)+
  scale_edge_color_continuous(low = "grey90", high = "slateblue4")+ 
  scale_edge_width(range = c(0.1, 3))+
  # node shape by cohort
  geom_node_point(aes(shape = cohort), size = 5, 
                  show.legend = FALSE)+
  scale_shape_manual(values=c(15, 16))+
  # theme
  expand_limits(x = c(2, 7), y = c(-3.8, 2.6))+
  theme_graph(foreground = "black", border = TRUE,
              plot_margin = margin(10, 20, 20, 20))

# multi panel
ggarrange(n1, n2, 
          labels = c("A", "B"),
          ncol = 1, nrow = 2,
          heights = c(0.5, 1))
```


# Statistical analysis: reinforcers

Instead of using dyad connections, we can use the social groups (which are serendipitously nearly evenly split among the reinforcers) to ask questions about conspecific interactions. Social groups can tell you more about the overall social environment than dyads alone (Farine and Whitehal 2015).

We hypothesised members of the mixed resident-reinforcer social group would proceed more quickly through the PRBM phases than those in the reinforcer only group. I also want to compare both reinforcer groups to the residents to see if one is more similar than the other.

Dates are from the last reinforcer released to the first reinforcer translocated to the secondary site. 

```{r}
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")

# define reinforcer date period
rein_dates <- seq.Date(from = as_date("2023-06-11"), to = as_date("2023-08-05"), by = "day")
```

### m1: Distance moved

Does daily distance moved differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam1 <- read.csv("results/daily_distance_moved.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date_bird)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive"))) %>%
  # add quadratic term for time
  mutate(elapsed2 = elapsed^2)

# create social group means
sum1 <- datam1 %>%
  group_by(date, social) %>%
  summarise(dist = mean(daily_dist),
            upper = dist + std.error(daily_dist),
            lower = dist - std.error(daily_dist)) %>%
  arrange(date)

# plot daily distance over time as social group means
ggplot(sum1, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-release") + 
  ylab("Daily distance moved (m)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam1$daily_dist)
ggqqplot(datam1$daily_dist)

# test difference between the groups with interaction of time as a quadratic
m1 <- glmmTMB(daily_dist ~ social * (scale(elapsed) + scale(elapsed2))+ (1|id), 
              data = datam1,
              na.action = "na.fail")

# model selection
dm1 <- dredge(m1)

# print best model on AICc
best1 <- get.models(dm1, delta==0)[[1]]
summary(best1)

# check model
check_model(best1)

# post-hoc comparison of means
emmeans(best1, pairwise ~ social, type = "response")

# post-hoc comparison of slopes
emtrends(best1, pairwise ~ social, var = "elapsed")

# plot effects
plot_model(best1)

# marginal effects 
pred1 <- predict_response(best1, terms = c("elapsed", "social"))

# plot predictions
ggplot(pred1, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-release") + 
  ylab("Predicted values of daily distance moved (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

The best fitting model included social group and time (linear and quadratic), the interaction between these, and individual as a random effect.

Residents had relatively stable movement patterns over time (slight increase but not significant). Whereas both reinforcer groups display a quadratic trajectory, initially increasing daily distance more rapidly, then decelerating such that their movement trajectories may eventually converge with or even decline relative to those of residents. There was no significant difference between the reinforcer groups (for either mean values or slopes).

Reinforcers behaved the same in terms of distance moved, and trended towards residents. Distance moved may have an optimum. 

### m2: Roost establishment

Does roost establishment differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam2 <- read.csv("results/daily_distance_between_roosts.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive"))) %>%
  # add quadratic term for time
  mutate(elapsed2 = elapsed^2)

# create social group means
sum2 <- datam2 %>%
  group_by(date, social) %>%
  summarise(dist = mean(distance_previous),
            upper = dist + std.error(distance_previous),
            lower = dist - std.error(distance_previous)) %>%
  arrange(date)

# plot roost displacement over time as social group means
ggplot(sum2, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-release") + 
  ylab("Distance between consecutive roosts (m)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam2$distance_previous)
ggqqplot(datam2$distance_previous)

# correct left skew
hist(log1p(datam2$distance_previous))
ggqqplot(log1p(datam2$distance_previous))

# test difference between the groups with interaction of time as a quadratic
m2 <- glmmTMB(log1p(distance_previous) ~ social * (scale(elapsed) + scale(elapsed2))+ (1|id), 
              data = datam2,
              na.action = "na.fail")

# model selection
dm2 <- dredge(m2)

# print best model on AICc
best2 <- get.models(dm2, delta==0)[[1]]
summary(best2)

# check model
check_model(best2)

# post-hoc comparison of means
emmeans(best2, pairwise ~ social, type = "response")

# plot effects
plot_model(best2)

# marginal effects 
pred2 <- predict_response(best2, terms = c("elapsed", "social"))

# plot predictions
ggplot(pred2, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-release") + 
  ylab("Predicted values of roost displacement (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

The best fitting model included social group, time (linar and quadratic), and individual as a random effect. No interactive terms.

Elapsed time had a significant positive linear effect (estimate = 0.455, SE = 0.129, p = 0.00042) and a significant negative quadratic effect (estimate = â€“0.581, SE = 0.129, p < 0.0001), indicating that distance initially increases with time before reaching a peak and then declines.

Exclusive reinforcers travelled significantly greater distances between consecutive roosts than both mixed reinforcers (p = 0.0001) and residents (p < 0.0001). The mixed reinforcers were not significantly different from residents. 

Overall, my interpretation is group co-membership with residents improved roost establishment and fidelity - an important step in post-release establishment.

### m3: Release site fidelity

Does release site fidelity differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam3 <- read.csv("results/daily_roost_distance_from_release.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive"))) %>%
  # add quadratic term for time
  mutate(elapsed2 = elapsed^2)

# create social group means
sum3 <- datam3 %>%
  group_by(date, social) %>%
  summarise(dist = mean(dist_release),
            upper = dist + std.error(dist_release),
            lower = dist - std.error(dist_release)) %>%
  arrange(date)

# plot distance from release site over time as social group means
ggplot(sum3, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-release") + 
  ylab("Distance from release site (m)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam3$dist_release)
ggqqplot(datam3$dist_release)

# correct left skew - still not great but a bit better
hist(sqrt(datam3$dist_release))
ggqqplot(sqrt(datam3$dist_release))

# test difference between the groups with interaction of time as a quadratic
m3 <- glmmTMB(sqrt(dist_release) ~ social * (scale(elapsed) + scale(elapsed2))+ (1|id), 
              data = datam3,
              na.action = "na.fail")

# model selection
dm3 <- dredge(m3)

# print best model on AICc
best3 <- get.models(dm3, delta==0)[[1]]
summary(best3)

# check model
check_model(best3)

# post-hoc comparison of means
emmeans(best3, pairwise ~ social, type = "response")

# post-hoc comparison of slopes
emtrends(best3, pairwise ~ social, var = "elapsed")

# plot effects
plot_model(best3)

# marginal effects 
pred3 <- predict_response(best3, terms = c("elapsed", "social"))

# plot predictions
ggplot(pred3, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-release") + 
  ylab("Predicted values of distance from release site (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```

The best fitting model included social group and time (linear and quadratic), the interaction between these, and individual as a random effect.

Exclusive reinforcers moved significantly further from the release site than both mixed reinforcers (p = 0.031) and residents (p = 0.0002). Additionally, the rate of change was significantly different for exclusive reinforcers - who coninuted to move away from the release site- compared to the other groups (p < 0.0001). 

Overall, group co-membership with residents had greater site fidelity. An alternative explanation is that the exclusive birds were pushed away - but I don't think this is the case because they continued to have interactions with the other group including some time roosting in the central woodland.

#### Release site fidelity map

How do they move away from the release site over time

```{r}
ggmap(map_z15)+
  # plot roosts colour by time
  geom_point(aes(longitude, latitude, colour = date),
             size = 2, data = datam2, inherit.aes = FALSE)+
  # add release location
  geom_point(aes(144.434323, -37.902374), 
             colour = "white", size = 5, shape = 13, inherit.aes = FALSE)+
  # add fence
  geom_spatvector(data = mtr, inherit.aes = FALSE, fill = NA, colour = "white",
                  linetype = "longdash")+
  # wrap by period
  facet_wrap(~social)+
  # theme options
  scale_colour_viridis_c(trans = "date", name = "2023")+
  theme_void()+
  scale_y_continuous(expand = expansion(mult = c(0, 0.01)))+
  theme(legend.position="bottom",
        legend.key.width = unit(3, 'cm'),
        strip.text = element_text(size = 13))+
  # add north in just the resident facet panel
  annotation_north_arrow(data  = subset(datam2, social == "Resident"),
                         location = "tr", 
                         height = unit(0.8, "cm"), width = unit(0.7, "cm"),
                         style = north_arrow_orienteering(text_col = "black"))+
  # add scale bar in just the resident facet panel
  annotation_scale(data  = subset(datam2, social == "Resident"),
                   location = "br", text_col = "black",
                   pad_x = unit(0.1, "cm"), pad_y = unit(0.4, "cm"))
```

### m4: Home range establishment

Does home range size differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam4 <- read.csv("results/daily_hr_area.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-10"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # convert group to factor and set resident as the intercept
  mutate(social = factor(social, levels = c("Resident", "Reinforcer - mixed", "Reinforcer - exclusive"))) %>%
  # add quadratic term for time
  mutate(elapsed2 = elapsed^2)

# create social group means
sum4 <- datam4 %>%
  group_by(date, social) %>%
  summarise(dist = mean(area),
            upper = dist + std.error(area),
            lower = dist - std.error(area)) %>%
  arrange(date)

# plot distance from release site over time as social group means
ggplot(sum4, aes(date, dist, ymin = lower, ymax = upper)) +
  geom_path(aes(colour = social)) +
  geom_ribbon(aes(fill = social), alpha = 0.2) +
  xlab("Days post-release") + 
  ylab("Home range 50% KUD (ha)") +
  theme_minimal() +
  scale_fill_viridis_d()+
  scale_colour_viridis_d()

# distribution of movement data
hist(datam4$area)
ggqqplot(datam4$area)

# correct left skew - still not great but a bit better
hist(sqrt(datam3$dist_release))
ggqqplot(sqrt(datam3$dist_release))

# test difference between the groups with interaction of time as a quadratic
m3 <- glmmTMB(sqrt(dist_release) ~ social * (scale(elapsed) + scale(elapsed2))+ (1|id), 
              data = datam3,
              na.action = "na.fail")

# model selection
dm3 <- dredge(m3)

# print best model on AICc
best3 <- get.models(dm3, delta==0)[[1]]
summary(best3)

# check model
check_model(best3)

# post-hoc comparison of means
emmeans(best3, pairwise ~ social, type = "response")

# post-hoc comparison of slopes
emtrends(best3, pairwise ~ social, var = "elapsed")

# plot effects
plot_model(best3)

# marginal effects 
pred3 <- predict_response(best3, terms = c("elapsed", "social"))

# plot predictions
ggplot(pred3, aes(x, predicted, fill = group, ymin = conf.low, ymax = conf.high)) +
  geom_line(aes(colour = group))+
  geom_ribbon(alpha = 0.2)+
  xlab("Days post-release") + 
  ylab("Predicted values of distance from release site (m)") +
  theme_minimal()+
  scale_fill_viridis_d()+
  scale_colour_viridis_d()
```


```{r}
# read in data and filter to reinforcement period
datam4 <- read.csv("results/daily_hr_area.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-11"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates)

# create cohort means
sum4 <- datam4 %>%
  group_by(date, social) %>%
  summarise(area = mean(area)) %>%
  arrange(date)

# plot home range area by social group
ggplot(datam4)+
  geom_boxplot(aes(social, area))+
  xlab("Social group")+ 
  ylab("Home range (50% KUD) area (ha)")+
  theme_minimal()

# plot home range area over time as social group means
ggplot(sum4)+
  geom_path(aes(date, area, color = social), linewidth = 1)+
  xlab("Days post-release")+ 
  ylab("Home range (50% KUD) area (ha)")+
  theme_minimal()

# plot home range area over time as linear model
ggplot(datam4)+
  geom_smooth(aes(elapsed, area, color = social), method = "lm")+
  xlab("Days post-release") + 
  ylab("Home range (50% KUD) area (ha)")+
  theme_minimal()
```

The reinforcers in the mixed group stayed similarly close to the release site as the residents (who were occupying an area of the woodland near the release site when the reinforcement translocation occurred), whereas the exclusive group left the area and went increasingly far from the release location.

```{r}
# distribution of movement data
hist(datam4$area)
ggqqplot(datam4$area)

# correct left skew - still not perfect but okay
hist(log(datam4$area))
ggqqplot(log(datam4$area))

# test whether establishment differs between the social groups
m4 <- lmer(log(area) ~ social * scale(date) + (1|id), data = datam4)
summary(m4)
emmeans(m4, )

# check residuals
hist(residuals(m4))
ggqqplot(residuals(m4))
```

Interpretation here

### m5: Time budget

Does time allocated to foraging differ between the social groups?

```{r}
# read in data and filter to reinforcement period
datam5 <- read.csv("results/daily_time_budget.csv") %>%
  rename(date = date_bird) %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # add a time elapsed post-release variable
  mutate(elapsed = as.numeric(date - as_date("2023-06-11"))) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # limit to reinforcement period
  filter(date %in% rein_dates)

# create cohort means
sum5 <- datam5 %>%
  group_by(date, social) %>%
  summarise(foraging = mean(state2p)) %>%
  arrange(date)

# and pivot longer for barchart
datam5bar <- datam5 %>%
  select(!3:7) %>%
  pivot_longer(3:6, names_to = "state", values_to = "proportion")

# plot time budget by social group
ggplot(datam5bar)+
  geom_bar(aes(x = social, y = proportion, fill = state),
           position="fill", stat="identity")+
  xlab("Social group")+ 
  ylab("Time budget allocation")+
  theme_minimal()

# plot foraging allocation over time as social group means
ggplot(sum5)+
  geom_path(aes(date, foraging, color = social), linewidth = 1)+
  xlab("Days post-release")+ 
  ylab("Proportion of time budget allocated to foraging")+
  theme_minimal()

# plot foraging allocation over time as linear model
ggplot(datam5)+
  geom_smooth(aes(elapsed, state2p, color = social), method = "lm")+
  xlab("Days post-release")+ 
  ylab("Proportion of time budget allocated to foraging")+
  theme_minimal()
```

The residents allocate around 50% of their time to foraging, compared to 65% for reinforcers. The reinforcers are very similar.

Lower allocation to foraging possibly due to increased efficiency and more time allocated to other behaviours. 

```{r}
# distribution of allocation
hist(datam5$state2p)
ggqqplot(datam5$state2p)

# Adjust values slightly so they 0 < x < 1
datam5 <- datam5 %>%
  mutate(adjusted = (state2p + 0.001) / 1.002)

hist(datam5$adjusted)
ggqqplot(datam5$adjusted)

# test whether establishment differs between the social groups
m5 <- glmmTMB(adjusted ~ social * scale(date) + (1 | id), data = datam5,
               family = beta_family(link = "logit"))
summary(m5)
emmeans(m5, pairwise ~ social, adjust = "tukey", type = "response")

# check residuals
hist(residuals(m4))
ggqqplot(residuals(m4))
```

Residents significantly different from all reinforcers, reinforcers not different from one another. No effect of time. 

### m6: Weight change

In addition to the movement-based metrics of performance I wanted to look at health check data. Weight change post-release is a good indicator of performance, where some loss is expected but less steep decline (trending towards stability) indicates better performance.

We were unable to compare residents to reinforcers for weight change because we did not have weight measurements for the six individuals released in January 2023 (backpacks fitted in the December trip and released by Mt Rothwell staff rather than me going back down there). So we can only compare reinforcers, but interested to see how the social group memberships contrast.

Unlike the movement data, the study period is for 70 days because weights were taken after the 55 minimum common tracking period. 

```{r}
# read in data and clean up
datam6 <- read_xlsx("data/healthchecks.xlsx") %>%
  clean_names() %>%
  rename(id = identity) %>%
  select(id, date, weight) %>%
  mutate(date = as_date(date)) %>%
  # add metadata
  left_join(select(metadata, c(id, start_date, cohort))) %>%
  drop_na() %>%
  # calculate elapsed time and add status
  mutate(elapsed = as.numeric(date - start_date)) %>%
  # keep only reinforcers
  filter(cohort == "Reinforcing") %>%
  # add social group membership %>%
   mutate(social = ifelse(id %in% club, "Reinforcer - exclusive", ifelse(cohort == "Resident", "Resident", "Reinforcer - mixed"))) %>%
  # keep only the latest pre-release values and assign to pre/post release
  group_by(id) %>%
  filter(elapsed > 0 | elapsed == max(elapsed[elapsed <= 0])) %>%
  ungroup() %>%
  mutate(status = as_factor(ifelse(elapsed > 0, "post-release", "pre-release"))) %>%
  arrange(id) %>%
  # filter to study period
  filter(elapsed <70)

# plot weight pre and post-release
ggplot(datam6)+
  geom_boxplot(aes(status, weight))+
  theme_minimal()

# plot weight pre and post release by individual, facet wrap social
ggplot(datam6)+
  geom_path(aes(status, weight, colour = id, group = id))+
  theme_minimal()+
  facet_wrap(~social)

# plot weight pre and post release by social group as a linear model
ggplot(datam6)+
  geom_smooth(aes(status, weight, colour = social, group = social), method = "lm")+
  theme_minimal()
```

We have pre and post data for 18 of the 20 reinforcers. All lost weight. The mixed social group declined less steeply, but started out on average lower than the exclusive group.

Next I calculated the change in weight both in grams and as a proportion of starting weight (to account for variation in body sizes).

```{r}
# calculate weight change in grams and as a proportion of starting weight
sum6 <- datam6 %>%
  select(c(id, social, weight, status)) %>%
  pivot_wider(names_from = status, values_from = weight) %>%
  clean_names() %>%
  drop_na() %>%
  # add change columns
  mutate(diff = pre_release - post_release,
         proportion = diff/pre_release)

# plot total weight differences by social group
ggplot(sum6)+
  geom_boxplot(aes(social, diff))+
  theme_minimal()

# plot proportional weight differences by social group
ggplot(sum6)+
  geom_boxplot(aes(social, proportion))+
  theme_minimal()
```

Although total weight change seems on average lower in the mixed group, proportionally it does not look like a lot of difference.

```{r}
# check distribution of the difference
hist(sum6$diff)
ggqqplot(sum6$diff)

# summary stats
sums <- sum6 %>%
  group_by(social) %>%
  summarise(mean_diff = mean(diff),
            se_diff = sd(diff, na.rm = TRUE) / sqrt(n()),
            mean_prop = mean(proportion),
            se_prop = sd(proportion, na.rm = TRUE) / sqrt(n()))

# test whether weight change differs between the social groups
m6 <- lm(diff ~ social, data = sum6)
summary(m6)
```

There is no significant differences between groups for weight loss.

## Figures

Multi-plot of all PRBM metrics by social group over time.

```{r}
# set default theme options for all plots
pal <- c("#2E3EDC", "#07A567", "#AFACAC")

theme <- function(){
  list(
    theme_classic(),
    xlab(element_blank()),
    scale_x_continuous(breaks=seq(0, 50, 10)),
    scale_color_manual(values = pal,
                       name = "Cohort and social group membership"),
    scale_fill_manual(values = pal,,
                      name = "Cohort and social group membership")
  )
}

# list of plots
g1 <- ggplot(datam1)+
  geom_smooth(aes(elapsed, daily_dist, color = social, fill = social),
              method = "lm")+
  ylab("Daily distance moved (m)")+
  theme()

g2 <- ggplot(datam2)+
  geom_smooth(aes(elapsed, distance_previous, color = social, fill = social),
              method = "lm")+
  ylab("Daily distance between roosts (m)")+
  theme()

g3 <- ggplot(datam3)+
  geom_smooth(aes(elapsed, dist_release, color = social, fill = social),
              method = "lm")+
  ylab("Distance from release site (m)")+
  theme()

g4 <- ggplot(datam4)+
  geom_smooth(aes(elapsed, area, color = social, fill = social),
              method = "lm")+
  ylab("Home range (50% KUD) area (ha)")+
  theme()

g5 <- ggplot(datam5)+
  geom_smooth(aes(elapsed, state2p, color = social, fill = social),
              method = "lm")+
  ylab("Time allocated to foraging %")+
  theme()

g6 <- ggplot(datam6)+
  geom_smooth(aes(status, weight, colour = social, group = social, fill = social),
              method = "lm")+
  theme_classic()+
  xlab(element_blank()) + 
  ylab("Weight (g)") + 
  scale_colour_manual(values = c("#2E3EDC", "#07A567"))+
  scale_fill_manual(values = c("#2E3EDC", "#07A567"))

# multi plot 3x2
ggarrange(g1, g2, g3, g4, g5, g6,
          ncol = 3, nrow = 2,
          labels = c("A", "B", "C", "D", "E", "F"),
          common.legend = TRUE, legend = "bottom")
```

Multi plot of all effects.

```{r}

```

# Statistical analysis residents

We want to know if the residents change their behaviour in response to the reinforcing release. To test this we compare their movement metrics before and after the reinforcement for the same period i.e. 60 days either side. Unlike the reinforcer dates, we are measuring post-release from the *first* reinforcer released, rather than the last - because these 3 days still have potential to impact the residents. 

```{r}
# define pre-release date period
pre_dates <- seq.Date(from = as_date("2023-04-08"), to = as_date("2023-06-06"), by = "day")

# define post-release date period
post_dates <- seq.Date(from = as_date("2023-06-07"), to = as_date("2023-08-05"), by = "day")

# all dates
dates <- c(pre_dates, post_dates)
```

## m7: Distance moved

Do residents change their distance moved after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam7 <- read.csv("results/daily_distance_moved.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as dates
  mutate(date = as_date(date_bird)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# create cohort mean
sum7 <- datam7 %>%
  group_by(date) %>%
  summarise(daily_dist = mean(daily_dist)) %>%
  arrange(date) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# plot means
ggplot(datam7)+
  geom_boxplot(aes(period, daily_dist))+
  theme_minimal()

# plot residents over time
ggplot(sum7)+
  geom_path(aes(date, daily_dist))+
  geom_vline(aes(xintercept = as_date("2023-06-07")), colour = "purple")+
  theme_minimal()+
  xlab("Date") + 
  ylab("Daily distance moved (m)")

# plot as a linear model
ggplot(datam7)+
  geom_smooth(aes(date, daily_dist, colour = period), method = "lm")+
  theme_minimal()+
  xlab("Date") + 
  ylab("Daily distance moved (m)")
```

They reduce their daily distance moved and then slowly increase it back to pre-release levels.

```{r}
# summarise to period
per7 <- datam7 %>%
  group_by(period, id) %>%
  summarise(daily_dist = mean(daily_dist))

# distribution of movement data
hist(per7$daily_dist)
ggqqplot(per7$daily_dist)

# test difference between the groups with interaction of time
m7 <- lmer(daily_dist ~ period + (1|id), data = per7)
summary(m7)
anova(m7)

# check residuals
hist(residuals(m7))
ggqqplot(residuals(m7))
```

They moved significantly less far in the period post-release (p = 0.0291). 

## m8: Roost location

Do residents change their distance between roosts after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam8 <- read.csv("results/daily_distance_between_roosts.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement"))) %>%
  # without major outliers from Nutmeg beyond the fence
  filter(distance_previous < 2000)

# create cohort mean
sum8 <- datam8 %>%
  group_by(date) %>%
  summarise(distance_previous = mean(distance_previous)) %>%
  arrange(date) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# plot means
ggplot(datam8)+
  geom_boxplot(aes(period, distance_previous))+
  theme_minimal()

# plot residents over time
ggplot(sum8)+
  geom_path(aes(date, distance_previous))+
  geom_vline(aes(xintercept = as_date("2023-06-07")), colour = "purple")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance between consecutive roosts (m)")

# plot as a linear model
ggplot(datam8)+
  geom_smooth(aes(date, distance_previous, colour = period), method = "lm")+
  theme_minimal()+
  xlab("Date") + 
  ylab("Distance between consecutive roosts (m)")
```

The linear model plot is a bit misleading because it's adding a trendline to what is basically static and then a spike either side of release - also I'm unsure why there is a spike just before release. Maybe because I was in the reserve and bothering them?

```{r}
# summarise to period
per8 <- datam8 %>%
  group_by(period, id) %>%
  summarise(distance_previous = mean(distance_previous))

# distribution of movement data
hist(per8$distance_previous)
ggqqplot(per8$distance_previous)

# test difference between the groups with interaction of time
m8 <- lmer(distance_previous ~ period + (1|id), data = per8)
summary(m8)

# check residuals
hist(residuals(m8))
ggqqplot(residuals(m8))
```

No difference in roost site displacement.

## m9: Release-site distance

Do residents change their distance from the release site after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam9 <- read.csv("results/daily_roost_distance_from_release.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# create cohort mean
sum9 <- datam9 %>%
  group_by(date) %>%
  summarise(dist_release = mean(dist_release)) %>%
  arrange(date) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# plot means
ggplot(datam9)+
  geom_boxplot(aes(period, dist_release))+
  theme_minimal()

# plot residents over time
ggplot(sum9)+
  geom_path(aes(date, dist_release))+
  geom_vline(aes(xintercept = as_date("2023-06-06")), colour = "purple")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance from release site (m)")

# plot as a linear model
ggplot(datam9)+
  geom_smooth(aes(date, dist_release, colour = period), method = "lm")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Distance from release site (m)")
```

The residents had already gradually been moving back in from zone 2 to zone 1 but the reinforcement attracted them to the central woodland north of the release site. 

```{r}
# summarise to period
per9 <- datam9 %>%
  group_by(period, id) %>%
  summarise(dist_release = mean(dist_release))

# distribution of movement data
hist(per9$dist_release)
ggqqplot(per9$dist_release)

# test difference between the groups with interaction of time
m9 <- lmer(dist_release ~ period + (1|id), data = per9)
summary(m9)

# check residuals
hist(residuals(m9))
ggqqplot(residuals(m9))
```

Not the best model and weird distribution of data. There is a difference in how far they are from the release site post-release (0.000356).

### Resident change map

I think it would be helpful to visualise their roost locations on a map.

```{r}
ggmap(map_z15)+
  # plot roosts colour by time
  geom_point(aes(longitude, latitude, colour = date),
             size = 2, data = datam8, inherit.aes = FALSE)+
  # add release location
  geom_point(aes(144.434323, -37.902374), 
             colour = "white", size = 5, shape = 13, inherit.aes = FALSE)+
  # add fence
  geom_spatvector(data = mtr, inherit.aes = FALSE, fill = NA, colour = "white",
                  linetype = "longdash")+
  # wrap by period
  facet_wrap(~period)+
  # theme options
  scale_colour_viridis_c(trans = "date", name = "2023")+
  theme_void()+
  scale_y_continuous(expand = expansion(mult = c(0, 0.01)))+
  theme(legend.position="bottom",
        legend.key.width = unit(4, 'cm'),
        strip.text = element_text(size = 15))
```

## m10: Home range size

Do residents change their home range size after reinforcement?

```{r}
# read in data and filter to residents for reinforcement period
datam10 <- read.csv("results/daily_hr_area.csv") %>%
  # add metadata
  left_join(dplyr::select(metadata, c("id", "cohort"))) %>%
  # select only residents
  filter(cohort == "Resident") %>%
  # format dates as dates
  mutate(date = as_date(date)) %>%
  # limit to reinforcement period
  filter(date %in% dates) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement"))) %>%
  # remove crazy outlier from Nutmeg's excursion
  filter(area < 100)

# create cohort mean
sum10 <- datam10 %>%
  group_by(date) %>%
  summarise(area = mean(area)) %>%
  arrange(date) %>%
  # add column for pre or post release
  mutate(period = factor(ifelse(date %in% pre_dates, 
                         "pre-reinforcement", "post-reinforcement"),
                         levels  = c("pre-reinforcement", "post-reinforcement")))

# plot means
ggplot(datam10)+
  geom_boxplot(aes(period, area))+
  theme_minimal()

# plot residents over time
ggplot(sum10)+
  geom_path(aes(date, area))+
  geom_vline(aes(xintercept = as_date("2023-06-06")), colour = "purple")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Home range size (ha)")

# plot as a linear model
ggplot(datam10)+
  geom_smooth(aes(date, area, colour = period), method = "lm")+
  theme_minimal() +
  xlab("Date") + 
  ylab("Home range size (ha)")
```

Doesn't look like much difference.

```{r}
# summarise to period
per10 <- datam10 %>%
  group_by(period, id) %>%
  summarise(area = mean(area))

# distribution of movement data
hist(per10$area)
ggqqplot(per10$area)

# test difference between the groups with interaction of time
m10 <- lmer(area ~ period + (1|id), data = per10)
summary(m10)

# check residuals
hist(residuals(m10))
ggqqplot(residuals(m10))
```

No difference. 

## m11: Time over the fence

I suspect the flightless reinforcers acted as an anchor to the residents, most of whom had regained flight. How many days (night technically) over the fence?

```{r}
# read in night data
data_night <- read.csv("data/data_clean_night.csv") %>%
  # format time as posixct
  mutate(time_local = as.POSIXct(time_local),
         date_bird = as_date(date_bird)) %>%
  # add cohort info
  left_join(select(metadata, c(id, cohort))) %>%
  # keep only residents
  filter(cohort == "Resident") %>%
  # pre and post release period dates
  filter(date_bird %in% dates)

# convert to spatial points
points <- data_night %>%
  vect(geom = c("longitude", "latitude"), crs = "EPSG:4326")

# Find points outside fence
outside <- points[!relate(points, mtr, "intersects")] %>%
  as.data.frame(geom = "XY")
  
# Plot points outside fence 
ggmap(map_z14)+
  geom_point(data=outside, aes(x, y, colour = id), alpha = 0.7, size = 3)+
  geom_spatvector(data=mtr, inherit.aes = FALSE, colour = "white", fill = NA)+
  scale_colour_viridis_d()+
  theme_void()

# Days with points outside
excursion <- outside %>%
  group_by(id, date_bird) %>%
  summarise(count = length(id)) %>%
  # filter days <10 points unlikely to be an excursion
  filter(count >= 10)
```

It's really only Nutmeg and Marmalade with flight at this stage, so insufficient replication to answer this question.

# Survival analysis

## Reinforcers and residents

Do reinforcers survive better than the residents? 

This is hard to answer because not tracked as long and some birds were subsequently moved to Orana (right censored data). Attempt to answer this using Kaplan Meier Analysis

Start by looking at the overall survival probabilities for all birds.

```{r m6}
# Format data for Kaplan Meier Analysis - where death is TRUE i.e. 1
surv_data <- metadata %>%
  # remove columns not needed
  dplyr::select(!c(location, abbbs, band, alive, release_year)) %>%
  # add survival time (persistence) - right censored data
  mutate(time = end_date - start_date) %>%
  # add status - whether death occurs
  mutate(status = ifelse(is.na(mortality), 0, 1))

km <- with(surv_data, Surv(time, status))
  
# Fit a basic survival model
kmfit <- survfit(Surv(time, status) ~ 1, data = surv_data)

# Estimated survival probabilities
summary(kmfit, times = c(1, 10, 30, 55, 100, 365))

# plot
autoplot(kmfit)
```

The probability of survival to 1 year is 50% (CI: 34-75%). The probability of survival to 55 days (the study period) is 91% (CI: 83-100%).

Next we compare survial by cohorts.

```{r}
# Fit a survival model by cohort
kmfit_cohort <- survfit(Surv(time, status) ~ cohort, data = surv_data)

summary(kmfit_cohort, times = c(1,30,55))

# plot
autoplot(kmfit_cohort)

# Fit Cox Model
cox <- coxph(Surv(time, status) ~ cohort, data = surv_data)
summary(cox)
```

The probability of survival to 55 days for residents is 87% (CI: 71-100%) and for reinforcers is 95% (CI: 86-100%). So reinforcers are slightly more likely to survive, however this effect is not significant (p=0.754). There were two disease events (one in each cohort) that accounted for most of the early deaths. Potentially the stress of translocation caused these individuals to succumb to illness. 

## Reinforcers by social group

During the social analysis step we found that post-reinforcement there were two sub-groups to the community:

  1) a group with just reinforcers, and 
  2) a blended group of all remaining residents and half the reinforcers.
  
I hypothesise the group with the residents would survive better because of the enhanced potential for learning. 

Compare to 55 days (minimum common denominator deployment period for reinforcers).

```{r}
# social group membership
club <- c("Rowan", "Rory", "Fauna", "Zeus", "Rocky", "Sofi", "Loki", "Avery", "Maeve")

# Format data for Kaplan Meier Analysis - where death is TRUE i.e. 1
surv_data <- metadata %>%
  # remove columns not needed
  dplyr::select(!c(location, abbbs, band, alive, release_year)) %>%
  # add survival time (persistence) - right censored data
  mutate(time = end_date - start_date) %>%
  # add status - whether death occurs
  mutate(status = ifelse(is.na(mortality), 0, 1)) %>%
  # add column for membership to social group
  mutate(social = ifelse(id %in% club, "exclusive", "mixed")) %>%
  # select only reinforcers
  filter(cohort == "Reinforcing")

# Fit a survival model by social group
kmfit_social <- survfit(Surv(time, status) ~ social, data = surv_data)

summary(kmfit_social, times = c(1,30,54))

# plot
autoplot(kmfit_social)

# Fit Cox Model
cox <- coxph(Surv(time, status) ~ social, data = surv_data)
summary(cox)
```

No difference in survival for reinforcers of different social memberships.